Starting job 8135152
SLURM assigned me the node(s): gpusrv09
Experiments are running under the following process IDs:
Experiment ID: 2	Process ID: 58106

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 14:14:46 (INFO): Running command 'run'
2022-05-19 14:14:46 (INFO): Started run with ID "2"
2022-05-19 14:14:50 (INFO): Data loaded succesfully
2022-05-19 14:14:50 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.2572648525238037
 |--------------------| 1.0%  - val_loss: 1269.9375203451 - val_trvae_loss: 1269.9375203451 |--------------------| 2.0%  - val_loss: 1241.2193806966 - val_trvae_loss: 1241.2193806966 |--------------------| 3.0%  - val_loss: 1198.5702921549 - val_trvae_loss: 1198.5702921549 |--------------------| 4.0%  - val_loss: 1175.4786275228 - val_trvae_loss: 1175.4786275228 |█-------------------| 5.0%  - val_loss: 1149.0321350098 - val_trvae_loss: 1149.0321350098 |█-------------------| 6.0%  - val_loss: 1149.6480000814 - val_trvae_loss: 1149.6480000814 |█-------------------| 7.0%  - val_loss: 1130.8700154622 - val_trvae_loss: 1130.8700154622 |█-------------------| 8.0%  - val_loss: 1125.7797241211 - val_trvae_loss: 1125.7797241211 |█-------------------| 9.0%  - val_loss: 1124.6869405111 - val_trvae_loss: 1124.6869405111 |██------------------| 10.0%  - val_loss: 1121.5934549967 - val_trvae_loss: 1121.5934549967 |██------------------| 11.0%  - val_loss: 1111.7610168457 - val_trvae_loss: 1111.7610168457 |██------------------| 12.0%  - val_loss: 1111.2119140625 - val_trvae_loss: 1111.2119140625 |██------------------| 13.0%  - val_loss: 1115.4792683919 - val_trvae_loss: 1115.4792683919 |██------------------| 14.0%  - val_loss: 1104.8080037435 - val_trvae_loss: 1104.8080037435 |███-----------------| 15.0%  - val_loss: 1107.0582173665 - val_trvae_loss: 1107.0582173665 |███-----------------| 16.0%  - val_loss: 1096.7504018148 - val_trvae_loss: 1096.7504018148 |███-----------------| 17.0%  - val_loss: 1103.4352213542 - val_trvae_loss: 1103.4352213542 |███-----------------| 18.0%  - val_loss: 1104.8767903646 - val_trvae_loss: 1104.8767903646 |███-----------------| 19.0%  - val_loss: 1103.9392089844 - val_trvae_loss: 1103.9392089844 |████----------------| 20.0%  - val_loss: 1097.9878031413 - val_trvae_loss: 1097.9878031413 |████----------------| 21.0%  - val_loss: 1098.0287170410 - val_trvae_loss: 1098.0287170410 |████----------------| 22.0%  - val_loss: 1102.2114359538 - val_trvae_loss: 1102.2114359538 |████----------------| 23.0%  - val_loss: 1096.9329223633 - val_trvae_loss: 1096.9329223633 |████----------------| 24.0%  - val_loss: 1094.5608723958 - val_trvae_loss: 1094.5608723958 |█████---------------| 25.0%  - val_loss: 1095.6565653483 - val_trvae_loss: 1095.6565653483 |█████---------------| 26.0%  - val_loss: 1091.0647074382 - val_trvae_loss: 1091.0647074382 |█████---------------| 27.0%  - val_loss: 1094.2610880534 - val_trvae_loss: 1094.2610880534 |█████---------------| 28.0%  - val_loss: 1094.2119649251 - val_trvae_loss: 1094.2119649251 |█████---------------| 29.0%  - val_loss: 1088.0088602702 - val_trvae_loss: 1088.0088602702 |██████--------------| 30.0%  - val_loss: 1088.4476420085 - val_trvae_loss: 1088.4476420085 |██████--------------| 31.0%  - val_loss: 1088.8429870605 - val_trvae_loss: 1088.8429870605 |██████--------------| 32.0%  - val_loss: 1087.6783955892 - val_trvae_loss: 1087.6783955892 |██████--------------| 33.0%  - val_loss: 1086.1440785726 - val_trvae_loss: 1086.1440785726 |██████--------------| 34.0%  - val_loss: 1086.6165059408 - val_trvae_loss: 1086.6165059408 |███████-------------| 35.0%  - val_loss: 1091.3019002279 - val_trvae_loss: 1091.3019002279 |███████-------------| 36.0%  - val_loss: 1096.0029195150 - val_trvae_loss: 1096.0029195150 |███████-------------| 37.0%  - val_loss: 1094.3177185059 - val_trvae_loss: 1094.3177185059 |███████-------------| 38.0%  - val_loss: 1084.7071990967 - val_trvae_loss: 1084.7071990967 |███████-------------| 39.0%  - val_loss: 1086.7148946126 - val_trvae_loss: 1086.7148946126 |████████------------| 40.0%  - val_loss: 1086.1435445150 - val_trvae_loss: 1086.1435445150 |████████------------| 41.0%  - val_loss: 1095.6299133301 - val_trvae_loss: 1095.6299133301 |████████------------| 42.0%  - val_loss: 1092.4518229167 - val_trvae_loss: 1092.4518229167 |████████------------| 43.0%  - val_loss: 1095.0510864258 - val_trvae_loss: 1095.0510864258 |████████------------| 44.0%  - val_loss: 1087.8435668945 - val_trvae_loss: 1087.8435668945 |█████████-----------| 45.0%  - val_loss: 1086.2372741699 - val_trvae_loss: 1086.2372741699 |█████████-----------| 46.0%  - val_loss: 1090.8887329102 - val_trvae_loss: 1090.8887329102 |█████████-----------| 47.0%  - val_loss: 1089.5092671712 - val_trvae_loss: 1089.5092671712 |█████████-----------| 48.0%  - val_loss: 1084.6381123861 - val_trvae_loss: 1084.6381123861 |█████████-----------| 49.0%  - val_loss: 1086.3252156576 - val_trvae_loss: 1086.3252156576 |██████████----------| 50.0%  - val_loss: 1088.4649556478 - val_trvae_loss: 1088.4649556478 |██████████----------| 51.0%  - val_loss: 1084.5859680176 - val_trvae_loss: 1084.5859680176 |██████████----------| 52.0%  - val_loss: 1088.3037414551 - val_trvae_loss: 1088.3037414551 |██████████----------| 53.0%  - val_loss: 1090.4471740723 - val_trvae_loss: 1090.4471740723 |██████████----------| 54.0%  - val_loss: 1083.2428588867 - val_trvae_loss: 1083.2428588867 |███████████---------| 55.0%  - val_loss: 1085.4738464355 - val_trvae_loss: 1085.4738464355 |███████████---------| 56.0%  - val_loss: 1081.7761891683 - val_trvae_loss: 1081.7761891683 |███████████---------| 57.0%  - val_loss: 1089.0532633464 - val_trvae_loss: 1089.0532633464 |███████████---------| 58.0%  - val_loss: 1089.1695353190 - val_trvae_loss: 1089.1695353190 |███████████---------| 59.0%  - val_loss: 1088.6463877360 - val_trvae_loss: 1088.6463877360 |████████████--------| 60.0%  - val_loss: 1089.0297953288 - val_trvae_loss: 1089.0297953288 |████████████--------| 61.0%  - val_loss: 1085.2234598796 - val_trvae_loss: 1085.2234598796 |████████████--------| 62.0%  - val_loss: 1086.9016215007 - val_trvae_loss: 1086.9016215007 |████████████--------| 63.0%  - val_loss: 1089.8020121257 - val_trvae_loss: 1089.8020121257 |████████████--------| 64.0%  - val_loss: 1076.6995646159 - val_trvae_loss: 1076.6995646159 |█████████████-------| 65.0%  - val_loss: 1085.0528361003 - val_trvae_loss: 1085.0528361003 |█████████████-------| 66.0%  - val_loss: 1084.6073710124 - val_trvae_loss: 1084.6073710124 |█████████████-------| 67.0%  - val_loss: 1091.0401713053 - val_trvae_loss: 1091.0401713053 |█████████████-------| 68.0%  - val_loss: 1090.2262980143 - val_trvae_loss: 1090.2262980143 |█████████████-------| 69.0%  - val_loss: 1086.7631327311 - val_trvae_loss: 1086.7631327311 |██████████████------| 70.0%  - val_loss: 1092.2671457926 - val_trvae_loss: 1092.2671457926 |██████████████------| 71.0%  - val_loss: 1090.1572469076 - val_trvae_loss: 1090.1572469076 |██████████████------| 72.0%  - val_loss: 1087.1563720703 - val_trvae_loss: 1087.1563720703 |██████████████------| 73.0%  - val_loss: 1087.0549825033 - val_trvae_loss: 1087.0549825033 |██████████████------| 74.0%  - val_loss: 1087.7087809245 - val_trvae_loss: 1087.7087809245 |███████████████-----| 75.0%  - val_loss: 1084.3316141764 - val_trvae_loss: 1084.3316141764 |███████████████-----| 76.0%  - val_loss: 1088.0981953939 - val_trvae_loss: 1088.0981953939 |███████████████-----| 77.0%  - val_loss: 1087.2561442057 - val_trvae_loss: 1087.2561442057 |███████████████-----| 78.0%  - val_loss: 1087.1606038411 - val_trvae_loss: 1087.1606038411 |███████████████-----| 79.0%  - val_loss: 1082.7002563477 - val_trvae_loss: 1082.7002563477 |████████████████----| 80.0%  - val_loss: 1086.1778564453 - val_trvae_loss: 1086.1778564453 |████████████████----| 81.0%  - val_loss: 1092.8042500814 - val_trvae_loss: 1089.4346822103 - val_landmark_loss: 3.3695817987 - val_labeled_loss: 3.3695817987 |████████████████----| 82.0%  - val_loss: 1091.1386311849 - val_trvae_loss: 1088.3866170247 - val_landmark_loss: 2.7519802252 - val_labeled_loss: 2.7519802252 |████████████████----| 83.0%  - val_loss: 1090.7721252441 - val_trvae_loss: 1088.2752380371 - val_landmark_loss: 2.4968889107 - val_labeled_loss: 2.4968889107 |████████████████----| 84.0%  - val_loss: 1082.9659983317 - val_trvae_loss: 1080.8559417725 - val_landmark_loss: 2.1100601951 - val_labeled_loss: 2.1100601951 |█████████████████---| 85.0%  - val_loss: 1093.2543233236 - val_trvae_loss: 1091.1124877930 - val_landmark_loss: 2.1418440094 - val_labeled_loss: 2.1418440094 |█████████████████---| 86.0%  - val_loss: 1095.2057088216 - val_trvae_loss: 1093.0509389242 - val_landmark_loss: 2.1547603309 - val_labeled_loss: 2.1547603309 |█████████████████---| 87.0%  - val_loss: 1085.8154296875 - val_trvae_loss: 1083.7902119954 - val_landmark_loss: 2.0252230416 - val_labeled_loss: 2.0252230416 |█████████████████---| 88.0%  - val_loss: 1086.6176147461 - val_trvae_loss: 1085.1421203613 - val_landmark_loss: 1.4754920503 - val_labeled_loss: 1.4754920503 |█████████████████---| 89.0%  - val_loss: 1089.1562296549 - val_trvae_loss: 1087.6109008789 - val_landmark_loss: 1.5453268240 - val_labeled_loss: 1.5453268240 |██████████████████--| 90.0%  - val_loss: 1087.2789510091 - val_trvae_loss: 1085.8056335449 - val_landmark_loss: 1.4733136396 - val_labeled_loss: 1.4733136396 |██████████████████--| 91.0%  - val_loss: 1086.7810668945 - val_trvae_loss: 1085.3762715658 - val_landmark_loss: 1.4048014730 - val_labeled_loss: 1.4048014730 |██████████████████--| 92.0%  - val_loss: 1088.5745442708 - val_trvae_loss: 1087.3162434896 - val_landmark_loss: 1.2583196983 - val_labeled_loss: 1.2583196983 |██████████████████--| 93.0%  - val_loss: 1084.9301757812 - val_trvae_loss: 1083.7556966146 - val_landmark_loss: 1.1744818091 - val_labeled_loss: 1.1744818091 |██████████████████--| 94.0%  - val_loss: 1082.4567616781 - val_trvae_loss: 1081.2906901042 - val_landmark_loss: 1.1660601695 - val_labeled_loss: 1.1660601695 |███████████████████-| 95.0%  - val_loss: 1087.7162373861 - val_trvae_loss: 1086.6035664876 - val_landmark_loss: 1.1126742562 - val_labeled_loss: 1.1126742562 |███████████████████-| 96.0%  - val_loss: 1089.5542399089 - val_trvae_loss: 1088.2657368978 - val_landmark_loss: 1.2885077248 - val_labeled_loss: 1.2885077248 |███████████████████-| 97.0%  - val_loss: 1088.7357686361 - val_trvae_loss: 1087.6450093587 - val_landmark_loss: 1.0907470981 - val_labeled_loss: 1.0907470981 |███████████████████-| 98.0%  - val_loss: 1086.7327473958 - val_trvae_loss: 1085.6135050456 - val_landmark_loss: 1.1192464481 - val_labeled_loss: 1.1192464481 |███████████████████-| 99.0%  - val_loss: 1086.8670145671 - val_trvae_loss: 1085.7210998535 - val_landmark_loss: 1.1459051619 - val_labeled_loss: 1.1459051619 |████████████████████| 100.0%  - val_loss: 1086.0372823079 - val_trvae_loss: 1085.0465799967 - val_landmark_loss: 0.9907031829 - val_labeled_loss: 0.9907031829
2022-05-19 14:16:54 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 1937 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

8
loaders init
loaders init done
0.011670589447021484
 |--------------------| 1.0%  - val_loss: 968.0136108398 - val_trvae_loss: 968.0136108398 |--------------------| 2.0%  - val_loss: 978.2784729004 - val_trvae_loss: 978.2784729004 |--------------------| 3.0%  - val_loss: 981.5720520020 - val_trvae_loss: 981.5720520020 |--------------------| 4.0%  - val_loss: 975.7130432129 - val_trvae_loss: 975.7130432129 |█-------------------| 5.0%  - val_loss: 967.4479980469 - val_trvae_loss: 967.4479980469 |█-------------------| 6.0%  - val_loss: 965.6285705566 - val_trvae_loss: 965.6285705566 |█-------------------| 7.0%  - val_loss: 956.9848937988 - val_trvae_loss: 956.9848937988 |█-------------------| 8.0%  - val_loss: 975.0497131348 - val_trvae_loss: 975.0497131348 |█-------------------| 9.0%  - val_loss: 965.0444946289 - val_trvae_loss: 965.0444946289 |██------------------| 10.0%  - val_loss: 961.5544128418 - val_trvae_loss: 961.5544128418 |██------------------| 11.0%  - val_loss: 962.4339904785 - val_trvae_loss: 962.4339904785 |██------------------| 12.0%  - val_loss: 969.5881652832 - val_trvae_loss: 969.5881652832 |██------------------| 13.0%  - val_loss: 968.5136413574 - val_trvae_loss: 968.5136413574 |██------------------| 14.0%  - val_loss: 960.2064208984 - val_trvae_loss: 960.2064208984 |███-----------------| 15.0%  - val_loss: 966.8315429688 - val_trvae_loss: 966.8315429688 |███-----------------| 16.0%  - val_loss: 964.5768127441 - val_trvae_loss: 964.5768127441 |███-----------------| 17.0%  - val_loss: 967.4188537598 - val_trvae_loss: 967.4188537598 |███-----------------| 18.0%  - val_loss: 967.7786560059 - val_trvae_loss: 967.7786560059 |███-----------------| 19.0%  - val_loss: 967.8244018555 - val_trvae_loss: 967.8244018555 |████----------------| 20.0%  - val_loss: 963.0474548340 - val_trvae_loss: 963.0474548340 |████----------------| 21.0%  - val_loss: 967.0285339355 - val_trvae_loss: 967.0285339355 |████----------------| 22.0%  - val_loss: 967.5064392090 - val_trvae_loss: 967.5064392090 |████----------------| 23.0%  - val_loss: 968.2387390137 - val_trvae_loss: 968.2387390137 |████----------------| 24.0%  - val_loss: 968.8966369629 - val_trvae_loss: 968.8966369629 |█████---------------| 25.0%  - val_loss: 963.8251647949 - val_trvae_loss: 963.8251647949 |█████---------------| 26.0%  - val_loss: 957.5721130371 - val_trvae_loss: 957.5721130371 |█████---------------| 27.0%  - val_loss: 964.7984619141 - val_trvae_loss: 964.7984619141 |█████---------------| 28.0%  - val_loss: 962.5995483398 - val_trvae_loss: 962.5995483398 |█████---------------| 29.0%  - val_loss: 963.5858764648 - val_trvae_loss: 963.5858764648 |██████--------------| 30.0%  - val_loss: 971.2926025391 - val_trvae_loss: 971.2926025391 |██████--------------| 31.0%  - val_loss: 954.9001159668 - val_trvae_loss: 954.9001159668 |██████--------------| 32.0%  - val_loss: 967.5128479004 - val_trvae_loss: 967.5128479004 |██████--------------| 33.0%  - val_loss: 959.4834594727 - val_trvae_loss: 959.4834594727 |██████--------------| 34.0%  - val_loss: 969.5025634766 - val_trvae_loss: 969.5025634766 |███████-------------| 35.0%  - val_loss: 965.7040710449 - val_trvae_loss: 965.7040710449 |███████-------------| 36.0%  - val_loss: 966.3238220215 - val_trvae_loss: 966.3238220215 |███████-------------| 37.0%  - val_loss: 961.0469970703 - val_trvae_loss: 961.0469970703 |███████-------------| 38.0%  - val_loss: 970.3778381348 - val_trvae_loss: 970.3778381348 |███████-------------| 39.0%  - val_loss: 961.8333740234 - val_trvae_loss: 961.8333740234 |████████------------| 40.0%  - val_loss: 962.1636352539 - val_trvae_loss: 962.1636352539 |████████------------| 41.0%  - val_loss: 962.1257934570 - val_trvae_loss: 962.1257934570 |████████------------| 42.0%  - val_loss: 945.9762573242 - val_trvae_loss: 945.9762573242 |████████------------| 43.0%  - val_loss: 961.7990722656 - val_trvae_loss: 961.7990722656 |████████------------| 44.0%  - val_loss: 963.7333984375 - val_trvae_loss: 963.7333984375 |█████████-----------| 45.0%  - val_loss: 954.5052795410 - val_trvae_loss: 954.5052795410 |█████████-----------| 46.0%  - val_loss: 958.6484985352 - val_trvae_loss: 958.6484985352 |█████████-----------| 47.0%  - val_loss: 957.0215759277 - val_trvae_loss: 957.0215759277 |█████████-----------| 48.0%  - val_loss: 957.3839416504 - val_trvae_loss: 957.3839416504 |█████████-----------| 49.0%  - val_loss: 954.0527038574 - val_trvae_loss: 954.0527038574 |██████████----------| 50.0%  - val_loss: 957.2402343750 - val_trvae_loss: 957.2402343750 |██████████----------| 51.0%  - val_loss: 960.3213500977 - val_trvae_loss: 960.3213500977 |██████████----------| 52.0%  - val_loss: 953.7281188965 - val_trvae_loss: 953.7281188965 |██████████----------| 53.0%  - val_loss: 950.4444885254 - val_trvae_loss: 950.4444885254 |██████████----------| 54.0%  - val_loss: 959.1962280273 - val_trvae_loss: 959.1962280273 |███████████---------| 55.0%  - val_loss: 962.0976562500 - val_trvae_loss: 962.0976562500 |███████████---------| 56.0%  - val_loss: 960.4851989746 - val_trvae_loss: 960.4851989746 |███████████---------| 57.0%  - val_loss: 958.0211181641 - val_trvae_loss: 958.0211181641 |███████████---------| 58.0%  - val_loss: 963.2770996094 - val_trvae_loss: 963.2770996094 |███████████---------| 59.0%  - val_loss: 966.9569396973 - val_trvae_loss: 966.9569396973 |████████████--------| 60.0%  - val_loss: 962.3050842285 - val_trvae_loss: 962.3050842285 |████████████--------| 61.0%  - val_loss: 960.5299072266 - val_trvae_loss: 960.5299072266 |████████████--------| 62.0%  - val_loss: 970.8482360840 - val_trvae_loss: 970.8482360840 |████████████--------| 63.0%  - val_loss: 963.7856140137 - val_trvae_loss: 963.7856140137 |████████████--------| 64.0%  - val_loss: 958.9633178711 - val_trvae_loss: 958.9633178711 |█████████████-------| 65.0%  - val_loss: 966.4438171387 - val_trvae_loss: 966.4438171387 |█████████████-------| 66.0%  - val_loss: 956.5646972656 - val_trvae_loss: 956.5646972656 |█████████████-------| 67.0%  - val_loss: 948.1075134277 - val_trvae_loss: 948.1075134277 |█████████████-------| 68.0%  - val_loss: 960.2873840332 - val_trvae_loss: 960.2873840332 |█████████████-------| 69.0%  - val_loss: 963.5548706055 - val_trvae_loss: 963.5548706055 |██████████████------| 70.0%  - val_loss: 960.3001708984 - val_trvae_loss: 960.3001708984 |██████████████------| 71.0%  - val_loss: 972.4505004883 - val_trvae_loss: 972.4505004883 |██████████████------| 72.0%  - val_loss: 953.3872375488 - val_trvae_loss: 953.3872375488 |██████████████------| 73.0%  - val_loss: 961.2613220215 - val_trvae_loss: 961.2613220215 |██████████████------| 74.0%  - val_loss: 950.4837951660 - val_trvae_loss: 950.4837951660 |███████████████-----| 75.0%  - val_loss: 969.9467468262 - val_trvae_loss: 969.9467468262 |███████████████-----| 76.0%  - val_loss: 962.1263732910 - val_trvae_loss: 962.1263732910 |███████████████-----| 77.0%  - val_loss: 964.8264160156 - val_trvae_loss: 964.8264160156 |███████████████-----| 78.0%  - val_loss: 963.8613281250 - val_trvae_loss: 963.8613281250 |███████████████-----| 79.0%  - val_loss: 952.5187377930 - val_trvae_loss: 952.5187377930 |████████████████----| 80.0%  - val_loss: 961.5426940918 - val_trvae_loss: 961.5426940918
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 16 clusters.
 |████████████████----| 81.0%  - val_loss: 960.6921386719 - val_trvae_loss: 960.6920776367 - val_landmark_loss: 0.0000683948 - val_unlabeled_loss: 0.0683948100 |████████████████----| 82.0%  - val_loss: 968.1797790527 - val_trvae_loss: 968.1797180176 - val_landmark_loss: 0.0000643143 - val_unlabeled_loss: 0.0643142946 |████████████████----| 83.0%  - val_loss: 952.1689147949 - val_trvae_loss: 952.1688537598 - val_landmark_loss: 0.0000637534 - val_unlabeled_loss: 0.0637534279 |████████████████----| 84.0%  - val_loss: 950.0093078613 - val_trvae_loss: 950.0092468262 - val_landmark_loss: 0.0000663938 - val_unlabeled_loss: 0.0663937517 |█████████████████---| 85.0%  - val_loss: 967.3758544922 - val_trvae_loss: 967.3757934570 - val_landmark_loss: 0.0000658695 - val_unlabeled_loss: 0.0658694729 |█████████████████---| 86.0%  - val_loss: 957.0586547852 - val_trvae_loss: 957.0585937500 - val_landmark_loss: 0.0000675899 - val_unlabeled_loss: 0.0675899163 |█████████████████---| 87.0%  - val_loss: 954.6934814453 - val_trvae_loss: 954.6934204102 - val_landmark_loss: 0.0000637006 - val_unlabeled_loss: 0.0637006033 |█████████████████---| 88.0%  - val_loss: 962.1752319336 - val_trvae_loss: 962.1751708984 - val_landmark_loss: 0.0000600374 - val_unlabeled_loss: 0.0600373596 |█████████████████---| 89.0%  - val_loss: 972.9064025879 - val_trvae_loss: 972.9063415527 - val_landmark_loss: 0.0000697315 - val_unlabeled_loss: 0.0697315317 |██████████████████--| 90.0%  - val_loss: 945.9736633301 - val_trvae_loss: 945.9736022949 - val_landmark_loss: 0.0000717997 - val_unlabeled_loss: 0.0717996676 |██████████████████--| 91.0%  - val_loss: 963.4134521484 - val_trvae_loss: 963.4133911133 - val_landmark_loss: 0.0000666218 - val_unlabeled_loss: 0.0666217618 |██████████████████--| 92.0%  - val_loss: 954.5762634277 - val_trvae_loss: 954.5762023926 - val_landmark_loss: 0.0000658407 - val_unlabeled_loss: 0.0658407435 |██████████████████--| 93.0%  - val_loss: 955.5707092285 - val_trvae_loss: 955.5706481934 - val_landmark_loss: 0.0000638487 - val_unlabeled_loss: 0.0638486631 |██████████████████--| 94.0%  - val_loss: 948.7436828613 - val_trvae_loss: 948.7436218262 - val_landmark_loss: 0.0000602038 - val_unlabeled_loss: 0.0602037515 |███████████████████-| 95.0%  - val_loss: 956.1470031738 - val_trvae_loss: 956.1469421387 - val_landmark_loss: 0.0000688147 - val_unlabeled_loss: 0.0688147396 |███████████████████-| 96.0%  - val_loss: 956.2772827148 - val_trvae_loss: 956.2772216797 - val_landmark_loss: 0.0000622177 - val_unlabeled_loss: 0.0622177292 |███████████████████-| 97.0%  - val_loss: 963.6390991211 - val_trvae_loss: 963.6390380859 - val_landmark_loss: 0.0000657811 - val_unlabeled_loss: 0.0657811407 |███████████████████-| 98.0%  - val_loss: 957.0297241211 - val_trvae_loss: 957.0296630859 - val_landmark_loss: 0.0000682801 - val_unlabeled_loss: 0.0682800934 |███████████████████-| 99.0%  - val_loss: 962.9596252441 - val_trvae_loss: 962.9595642090 - val_landmark_loss: 0.0000663390 - val_unlabeled_loss: 0.0663390197 |████████████████████| 100.0%  - val_loss: 956.4989318848 - val_trvae_loss: 956.4988708496 - val_landmark_loss: 0.0000660905 - val_unlabeled_loss: 0.0660904814
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 14:17:19 (INFO): Computing metrics
2022-05-19 14:17:19 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
Saving best state of network...
Best State was in Epoch 87
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2022-05-19 14:19:55 (ERROR): Failed after 0:05:09!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/tmp/22323/uncertainty/uncertainty_seml.py", line 252, in run
    rmtree(REF_PATH)
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 699, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 697, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/storage/groups/ml01/workspace/carlo.dedonno/lataq_reproduce/tmp/ref_model_embedcvae_2'

