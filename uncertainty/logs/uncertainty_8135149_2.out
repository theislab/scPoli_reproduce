Starting job 8135153
SLURM assigned me the node(s): gpusrv10
Experiments are running under the following process IDs:
Experiment ID: 3	Process ID: 41612

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 14:15:23 (INFO): Running command 'run'
2022-05-19 14:15:23 (INFO): Started run with ID "3"
2022-05-19 14:15:25 (INFO): Data loaded succesfully
2022-05-19 14:15:25 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.2597057819366455
 |--------------------| 1.0%  - val_loss: 1287.4968566895 - val_trvae_loss: 1287.4968566895 |--------------------| 2.0%  - val_loss: 1259.8140563965 - val_trvae_loss: 1259.8140563965 |--------------------| 3.0%  - val_loss: 1207.7748819987 - val_trvae_loss: 1207.7748819987 |--------------------| 4.0%  - val_loss: 1178.9897359212 - val_trvae_loss: 1178.9897359212 |█-------------------| 5.0%  - val_loss: 1156.0618082682 - val_trvae_loss: 1156.0618082682 |█-------------------| 6.0%  - val_loss: 1148.7350769043 - val_trvae_loss: 1148.7350769043 |█-------------------| 7.0%  - val_loss: 1141.6867980957 - val_trvae_loss: 1141.6867980957 |█-------------------| 8.0%  - val_loss: 1135.0966898600 - val_trvae_loss: 1135.0966898600 |█-------------------| 9.0%  - val_loss: 1134.0768432617 - val_trvae_loss: 1134.0768432617 |██------------------| 10.0%  - val_loss: 1127.6071472168 - val_trvae_loss: 1127.6071472168 |██------------------| 11.0%  - val_loss: 1120.1458638509 - val_trvae_loss: 1120.1458638509 |██------------------| 12.0%  - val_loss: 1120.1762288411 - val_trvae_loss: 1120.1762288411 |██------------------| 13.0%  - val_loss: 1120.3739115397 - val_trvae_loss: 1120.3739115397 |██------------------| 14.0%  - val_loss: 1109.5069376628 - val_trvae_loss: 1109.5069376628 |███-----------------| 15.0%  - val_loss: 1112.0437622070 - val_trvae_loss: 1112.0437622070 |███-----------------| 16.0%  - val_loss: 1105.7118428548 - val_trvae_loss: 1105.7118428548 |███-----------------| 17.0%  - val_loss: 1105.4701436361 - val_trvae_loss: 1105.4701436361 |███-----------------| 18.0%  - val_loss: 1105.8217468262 - val_trvae_loss: 1105.8217468262 |███-----------------| 19.0%  - val_loss: 1102.0408426921 - val_trvae_loss: 1102.0408426921 |████----------------| 20.0%  - val_loss: 1102.1307169596 - val_trvae_loss: 1102.1307169596 |████----------------| 21.0%  - val_loss: 1108.3438313802 - val_trvae_loss: 1108.3438313802 |████----------------| 22.0%  - val_loss: 1100.8144022624 - val_trvae_loss: 1100.8144022624 |████----------------| 23.0%  - val_loss: 1101.4051005046 - val_trvae_loss: 1101.4051005046 |████----------------| 24.0%  - val_loss: 1100.3263549805 - val_trvae_loss: 1100.3263549805 |█████---------------| 25.0%  - val_loss: 1099.4844970703 - val_trvae_loss: 1099.4844970703 |█████---------------| 26.0%  - val_loss: 1097.1112874349 - val_trvae_loss: 1097.1112874349 |█████---------------| 27.0%  - val_loss: 1103.6380004883 - val_trvae_loss: 1103.6380004883 |█████---------------| 28.0%  - val_loss: 1099.4486185710 - val_trvae_loss: 1099.4486185710 |█████---------------| 29.0%  - val_loss: 1090.7399393717 - val_trvae_loss: 1090.7399393717 |██████--------------| 30.0%  - val_loss: 1085.6894734701 - val_trvae_loss: 1085.6894734701 |██████--------------| 31.0%  - val_loss: 1099.9860229492 - val_trvae_loss: 1099.9860229492 |██████--------------| 32.0%  - val_loss: 1093.7889404297 - val_trvae_loss: 1093.7889404297 |██████--------------| 33.0%  - val_loss: 1093.4911397298 - val_trvae_loss: 1093.4911397298 |██████--------------| 34.0%  - val_loss: 1093.9506225586 - val_trvae_loss: 1093.9506225586 |███████-------------| 35.0%  - val_loss: 1089.6598002116 - val_trvae_loss: 1089.6598002116 |███████-------------| 36.0%  - val_loss: 1094.8060404460 - val_trvae_loss: 1094.8060404460 |███████-------------| 37.0%  - val_loss: 1093.8221842448 - val_trvae_loss: 1093.8221842448 |███████-------------| 38.0%  - val_loss: 1100.1754760742 - val_trvae_loss: 1100.1754760742 |███████-------------| 39.0%  - val_loss: 1092.6670023600 - val_trvae_loss: 1092.6670023600 |████████------------| 40.0%  - val_loss: 1092.5254007975 - val_trvae_loss: 1092.5254007975 |████████------------| 41.0%  - val_loss: 1098.8020629883 - val_trvae_loss: 1098.8020629883 |████████------------| 42.0%  - val_loss: 1095.3161315918 - val_trvae_loss: 1095.3161315918 |████████------------| 43.0%  - val_loss: 1097.7262369792 - val_trvae_loss: 1097.7262369792 |████████------------| 44.0%  - val_loss: 1085.5437113444 - val_trvae_loss: 1085.5437113444 |█████████-----------| 45.0%  - val_loss: 1086.9238942464 - val_trvae_loss: 1086.9238942464 |█████████-----------| 46.0%  - val_loss: 1092.8223673503 - val_trvae_loss: 1092.8223673503 |█████████-----------| 47.0%  - val_loss: 1089.8654378255 - val_trvae_loss: 1089.8654378255 |█████████-----------| 48.0%  - val_loss: 1091.1768798828 - val_trvae_loss: 1091.1768798828 |█████████-----------| 49.0%  - val_loss: 1089.8944193522 - val_trvae_loss: 1089.8944193522 |██████████----------| 50.0%  - val_loss: 1091.3086446126 - val_trvae_loss: 1091.3086446126 |██████████----------| 51.0%  - val_loss: 1093.3561197917 - val_trvae_loss: 1093.3561197917 |██████████----------| 52.0%  - val_loss: 1091.2291870117 - val_trvae_loss: 1091.2291870117 |██████████----------| 53.0%  - val_loss: 1089.8731994629 - val_trvae_loss: 1089.8731994629 |██████████----------| 54.0%  - val_loss: 1079.3455759684 - val_trvae_loss: 1079.3455759684 |███████████---------| 55.0%  - val_loss: 1085.9565429688 - val_trvae_loss: 1085.9565429688 |███████████---------| 56.0%  - val_loss: 1088.9795328776 - val_trvae_loss: 1088.9795328776 |███████████---------| 57.0%  - val_loss: 1098.3244323730 - val_trvae_loss: 1098.3244323730 |███████████---------| 58.0%  - val_loss: 1091.1350809733 - val_trvae_loss: 1091.1350809733 |███████████---------| 59.0%  - val_loss: 1084.3096008301 - val_trvae_loss: 1084.3096008301 |████████████--------| 60.0%  - val_loss: 1084.9159495036 - val_trvae_loss: 1084.9159495036 |████████████--------| 61.0%  - val_loss: 1095.9173685710 - val_trvae_loss: 1095.9173685710 |████████████--------| 62.0%  - val_loss: 1090.7692769368 - val_trvae_loss: 1090.7692769368 |████████████--------| 63.0%  - val_loss: 1088.5021158854 - val_trvae_loss: 1088.5021158854 |████████████--------| 64.0%  - val_loss: 1085.4110514323 - val_trvae_loss: 1085.4110514323 |█████████████-------| 65.0%  - val_loss: 1092.3475748698 - val_trvae_loss: 1092.3475748698 |█████████████-------| 66.0%  - val_loss: 1089.5270894368 - val_trvae_loss: 1089.5270894368 |█████████████-------| 67.0%  - val_loss: 1087.0651245117 - val_trvae_loss: 1087.0651245117 |█████████████-------| 68.0%  - val_loss: 1085.1289062500 - val_trvae_loss: 1085.1289062500 |█████████████-------| 69.0%  - val_loss: 1091.1013793945 - val_trvae_loss: 1091.1013793945 |██████████████------| 70.0%  - val_loss: 1088.0122680664 - val_trvae_loss: 1088.0122680664 |██████████████------| 71.0%  - val_loss: 1091.0978597005 - val_trvae_loss: 1091.0978597005 |██████████████------| 72.0%  - val_loss: 1090.6602681478 - val_trvae_loss: 1090.6602681478 |██████████████------| 73.0%  - val_loss: 1086.5378774007 - val_trvae_loss: 1086.5378774007 |██████████████------| 74.0%  - val_loss: 1088.7066141764 - val_trvae_loss: 1088.7066141764 |███████████████-----| 75.0%  - val_loss: 1093.4604593913 - val_trvae_loss: 1093.4604593913 |███████████████-----| 76.0%  - val_loss: 1083.9068756104 - val_trvae_loss: 1083.9068756104 |███████████████-----| 77.0%  - val_loss: 1088.4332885742 - val_trvae_loss: 1088.4332885742 |███████████████-----| 78.0%  - val_loss: 1090.0830383301 - val_trvae_loss: 1090.0830383301 |███████████████-----| 79.0%  - val_loss: 1086.8025309245 - val_trvae_loss: 1086.8025309245 |████████████████----| 80.0%  - val_loss: 1087.8907063802 - val_trvae_loss: 1087.8907063802 |████████████████----| 81.0%  - val_loss: 1094.2221679688 - val_trvae_loss: 1091.0550842285 - val_landmark_loss: 3.1670872569 - val_labeled_loss: 3.1670872569 |████████████████----| 82.0%  - val_loss: 1095.1352742513 - val_trvae_loss: 1092.6925557454 - val_landmark_loss: 2.4427284797 - val_labeled_loss: 2.4427284797 |████████████████----| 83.0%  - val_loss: 1096.3677571615 - val_trvae_loss: 1094.3745218913 - val_landmark_loss: 1.9932075242 - val_labeled_loss: 1.9932075242 |████████████████----| 84.0%  - val_loss: 1094.2553100586 - val_trvae_loss: 1092.2260335286 - val_landmark_loss: 2.0292720993 - val_labeled_loss: 2.0292720993 |█████████████████---| 85.0%  - val_loss: 1086.9476470947 - val_trvae_loss: 1085.2754109701 - val_landmark_loss: 1.6722264787 - val_labeled_loss: 1.6722264787 |█████████████████---| 86.0%  - val_loss: 1100.1897684733 - val_trvae_loss: 1098.5270690918 - val_landmark_loss: 1.6627043982 - val_labeled_loss: 1.6627043982 |█████████████████---| 87.0%  - val_loss: 1087.1210734049 - val_trvae_loss: 1085.5035705566 - val_landmark_loss: 1.6175068865 - val_labeled_loss: 1.6175068865 |█████████████████---| 88.0%  - val_loss: 1088.4128112793 - val_trvae_loss: 1086.7647705078 - val_landmark_loss: 1.6480486194 - val_labeled_loss: 1.6480486194 |█████████████████---| 89.0%  - val_loss: 1095.2161560059 - val_trvae_loss: 1093.7646586100 - val_landmark_loss: 1.4515013248 - val_labeled_loss: 1.4515013248 |██████████████████--| 90.0%  - val_loss: 1088.6449584961 - val_trvae_loss: 1087.2090047201 - val_landmark_loss: 1.4359433552 - val_labeled_loss: 1.4359433552 |██████████████████--| 91.0%  - val_loss: 1089.2797648112 - val_trvae_loss: 1087.8531188965 - val_landmark_loss: 1.4266496499 - val_labeled_loss: 1.4266496499 |██████████████████--| 92.0%  - val_loss: 1092.2165323893 - val_trvae_loss: 1090.8683166504 - val_landmark_loss: 1.3482141197 - val_labeled_loss: 1.3482141197 |██████████████████--| 93.0%  - val_loss: 1090.1755269368 - val_trvae_loss: 1088.9738159180 - val_landmark_loss: 1.2017128716 - val_labeled_loss: 1.2017128716 |██████████████████--| 94.0%  - val_loss: 1083.0158894857 - val_trvae_loss: 1081.9232381185 - val_landmark_loss: 1.0926643958 - val_labeled_loss: 1.0926643958 |███████████████████-| 95.0%  - val_loss: 1089.0846048991 - val_trvae_loss: 1087.9496459961 - val_landmark_loss: 1.1349614114 - val_labeled_loss: 1.1349614114 |███████████████████-| 96.0%  - val_loss: 1088.7064615885 - val_trvae_loss: 1087.6849263509 - val_landmark_loss: 1.0215380838 - val_labeled_loss: 1.0215380838 |███████████████████-| 97.0%  - val_loss: 1093.5356140137 - val_trvae_loss: 1092.4734191895 - val_landmark_loss: 1.0621975164 - val_labeled_loss: 1.0621975164 |███████████████████-| 98.0%  - val_loss: 1089.6381022135 - val_trvae_loss: 1088.7263590495 - val_landmark_loss: 0.9117382094 - val_labeled_loss: 0.9117382094 |███████████████████-| 99.0%  - val_loss: 1091.3536783854 - val_trvae_loss: 1090.3918050130 - val_landmark_loss: 0.9618829290 - val_labeled_loss: 0.9618829290 |████████████████████| 100.0%  - val_loss: 1090.8452860514 - val_trvae_loss: 1089.9648234049 - val_landmark_loss: 0.8804696426 - val_labeled_loss: 0.8804696426
2022-05-19 14:17:22 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 1937 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

8
loaders init
loaders init done
0.012012243270874023
 |--------------------| 1.0%  - val_loss: 990.5757751465 - val_trvae_loss: 990.5757751465 |--------------------| 2.0%  - val_loss: 998.1742553711 - val_trvae_loss: 998.1742553711 |--------------------| 3.0%  - val_loss: 998.4617614746 - val_trvae_loss: 998.4617614746 |--------------------| 4.0%  - val_loss: 989.7403564453 - val_trvae_loss: 989.7403564453 |█-------------------| 5.0%  - val_loss: 979.0588684082 - val_trvae_loss: 979.0588684082 |█-------------------| 6.0%  - val_loss: 975.2140197754 - val_trvae_loss: 975.2140197754 |█-------------------| 7.0%  - val_loss: 964.7554931641 - val_trvae_loss: 964.7554931641 |█-------------------| 8.0%  - val_loss: 981.3320007324 - val_trvae_loss: 981.3320007324 |█-------------------| 9.0%  - val_loss: 969.8200378418 - val_trvae_loss: 969.8200378418 |██------------------| 10.0%  - val_loss: 965.8501586914 - val_trvae_loss: 965.8501586914 |██------------------| 11.0%  - val_loss: 965.8444519043 - val_trvae_loss: 965.8444519043 |██------------------| 12.0%  - val_loss: 973.0009765625 - val_trvae_loss: 973.0009765625 |██------------------| 13.0%  - val_loss: 971.1421203613 - val_trvae_loss: 971.1421203613 |██------------------| 14.0%  - val_loss: 962.3937988281 - val_trvae_loss: 962.3937988281 |███-----------------| 15.0%  - val_loss: 968.6341857910 - val_trvae_loss: 968.6341857910 |███-----------------| 16.0%  - val_loss: 966.0823364258 - val_trvae_loss: 966.0823364258 |███-----------------| 17.0%  - val_loss: 968.5374450684 - val_trvae_loss: 968.5374450684 |███-----------------| 18.0%  - val_loss: 968.9925537109 - val_trvae_loss: 968.9925537109 |███-----------------| 19.0%  - val_loss: 968.9312438965 - val_trvae_loss: 968.9312438965 |████----------------| 20.0%  - val_loss: 963.7871093750 - val_trvae_loss: 963.7871093750 |████----------------| 21.0%  - val_loss: 967.8796386719 - val_trvae_loss: 967.8796386719 |████----------------| 22.0%  - val_loss: 968.3015747070 - val_trvae_loss: 968.3015747070 |████----------------| 23.0%  - val_loss: 968.5679321289 - val_trvae_loss: 968.5679321289 |████----------------| 24.0%  - val_loss: 969.4152221680 - val_trvae_loss: 969.4152221680 |█████---------------| 25.0%  - val_loss: 964.4757995605 - val_trvae_loss: 964.4757995605 |█████---------------| 26.0%  - val_loss: 958.4267272949 - val_trvae_loss: 958.4267272949 |█████---------------| 27.0%  - val_loss: 965.3167419434 - val_trvae_loss: 965.3167419434 |█████---------------| 28.0%  - val_loss: 963.2833557129 - val_trvae_loss: 963.2833557129 |█████---------------| 29.0%  - val_loss: 964.1969299316 - val_trvae_loss: 964.1969299316 |██████--------------| 30.0%  - val_loss: 971.8764343262 - val_trvae_loss: 971.8764343262 |██████--------------| 31.0%  - val_loss: 955.4567871094 - val_trvae_loss: 955.4567871094 |██████--------------| 32.0%  - val_loss: 968.1976013184 - val_trvae_loss: 968.1976013184 |██████--------------| 33.0%  - val_loss: 960.4743652344 - val_trvae_loss: 960.4743652344 |██████--------------| 34.0%  - val_loss: 970.4634094238 - val_trvae_loss: 970.4634094238 |███████-------------| 35.0%  - val_loss: 966.2644348145 - val_trvae_loss: 966.2644348145 |███████-------------| 36.0%  - val_loss: 967.0593872070 - val_trvae_loss: 967.0593872070 |███████-------------| 37.0%  - val_loss: 961.7837524414 - val_trvae_loss: 961.7837524414 |███████-------------| 38.0%  - val_loss: 971.3776550293 - val_trvae_loss: 971.3776550293 |███████-------------| 39.0%  - val_loss: 962.5398864746 - val_trvae_loss: 962.5398864746 |████████------------| 40.0%  - val_loss: 962.8243408203 - val_trvae_loss: 962.8243408203 |████████------------| 41.0%  - val_loss: 962.8285827637 - val_trvae_loss: 962.8285827637 |████████------------| 42.0%  - val_loss: 946.7035827637 - val_trvae_loss: 946.7035827637 |████████------------| 43.0%  - val_loss: 962.2713623047 - val_trvae_loss: 962.2713623047 |████████------------| 44.0%  - val_loss: 964.4825439453 - val_trvae_loss: 964.4825439453 |█████████-----------| 45.0%  - val_loss: 955.2520141602 - val_trvae_loss: 955.2520141602 |█████████-----------| 46.0%  - val_loss: 959.4308776855 - val_trvae_loss: 959.4308776855 |█████████-----------| 47.0%  - val_loss: 957.4063720703 - val_trvae_loss: 957.4063720703 |█████████-----------| 48.0%  - val_loss: 957.6828002930 - val_trvae_loss: 957.6828002930 |█████████-----------| 49.0%  - val_loss: 954.8328247070 - val_trvae_loss: 954.8328247070 |██████████----------| 50.0%  - val_loss: 957.7786254883 - val_trvae_loss: 957.7786254883 |██████████----------| 51.0%  - val_loss: 961.0013427734 - val_trvae_loss: 961.0013427734 |██████████----------| 52.0%  - val_loss: 954.5650634766 - val_trvae_loss: 954.5650634766 |██████████----------| 53.0%  - val_loss: 951.2328186035 - val_trvae_loss: 951.2328186035 |██████████----------| 54.0%  - val_loss: 959.7894592285 - val_trvae_loss: 959.7894592285 |███████████---------| 55.0%  - val_loss: 962.7277526855 - val_trvae_loss: 962.7277526855 |███████████---------| 56.0%  - val_loss: 961.3779296875 - val_trvae_loss: 961.3779296875 |███████████---------| 57.0%  - val_loss: 958.5146179199 - val_trvae_loss: 958.5146179199 |███████████---------| 58.0%  - val_loss: 963.9467468262 - val_trvae_loss: 963.9467468262 |███████████---------| 59.0%  - val_loss: 967.7774963379 - val_trvae_loss: 967.7774963379 |████████████--------| 60.0%  - val_loss: 963.2438659668 - val_trvae_loss: 963.2438659668 |████████████--------| 61.0%  - val_loss: 961.7046203613 - val_trvae_loss: 961.7046203613 |████████████--------| 62.0%  - val_loss: 971.7534179688 - val_trvae_loss: 971.7534179688 |████████████--------| 63.0%  - val_loss: 964.7806091309 - val_trvae_loss: 964.7806091309 |████████████--------| 64.0%  - val_loss: 959.9401245117 - val_trvae_loss: 959.9401245117 |█████████████-------| 65.0%  - val_loss: 967.2856140137 - val_trvae_loss: 967.2856140137 |█████████████-------| 66.0%  - val_loss: 957.3853454590 - val_trvae_loss: 957.3853454590 |█████████████-------| 67.0%  - val_loss: 948.9237365723 - val_trvae_loss: 948.9237365723 |█████████████-------| 68.0%  - val_loss: 961.2372131348 - val_trvae_loss: 961.2372131348 |█████████████-------| 69.0%  - val_loss: 964.6551208496 - val_trvae_loss: 964.6551208496 |██████████████------| 70.0%  - val_loss: 961.3180236816 - val_trvae_loss: 961.3180236816 |██████████████------| 71.0%  - val_loss: 973.3799743652 - val_trvae_loss: 973.3799743652 |██████████████------| 72.0%  - val_loss: 954.0560607910 - val_trvae_loss: 954.0560607910 |██████████████------| 73.0%  - val_loss: 961.7734680176 - val_trvae_loss: 961.7734680176 |██████████████------| 74.0%  - val_loss: 951.3795471191 - val_trvae_loss: 951.3795471191 |███████████████-----| 75.0%  - val_loss: 971.0519104004 - val_trvae_loss: 971.0519104004 |███████████████-----| 76.0%  - val_loss: 963.1972961426 - val_trvae_loss: 963.1972961426 |███████████████-----| 77.0%  - val_loss: 966.0012817383 - val_trvae_loss: 966.0012817383 |███████████████-----| 78.0%  - val_loss: 964.6604309082 - val_trvae_loss: 964.6604309082 |███████████████-----| 79.0%  - val_loss: 953.4910888672 - val_trvae_loss: 953.4910888672 |████████████████----| 80.0%  - val_loss: 962.5163879395 - val_trvae_loss: 962.5163879395
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 14 clusters.
 |████████████████----| 81.0%  - val_loss: 961.3497314453 - val_trvae_loss: 961.3496398926 - val_landmark_loss: 0.0001006873 - val_unlabeled_loss: 0.1006873399 |████████████████----| 82.0%  - val_loss: 969.2503662109 - val_trvae_loss: 969.2502441406 - val_landmark_loss: 0.0001010961 - val_unlabeled_loss: 0.1010960788 |████████████████----| 83.0%  - val_loss: 953.1409606934 - val_trvae_loss: 953.1408691406 - val_landmark_loss: 0.0000845245 - val_unlabeled_loss: 0.0845245458 |████████████████----| 84.0%  - val_loss: 951.1524353027 - val_trvae_loss: 951.1523437500 - val_landmark_loss: 0.0000909528 - val_unlabeled_loss: 0.0909528434 |█████████████████---| 85.0%  - val_loss: 968.4746398926 - val_trvae_loss: 968.4745483398 - val_landmark_loss: 0.0000916903 - val_unlabeled_loss: 0.0916902721 |█████████████████---| 86.0%  - val_loss: 957.8289794922 - val_trvae_loss: 957.8288574219 - val_landmark_loss: 0.0000982896 - val_unlabeled_loss: 0.0982895531 |█████████████████---| 87.0%  - val_loss: 955.6139526367 - val_trvae_loss: 955.6138610840 - val_landmark_loss: 0.0000935153 - val_unlabeled_loss: 0.0935153030 |█████████████████---| 88.0%  - val_loss: 963.1208190918 - val_trvae_loss: 963.1207275391 - val_landmark_loss: 0.0000976822 - val_unlabeled_loss: 0.0976822115 |█████████████████---| 89.0%  - val_loss: 973.6814880371 - val_trvae_loss: 973.6813964844 - val_landmark_loss: 0.0001160325 - val_unlabeled_loss: 0.1160324588 |██████████████████--| 90.0%  - val_loss: 946.9517211914 - val_trvae_loss: 946.9516296387 - val_landmark_loss: 0.0001083490 - val_unlabeled_loss: 0.1083489768 |██████████████████--| 91.0%  - val_loss: 964.5319213867 - val_trvae_loss: 964.5318298340 - val_landmark_loss: 0.0001055155 - val_unlabeled_loss: 0.1055154651 |██████████████████--| 92.0%  - val_loss: 955.4395751953 - val_trvae_loss: 955.4394836426 - val_landmark_loss: 0.0001136066 - val_unlabeled_loss: 0.1136065908 |██████████████████--| 93.0%  - val_loss: 956.4567871094 - val_trvae_loss: 956.4566955566 - val_landmark_loss: 0.0000920019 - val_unlabeled_loss: 0.0920018740 |██████████████████--| 94.0%  - val_loss: 949.6893615723 - val_trvae_loss: 949.6892395020 - val_landmark_loss: 0.0000957505 - val_unlabeled_loss: 0.0957504474 |███████████████████-| 95.0%  - val_loss: 956.7413635254 - val_trvae_loss: 956.7412719727 - val_landmark_loss: 0.0000967338 - val_unlabeled_loss: 0.0967338085 |███████████████████-| 96.0%  - val_loss: 957.1319580078 - val_trvae_loss: 957.1318664551 - val_landmark_loss: 0.0000986064 - val_unlabeled_loss: 0.0986064300 |███████████████████-| 97.0%  - val_loss: 964.6456604004 - val_trvae_loss: 964.6455688477 - val_landmark_loss: 0.0000917322 - val_unlabeled_loss: 0.0917321667 |███████████████████-| 98.0%  - val_loss: 957.8588562012 - val_trvae_loss: 957.8587646484 - val_landmark_loss: 0.0000887366 - val_unlabeled_loss: 0.0887366012 |███████████████████-| 99.0%  - val_loss: 964.0466308594 - val_trvae_loss: 964.0465087891 - val_landmark_loss: 0.0000981324 - val_unlabeled_loss: 0.0981323868 |████████████████████| 100.0%  - val_loss: 957.6351318359 - val_trvae_loss: 957.6350402832 - val_landmark_loss: 0.0000941670 - val_unlabeled_loss: 0.0941670313
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 14:17:46 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2022-05-19 14:17:47 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
Saving best state of network...
Best State was in Epoch 82
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2022-05-19 14:20:33 (ERROR): Failed after 0:05:10!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/tmp/3670/uncertainty/uncertainty_seml.py", line 252, in run
    rmtree(REF_PATH)
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 699, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 697, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/storage/groups/ml01/workspace/carlo.dedonno/lataq_reproduce/tmp/ref_model_embedcvae_3'

