Starting job 8135132
SLURM assigned me the node(s): supergpu05
Experiments are running under the following process IDs:
Experiment ID: 2	Process ID: 97740

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 13:55:08 (INFO): Running command 'run'
2022-05-19 13:55:08 (INFO): Started run with ID "2"
2022-05-19 13:55:09 (INFO): Data loaded succesfully
2022-05-19 13:55:09 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.5614237785339355
 |--------------------| 1.0%  - val_loss: 1457.9184909397 - val_trvae_loss: 1457.9184909397 |--------------------| 2.0%  - val_loss: 1435.4941338433 - val_trvae_loss: 1435.4941338433 |--------------------| 3.0%  - val_loss: 1407.2016669379 - val_trvae_loss: 1407.2016669379 |--------------------| 4.0%  - val_loss: 1395.9402058919 - val_trvae_loss: 1395.9402058919 |█-------------------| 5.0%  - val_loss: 1387.0105929905 - val_trvae_loss: 1387.0105929905 |█-------------------| 6.0%  - val_loss: 1382.5042521159 - val_trvae_loss: 1382.5042521159 |█-------------------| 7.0%  - val_loss: 1376.8747626411 - val_trvae_loss: 1376.8747626411 |█-------------------| 8.0%  - val_loss: 1371.9981825087 - val_trvae_loss: 1371.9981825087 |█-------------------| 9.0%  - val_loss: 1367.9942220052 - val_trvae_loss: 1367.9942220052 |██------------------| 10.0%  - val_loss: 1365.4681193034 - val_trvae_loss: 1365.4681193034 |██------------------| 11.0%  - val_loss: 1366.5061577691 - val_trvae_loss: 1366.5061577691 |██------------------| 12.0%  - val_loss: 1361.8708970812 - val_trvae_loss: 1361.8708970812 |██------------------| 13.0%  - val_loss: 1359.9082845052 - val_trvae_loss: 1359.9082845052 |██------------------| 14.0%  - val_loss: 1356.6299641927 - val_trvae_loss: 1356.6299641927 |███-----------------| 15.0%  - val_loss: 1356.1933186849 - val_trvae_loss: 1356.1933186849 |███-----------------| 16.0%  - val_loss: 1355.8707411024 - val_trvae_loss: 1355.8707411024 |███-----------------| 17.0%  - val_loss: 1354.0006374783 - val_trvae_loss: 1354.0006374783 |███-----------------| 18.0%  - val_loss: 1354.0904337565 - val_trvae_loss: 1354.0904337565 |███-----------------| 19.0%  - val_loss: 1352.8636813694 - val_trvae_loss: 1352.8636813694 |████----------------| 20.0%  - val_loss: 1352.3284708659 - val_trvae_loss: 1352.3284708659 |████----------------| 21.0%  - val_loss: 1351.9328477648 - val_trvae_loss: 1351.9328477648 |████----------------| 22.0%  - val_loss: 1351.2732137044 - val_trvae_loss: 1351.2732137044 |████----------------| 23.0%  - val_loss: 1351.1778564453 - val_trvae_loss: 1351.1778564453 |████----------------| 24.0%  - val_loss: 1350.2553846571 - val_trvae_loss: 1350.2553846571 |█████---------------| 25.0%  - val_loss: 1350.8541124132 - val_trvae_loss: 1350.8541124132 |█████---------------| 26.0%  - val_loss: 1349.0590277778 - val_trvae_loss: 1349.0590277778 |█████---------------| 27.0%  - val_loss: 1349.1459011502 - val_trvae_loss: 1349.1459011502 |█████---------------| 28.0%  - val_loss: 1348.3640068902 - val_trvae_loss: 1348.3640068902 |█████---------------| 29.0%  - val_loss: 1350.5286051432 - val_trvae_loss: 1350.5286051432 |██████--------------| 30.0%  - val_loss: 1348.8036024306 - val_trvae_loss: 1348.8036024306 |██████--------------| 31.0%  - val_loss: 1348.0581325955 - val_trvae_loss: 1348.0581325955 |██████--------------| 32.0%  - val_loss: 1348.3372260200 - val_trvae_loss: 1348.3372260200 |██████--------------| 33.0%  - val_loss: 1347.8957451714 - val_trvae_loss: 1347.8957451714 |██████--------------| 34.0%  - val_loss: 1347.9523993598 - val_trvae_loss: 1347.9523993598 |███████-------------| 35.0%  - val_loss: 1347.7614407010 - val_trvae_loss: 1347.7614407010 |███████-------------| 36.0%  - val_loss: 1347.2960408529 - val_trvae_loss: 1347.2960408529 |███████-------------| 37.0%  - val_loss: 1348.9440375434 - val_trvae_loss: 1348.9440375434 |███████-------------| 38.0%  - val_loss: 1346.9360690647 - val_trvae_loss: 1346.9360690647 |███████-------------| 39.0%  - val_loss: 1348.5615641276 - val_trvae_loss: 1348.5615641276 |████████------------| 40.0%  - val_loss: 1345.8401828342 - val_trvae_loss: 1345.8401828342 |████████------------| 41.0%  - val_loss: 1347.1988593207 - val_trvae_loss: 1347.1988593207 |████████------------| 42.0%  - val_loss: 1346.6454399957 - val_trvae_loss: 1346.6454399957 |████████------------| 43.0%  - val_loss: 1346.3910115560 - val_trvae_loss: 1346.3910115560 |████████------------| 44.0%  - val_loss: 1345.7961832682 - val_trvae_loss: 1345.7961832682 |█████████-----------| 45.0%  - val_loss: 1348.4384223090 - val_trvae_loss: 1348.4384223090 |█████████-----------| 46.0%  - val_loss: 1345.7956610786 - val_trvae_loss: 1345.7956610786 |█████████-----------| 47.0%  - val_loss: 1344.5992567274 - val_trvae_loss: 1344.5992567274 |█████████-----------| 48.0%  - val_loss: 1346.7631496853 - val_trvae_loss: 1346.7631496853 |█████████-----------| 49.0%  - val_loss: 1346.8076850043 - val_trvae_loss: 1346.8076850043 |██████████----------| 50.0%  - val_loss: 1345.2040269640 - val_trvae_loss: 1345.2040269640 |██████████----------| 51.0%  - val_loss: 1345.2801310221 - val_trvae_loss: 1345.2801310221 |██████████----------| 52.0%  - val_loss: 1345.7105305990 - val_trvae_loss: 1345.7105305990 |██████████----------| 53.0%  - val_loss: 1346.1226874457 - val_trvae_loss: 1346.1226874457 |██████████----------| 54.0%  - val_loss: 1346.1725192600 - val_trvae_loss: 1346.1725192600 |███████████---------| 55.0%  - val_loss: 1345.2670220269 - val_trvae_loss: 1345.2670220269 |███████████---------| 56.0%  - val_loss: 1346.6030069987 - val_trvae_loss: 1346.6030069987 |███████████---------| 57.0%  - val_loss: 1346.5003323025 - val_trvae_loss: 1346.5003323025 |███████████---------| 58.0%  - val_loss: 1345.0545789931 - val_trvae_loss: 1345.0545789931 |███████████---------| 59.0%  - val_loss: 1346.3013644748 - val_trvae_loss: 1346.3013644748 |████████████--------| 60.0%  - val_loss: 1347.3971354167 - val_trvae_loss: 1347.3971354167 |████████████--------| 61.0%  - val_loss: 1346.5312703451 - val_trvae_loss: 1346.5312703451 |████████████--------| 62.0%  - val_loss: 1345.0456203885 - val_trvae_loss: 1345.0456203885 |████████████--------| 63.0%  - val_loss: 1344.5570000543 - val_trvae_loss: 1344.5570000543 |████████████--------| 64.0%  - val_loss: 1345.2718777127 - val_trvae_loss: 1345.2718777127 |█████████████-------| 65.0%  - val_loss: 1344.4772067600 - val_trvae_loss: 1344.4772067600 |█████████████-------| 66.0%  - val_loss: 1345.0535210503 - val_trvae_loss: 1345.0535210503 |█████████████-------| 67.0%  - val_loss: 1344.9401041667 - val_trvae_loss: 1344.9401041667 |█████████████-------| 68.0%  - val_loss: 1344.6550089518 - val_trvae_loss: 1344.6550089518 |█████████████-------| 69.0%  - val_loss: 1345.4685329861 - val_trvae_loss: 1345.4685329861 |██████████████------| 70.0%  - val_loss: 1344.4853651259 - val_trvae_loss: 1344.4853651259 |██████████████------| 71.0%  - val_loss: 1345.7232259115 - val_trvae_loss: 1345.7232259115 |██████████████------| 72.0%  - val_loss: 1344.2971937391 - val_trvae_loss: 1344.2971937391 |██████████████------| 73.0%  - val_loss: 1345.2609727648 - val_trvae_loss: 1345.2609727648 |██████████████------| 74.0%  - val_loss: 1343.7904730903 - val_trvae_loss: 1343.7904730903 |███████████████-----| 75.0%  - val_loss: 1344.5807902018 - val_trvae_loss: 1344.5807902018 |███████████████-----| 76.0%  - val_loss: 1345.7321709527 - val_trvae_loss: 1345.7321709527 |███████████████-----| 77.0%  - val_loss: 1343.9548407661 - val_trvae_loss: 1343.9548407661 |███████████████-----| 78.0%  - val_loss: 1344.2058308919 - val_trvae_loss: 1344.2058308919 |███████████████-----| 79.0%  - val_loss: 1344.1663953993 - val_trvae_loss: 1344.1663953993 |████████████████----| 80.0%  - val_loss: 1350.1975233290 - val_trvae_loss: 1350.1975233290 |████████████████----| 81.0%  - val_loss: 1355.1786702474 - val_trvae_loss: 1349.3089463976 - val_landmark_loss: 5.8697315057 - val_labeled_loss: 5.8697315057 |████████████████----| 82.0%  - val_loss: 1351.8827718099 - val_trvae_loss: 1347.5048963759 - val_landmark_loss: 4.3778714604 - val_labeled_loss: 4.3778714604 |████████████████----| 83.0%  - val_loss: 1349.5619099935 - val_trvae_loss: 1346.0081380208 - val_landmark_loss: 3.5537872712 - val_labeled_loss: 3.5537872712 |████████████████----| 84.0%  - val_loss: 1349.9398871528 - val_trvae_loss: 1346.9467434353 - val_landmark_loss: 2.9931429492 - val_labeled_loss: 2.9931429492 |█████████████████---| 85.0%  - val_loss: 1350.7083740234 - val_trvae_loss: 1347.8965318468 - val_landmark_loss: 2.8118348387 - val_labeled_loss: 2.8118348387 |█████████████████---| 86.0%  - val_loss: 1348.0095825195 - val_trvae_loss: 1345.5992567274 - val_landmark_loss: 2.4103138182 - val_labeled_loss: 2.4103138182 |█████████████████---| 87.0%  - val_loss: 1348.8372938368 - val_trvae_loss: 1346.4201931424 - val_landmark_loss: 2.4171011845 - val_labeled_loss: 2.4171011845 |█████████████████---| 88.0%  - val_loss: 1348.0364922418 - val_trvae_loss: 1345.8974338108 - val_landmark_loss: 2.1390607821 - val_labeled_loss: 2.1390607821 |█████████████████---| 89.0%  - val_loss: 1348.4454074436 - val_trvae_loss: 1346.4876369900 - val_landmark_loss: 1.9577824043 - val_labeled_loss: 1.9577824043 |██████████████████--| 90.0%  - val_loss: 1348.2566121419 - val_trvae_loss: 1346.3279418945 - val_landmark_loss: 1.9286695056 - val_labeled_loss: 1.9286695056 |██████████████████--| 91.0%  - val_loss: 1347.7813313802 - val_trvae_loss: 1346.1471625434 - val_landmark_loss: 1.6341725157 - val_labeled_loss: 1.6341725157 |██████████████████--| 92.0%  - val_loss: 1347.2929755317 - val_trvae_loss: 1345.5969102648 - val_landmark_loss: 1.6960607900 - val_labeled_loss: 1.6960607900 |██████████████████--| 93.0%  - val_loss: 1347.4852498372 - val_trvae_loss: 1346.0875718859 - val_landmark_loss: 1.3976713220 - val_labeled_loss: 1.3976713220 |██████████████████--| 94.0%  - val_loss: 1346.3772650825 - val_trvae_loss: 1345.0681762695 - val_landmark_loss: 1.3090721071 - val_labeled_loss: 1.3090721071 |███████████████████-| 95.0%  - val_loss: 1347.7968410916 - val_trvae_loss: 1346.2810804579 - val_landmark_loss: 1.5157741374 - val_labeled_loss: 1.5157741374 |███████████████████-| 96.0%  - val_loss: 1347.9730495877 - val_trvae_loss: 1346.4982164171 - val_landmark_loss: 1.4748356938 - val_labeled_loss: 1.4748356938 |███████████████████-| 97.0%  - val_loss: 1347.2516004774 - val_trvae_loss: 1345.9376220703 - val_landmark_loss: 1.3139872783 - val_labeled_loss: 1.3139872783 |███████████████████-| 98.0%  - val_loss: 1346.7587551541 - val_trvae_loss: 1345.3214179145 - val_landmark_loss: 1.4373301003 - val_labeled_loss: 1.4373301003 |███████████████████-| 99.0%  - val_loss: 1345.6677246094 - val_trvae_loss: 1344.4786851671 - val_landmark_loss: 1.1890352733 - val_labeled_loss: 1.1890352733 |████████████████████| 100.0%  - val_loss: 1346.2197740343 - val_trvae_loss: 1345.1062486437 - val_landmark_loss: 1.1135339373 - val_labeled_loss: 1.1135339373
2022-05-19 13:58:02 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 9581 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

3
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
loaders init
loaders init done
0.1333150863647461
 |--------------------| 1.0%  - val_loss: 1417.9341125488 - val_trvae_loss: 1417.9341125488 |--------------------| 2.0%  - val_loss: 1401.2982177734 - val_trvae_loss: 1401.2982177734 |--------------------| 3.0%  - val_loss: 1379.0445251465 - val_trvae_loss: 1379.0445251465 |--------------------| 4.0%  - val_loss: 1376.6772308350 - val_trvae_loss: 1376.6772308350 |█-------------------| 5.0%  - val_loss: 1375.9714050293 - val_trvae_loss: 1375.9714050293 |█-------------------| 6.0%  - val_loss: 1345.8626403809 - val_trvae_loss: 1345.8626403809 |█-------------------| 7.0%  - val_loss: 1345.4570465088 - val_trvae_loss: 1345.4570465088 |█-------------------| 8.0%  - val_loss: 1339.1299591064 - val_trvae_loss: 1339.1299591064 |█-------------------| 9.0%  - val_loss: 1341.4455566406 - val_trvae_loss: 1341.4455566406 |██------------------| 10.0%  - val_loss: 1347.8390960693 - val_trvae_loss: 1347.8390960693 |██------------------| 11.0%  - val_loss: 1332.6054382324 - val_trvae_loss: 1332.6054382324 |██------------------| 12.0%  - val_loss: 1327.1629333496 - val_trvae_loss: 1327.1629333496 |██------------------| 13.0%  - val_loss: 1316.1526641846 - val_trvae_loss: 1316.1526641846 |██------------------| 14.0%  - val_loss: 1323.0201110840 - val_trvae_loss: 1323.0201110840 |███-----------------| 15.0%  - val_loss: 1307.9870605469 - val_trvae_loss: 1307.9870605469 |███-----------------| 16.0%  - val_loss: 1304.1737976074 - val_trvae_loss: 1304.1737976074 |███-----------------| 17.0%  - val_loss: 1285.4076232910 - val_trvae_loss: 1285.4076232910 |███-----------------| 18.0%  - val_loss: 1285.7911376953 - val_trvae_loss: 1285.7911376953 |███-----------------| 19.0%  - val_loss: 1278.5736236572 - val_trvae_loss: 1278.5736236572 |████----------------| 20.0%  - val_loss: 1280.8317565918 - val_trvae_loss: 1280.8317565918 |████----------------| 21.0%  - val_loss: 1290.5327758789 - val_trvae_loss: 1290.5327758789 |████----------------| 22.0%  - val_loss: 1282.2689666748 - val_trvae_loss: 1282.2689666748 |████----------------| 23.0%  - val_loss: 1282.2946624756 - val_trvae_loss: 1282.2946624756 |████----------------| 24.0%  - val_loss: 1282.5741882324 - val_trvae_loss: 1282.5741882324 |█████---------------| 25.0%  - val_loss: 1266.2278442383 - val_trvae_loss: 1266.2278442383 |█████---------------| 26.0%  - val_loss: 1261.9481964111 - val_trvae_loss: 1261.9481964111 |█████---------------| 27.0%  - val_loss: 1266.1578826904 - val_trvae_loss: 1266.1578826904 |█████---------------| 28.0%  - val_loss: 1268.6924438477 - val_trvae_loss: 1268.6924438477 |█████---------------| 29.0%  - val_loss: 1251.6165313721 - val_trvae_loss: 1251.6165313721 |██████--------------| 30.0%  - val_loss: 1253.9248046875 - val_trvae_loss: 1253.9248046875 |██████--------------| 31.0%  - val_loss: 1256.2655487061 - val_trvae_loss: 1256.2655487061 |██████--------------| 32.0%  - val_loss: 1259.8198242188 - val_trvae_loss: 1259.8198242188 |██████--------------| 33.0%  - val_loss: 1257.9118804932 - val_trvae_loss: 1257.9118804932 |██████--------------| 34.0%  - val_loss: 1250.1446075439 - val_trvae_loss: 1250.1446075439 |███████-------------| 35.0%  - val_loss: 1245.3884887695 - val_trvae_loss: 1245.3884887695 |███████-------------| 36.0%  - val_loss: 1244.6779785156 - val_trvae_loss: 1244.6779785156 |███████-------------| 37.0%  - val_loss: 1242.0292968750 - val_trvae_loss: 1242.0292968750 |███████-------------| 38.0%  - val_loss: 1238.3668212891 - val_trvae_loss: 1238.3668212891 |███████-------------| 39.0%  - val_loss: 1236.2440490723 - val_trvae_loss: 1236.2440490723 |████████------------| 40.0%  - val_loss: 1228.4092102051 - val_trvae_loss: 1228.4092102051 |████████------------| 41.0%  - val_loss: 1224.2741394043 - val_trvae_loss: 1224.2741394043 |████████------------| 42.0%  - val_loss: 1229.9444427490 - val_trvae_loss: 1229.9444427490 |████████------------| 43.0%  - val_loss: 1230.3708801270 - val_trvae_loss: 1230.3708801270 |████████------------| 44.0%  - val_loss: 1229.9709320068 - val_trvae_loss: 1229.9709320068 |█████████-----------| 45.0%  - val_loss: 1231.1212158203 - val_trvae_loss: 1231.1212158203 |█████████-----------| 46.0%  - val_loss: 1221.2188568115 - val_trvae_loss: 1221.2188568115 |█████████-----------| 47.0%  - val_loss: 1221.6715087891 - val_trvae_loss: 1221.6715087891 |█████████-----------| 48.0%  - val_loss: 1224.9078369141 - val_trvae_loss: 1224.9078369141 |█████████-----------| 49.0%  - val_loss: 1218.9527893066 - val_trvae_loss: 1218.9527893066 |██████████----------| 50.0%  - val_loss: 1223.5112457275 - val_trvae_loss: 1223.5112457275 |██████████----------| 51.0%  - val_loss: 1217.2830657959 - val_trvae_loss: 1217.2830657959 |██████████----------| 52.0%  - val_loss: 1223.8530120850 - val_trvae_loss: 1223.8530120850 |██████████----------| 53.0%  - val_loss: 1214.7442474365 - val_trvae_loss: 1214.7442474365 |██████████----------| 54.0%  - val_loss: 1219.3994293213 - val_trvae_loss: 1219.3994293213 |███████████---------| 55.0%  - val_loss: 1206.3217010498 - val_trvae_loss: 1206.3217010498 |███████████---------| 56.0%  - val_loss: 1215.4757995605 - val_trvae_loss: 1215.4757995605 |███████████---------| 57.0%  - val_loss: 1220.0116271973 - val_trvae_loss: 1220.0116271973 |███████████---------| 58.0%  - val_loss: 1215.6385955811 - val_trvae_loss: 1215.6385955811 |███████████---------| 59.0%  - val_loss: 1205.6937255859 - val_trvae_loss: 1205.6937255859 |████████████--------| 60.0%  - val_loss: 1215.7524414062 - val_trvae_loss: 1215.7524414062 |████████████--------| 61.0%  - val_loss: 1206.1674499512 - val_trvae_loss: 1206.1674499512 |████████████--------| 62.0%  - val_loss: 1216.7475738525 - val_trvae_loss: 1216.7475738525 |████████████--------| 63.0%  - val_loss: 1203.1790466309 - val_trvae_loss: 1203.1790466309 |████████████--------| 64.0%  - val_loss: 1209.4925231934 - val_trvae_loss: 1209.4925231934 |█████████████-------| 65.0%  - val_loss: 1206.3575439453 - val_trvae_loss: 1206.3575439453 |█████████████-------| 66.0%  - val_loss: 1210.1248626709 - val_trvae_loss: 1210.1248626709 |█████████████-------| 67.0%  - val_loss: 1207.5773010254 - val_trvae_loss: 1207.5773010254 |█████████████-------| 68.0%  - val_loss: 1206.1496429443 - val_trvae_loss: 1206.1496429443 |█████████████-------| 69.0%  - val_loss: 1200.8811187744 - val_trvae_loss: 1200.8811187744 |██████████████------| 70.0%  - val_loss: 1198.9344635010 - val_trvae_loss: 1198.9344635010 |██████████████------| 71.0%  - val_loss: 1203.8402404785 - val_trvae_loss: 1203.8402404785 |██████████████------| 72.0%  - val_loss: 1205.6811218262 - val_trvae_loss: 1205.6811218262 |██████████████------| 73.0%  - val_loss: 1200.6536560059 - val_trvae_loss: 1200.6536560059 |██████████████------| 74.0%  - val_loss: 1200.8630981445 - val_trvae_loss: 1200.8630981445 |███████████████-----| 75.0%  - val_loss: 1195.5557403564 - val_trvae_loss: 1195.5557403564 |███████████████-----| 76.0%  - val_loss: 1197.2499389648 - val_trvae_loss: 1197.2499389648 |███████████████-----| 77.0%  - val_loss: 1196.1792755127 - val_trvae_loss: 1196.1792755127 |███████████████-----| 78.0%  - val_loss: 1200.1289062500 - val_trvae_loss: 1200.1289062500 |███████████████-----| 79.0%  - val_loss: 1190.6807556152 - val_trvae_loss: 1190.6807556152 |████████████████----| 80.0%  - val_loss: 1208.9087982178 - val_trvae_loss: 1208.9087982178
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 20 clusters.
 |████████████████----| 81.0%  - val_loss: 1192.5556793213 - val_trvae_loss: 1192.5554656982 - val_landmark_loss: 0.0002323712 - val_unlabeled_loss: 0.2323711440 |████████████████----| 82.0%  - val_loss: 1191.3497619629 - val_trvae_loss: 1191.3495025635 - val_landmark_loss: 0.0002358354 - val_unlabeled_loss: 0.2358353883 |████████████████----| 83.0%  - val_loss: 1192.2606048584 - val_trvae_loss: 1192.2603759766 - val_landmark_loss: 0.0002289373 - val_unlabeled_loss: 0.2289372738 |████████████████----| 84.0%  - val_loss: 1195.0606994629 - val_trvae_loss: 1195.0605010986 - val_landmark_loss: 0.0002238302 - val_unlabeled_loss: 0.2238302231 |█████████████████---| 85.0%  - val_loss: 1202.8290100098 - val_trvae_loss: 1202.8287658691 - val_landmark_loss: 0.0002335942 - val_unlabeled_loss: 0.2335941866 |█████████████████---| 86.0%  - val_loss: 1197.2455749512 - val_trvae_loss: 1197.2453460693 - val_landmark_loss: 0.0002240673 - val_unlabeled_loss: 0.2240672577 |█████████████████---| 87.0%  - val_loss: 1197.8735046387 - val_trvae_loss: 1197.8732757568 - val_landmark_loss: 0.0002043553 - val_unlabeled_loss: 0.2043552883 |█████████████████---| 88.0%  - val_loss: 1190.5747985840 - val_trvae_loss: 1190.5745849609 - val_landmark_loss: 0.0002239743 - val_unlabeled_loss: 0.2239742987 |█████████████████---| 89.0%  - val_loss: 1198.7651214600 - val_trvae_loss: 1198.7649078369 - val_landmark_loss: 0.0002137737 - val_unlabeled_loss: 0.2137736753 |██████████████████--| 90.0%  - val_loss: 1187.6116790771 - val_trvae_loss: 1187.6114807129 - val_landmark_loss: 0.0002093581 - val_unlabeled_loss: 0.2093580570 |██████████████████--| 91.0%  - val_loss: 1194.0161285400 - val_trvae_loss: 1194.0159301758 - val_landmark_loss: 0.0002165055 - val_unlabeled_loss: 0.2165054977 |██████████████████--| 92.0%  - val_loss: 1188.2686920166 - val_trvae_loss: 1188.2684631348 - val_landmark_loss: 0.0002334884 - val_unlabeled_loss: 0.2334884144 |██████████████████--| 93.0%  - val_loss: 1198.1703491211 - val_trvae_loss: 1198.1701049805 - val_landmark_loss: 0.0002258975 - val_unlabeled_loss: 0.2258975077 |██████████████████--| 94.0%  - val_loss: 1191.8384094238 - val_trvae_loss: 1191.8381958008 - val_landmark_loss: 0.0002221943 - val_unlabeled_loss: 0.2221942879 |███████████████████-| 95.0%  - val_loss: 1201.3623809814 - val_trvae_loss: 1201.3621368408 - val_landmark_loss: 0.0002293998 - val_unlabeled_loss: 0.2293998282 |███████████████████-| 96.0%  - val_loss: 1194.7018890381 - val_trvae_loss: 1194.7016448975 - val_landmark_loss: 0.0002404508 - val_unlabeled_loss: 0.2404508125 |███████████████████-| 97.0%  - val_loss: 1188.2688751221 - val_trvae_loss: 1188.2686309814 - val_landmark_loss: 0.0002238480 - val_unlabeled_loss: 0.2238480076 |███████████████████-| 98.0%  - val_loss: 1198.1889495850 - val_trvae_loss: 1198.1887054443 - val_landmark_loss: 0.0002364560 - val_unlabeled_loss: 0.2364559863 |███████████████████-| 99.0%  - val_loss: 1190.7868804932 - val_trvae_loss: 1190.7866516113 - val_landmark_loss: 0.0002144879 - val_unlabeled_loss: 0.2144878525 |████████████████████| 100.0%  - val_loss: 1195.3838958740 - val_trvae_loss: 1195.3836517334 - val_landmark_loss: 0.0002364355 - val_unlabeled_loss: 0.2364355065
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 13:59:18 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2022-05-19 13:59:19 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2022-05-19 14:17:07 (INFO): Result: {'distances':   condition  cos_dist  eucl_dist
0       10X  1.400811   0.829292
1       Sun  1.216413   0.811549
2   Freytag  0.502195   0.811549
3    Oetjen  0.502195   0.852409, 'classification_report':                                   precision    recall  f1-score    support
CD10+ B cells                      0.000000  0.000000  0.000000    207.000
CD14+ Monocytes                    0.907206  0.987220  0.945523   6338.000
CD16+ Monocytes                    0.980320  0.966061  0.973138    825.000
CD20+ B cells                      0.986454  0.988514  0.987483   2873.000
CD4+ T cells                       0.921750  0.931795  0.926746  11011.000
CD8+ T cells                       0.727070  0.748053  0.737413   2183.000
Erythrocytes                       0.000000  0.000000  0.000000   1502.000
Erythroid progenitors              0.000000  0.000000  0.000000    463.000
HSPCs                              0.217113  0.788584  0.340484    473.000
Megakaryocyte progenitors          0.794118  0.200000  0.319527    270.000
Monocyte progenitors               0.000000  0.000000  0.000000    428.000
Monocyte-derived dendritic cells   0.389167  0.976987  0.556615    478.000
NK cells                           0.889868  0.880558  0.885188   2294.000
NKT cells                          0.833855  0.873953  0.853433   2745.000
Plasma cells                       0.305882  0.201550  0.242991    129.000
Plasmacytoid dendritic cells       0.860000  0.973585  0.913274    265.000
accuracy                           0.843000  0.843000  0.843000      0.843
macro avg                          0.550800  0.594804  0.542613  32484.000
weighted avg                       0.807477  0.843000  0.819074  32484.000, 'classification_report_query':                                   precision    recall  f1-score      support
CD10+ B cells                      0.000000  0.000000  0.000000   207.000000
CD14+ Monocytes                    0.615877  0.964895  0.751856   997.000000
CD16+ Monocytes                    0.970588  1.000000  0.985075   165.000000
CD20+ B cells                      0.925490  0.961303  0.943057   491.000000
CD4+ T cells                       0.739089  0.925911  0.822019  2524.000000
CD8+ T cells                       0.720365  0.481218  0.576993   985.000000
Erythrocytes                       0.000000  0.000000  0.000000  1502.000000
Erythroid progenitors              0.000000  0.000000  0.000000   463.000000
HSPCs                              0.204276  0.773034  0.323156   445.000000
Megakaryocyte progenitors          0.200000  0.013699  0.025641   219.000000
Monocyte progenitors               0.000000  0.000000  0.000000   428.000000
Monocyte-derived dendritic cells   0.233880  1.000000  0.379097   214.000000
NK cells                           0.524390  0.966292  0.679842    89.000000
NKT cells                          0.855750  0.722039  0.783229   608.000000
Plasma cells                       0.126984  0.072072  0.091954   111.000000
Plasmacytoid dendritic cells       0.763636  0.947368  0.845638   133.000000
accuracy                           0.587621  0.587621  0.587621     0.587621
macro avg                          0.430020  0.551740  0.450472  9581.000000
weighted avg                       0.487526  0.587621  0.512287  9581.000000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.814653           0.827455  ...                   0.586193    0.960719

[1 rows x 8 columns]}
Saving best state of network...
Best State was in Epoch 86
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2022-05-19 14:17:07 (INFO): Completed after 0:21:59
