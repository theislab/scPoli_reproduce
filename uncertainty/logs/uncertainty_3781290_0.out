Starting job 3781291
SLURM assigned me the node(s): gpusrv12
Experiments are running under the following process IDs:
Experiment ID: 1	Process ID: 254839

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 11:03:23 (INFO): Running command 'run'
2021-10-26 11:03:23 (INFO): Started run with ID "1"
2021-10-26 11:03:25 (INFO): Data loaded succesfully
2021-10-26 11:03:25 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1263.7325541178 - val_trvae_loss: 1263.7325541178 |--------------------| 2.0%  - val_loss: 1213.4681905111 - val_trvae_loss: 1213.4681905111 |--------------------| 3.0%  - val_loss: 1174.2001546224 - val_trvae_loss: 1174.2001546224 |--------------------| 4.0%  - val_loss: 1153.9938964844 - val_trvae_loss: 1153.9938964844 |█-------------------| 5.0%  - val_loss: 1139.6584676107 - val_trvae_loss: 1139.6584676107 |█-------------------| 6.0%  - val_loss: 1141.9953715007 - val_trvae_loss: 1141.9953715007 |█-------------------| 7.0%  - val_loss: 1132.5376078288 - val_trvae_loss: 1132.5376078288 |█-------------------| 8.0%  - val_loss: 1126.5238647461 - val_trvae_loss: 1126.5238647461 |█-------------------| 9.0%  - val_loss: 1125.5930480957 - val_trvae_loss: 1125.5930480957 |██------------------| 10.0%  - val_loss: 1115.1307271322 - val_trvae_loss: 1115.1307271322 |██------------------| 11.0%  - val_loss: 1112.1803385417 - val_trvae_loss: 1112.1803385417 |██------------------| 12.0%  - val_loss: 1113.8423461914 - val_trvae_loss: 1113.8423461914 |██------------------| 13.0%  - val_loss: 1115.7553710938 - val_trvae_loss: 1115.7553710938 |██------------------| 14.0%  - val_loss: 1106.6477254232 - val_trvae_loss: 1106.6477254232 |███-----------------| 15.0%  - val_loss: 1110.8830057780 - val_trvae_loss: 1110.8830057780 |███-----------------| 16.0%  - val_loss: 1109.5144653320 - val_trvae_loss: 1109.5144653320 |███-----------------| 17.0%  - val_loss: 1099.0303853353 - val_trvae_loss: 1099.0303853353 |███-----------------| 18.0%  - val_loss: 1103.5908203125 - val_trvae_loss: 1103.5908203125 |███-----------------| 19.0%  - val_loss: 1097.4633687337 - val_trvae_loss: 1097.4633687337 |████----------------| 20.0%  - val_loss: 1100.4238382975 - val_trvae_loss: 1100.4238382975 |████----------------| 21.0%  - val_loss: 1100.6619974772 - val_trvae_loss: 1100.6619974772 |████----------------| 22.0%  - val_loss: 1099.4562988281 - val_trvae_loss: 1099.4562988281 |████----------------| 23.0%  - val_loss: 1097.4424641927 - val_trvae_loss: 1097.4424641927 |████----------------| 24.0%  - val_loss: 1092.9849955241 - val_trvae_loss: 1092.9849955241 |█████---------------| 25.0%  - val_loss: 1100.4570109049 - val_trvae_loss: 1100.4570109049 |█████---------------| 26.0%  - val_loss: 1100.5142720540 - val_trvae_loss: 1100.5142720540 |█████---------------| 27.0%  - val_loss: 1099.0388081868 - val_trvae_loss: 1099.0388081868 |█████---------------| 28.0%  - val_loss: 1093.7436421712 - val_trvae_loss: 1093.7436421712 |█████---------------| 29.0%  - val_loss: 1092.1309509277 - val_trvae_loss: 1092.1309509277 |██████--------------| 30.0%  - val_loss: 1092.5582377116 - val_trvae_loss: 1092.5582377116 |██████--------------| 31.0%  - val_loss: 1090.8945515951 - val_trvae_loss: 1090.8945515951 |██████--------------| 32.0%  - val_loss: 1087.0525817871 - val_trvae_loss: 1087.0525817871 |██████--------------| 33.0%  - val_loss: 1089.2254130046 - val_trvae_loss: 1089.2254130046 |██████--------------| 34.0%  - val_loss: 1089.4785156250 - val_trvae_loss: 1089.4785156250 |███████-------------| 35.0%  - val_loss: 1090.0938110352 - val_trvae_loss: 1090.0938110352 |███████-------------| 36.0%  - val_loss: 1090.8128356934 - val_trvae_loss: 1090.8128356934 |███████-------------| 37.0%  - val_loss: 1087.0347086589 - val_trvae_loss: 1087.0347086589 |███████-------------| 38.0%  - val_loss: 1089.9159240723 - val_trvae_loss: 1089.9159240723 |███████-------------| 39.0%  - val_loss: 1091.6607666016 - val_trvae_loss: 1091.6607666016 |████████------------| 40.0%  - val_loss: 1086.2473551432 - val_trvae_loss: 1086.2473551432 |████████------------| 41.0%  - val_loss: 1092.0379638672 - val_trvae_loss: 1092.0379638672 |████████------------| 42.0%  - val_loss: 1089.2633768717 - val_trvae_loss: 1089.2633768717 |████████------------| 43.0%  - val_loss: 1090.1178792318 - val_trvae_loss: 1090.1178792318 |████████------------| 44.0%  - val_loss: 1085.5402018229 - val_trvae_loss: 1085.5402018229 |█████████-----------| 45.0%  - val_loss: 1084.6543477376 - val_trvae_loss: 1084.6543477376 |█████████-----------| 46.0%  - val_loss: 1089.0533040365 - val_trvae_loss: 1089.0533040365 |█████████-----------| 47.0%  - val_loss: 1090.1002095540 - val_trvae_loss: 1090.1002095540 |█████████-----------| 48.0%  - val_loss: 1086.4715627035 - val_trvae_loss: 1086.4715627035 |█████████-----------| 49.0%  - val_loss: 1083.8619079590 - val_trvae_loss: 1083.8619079590 |██████████----------| 50.0%  - val_loss: 1086.1807352702 - val_trvae_loss: 1086.1807352702 |██████████----------| 51.0%  - val_loss: 1089.8254801432 - val_trvae_loss: 1089.8254801432 |██████████----------| 52.0%  - val_loss: 1088.6873881022 - val_trvae_loss: 1088.6873881022 |██████████----------| 53.0%  - val_loss: 1092.4510904948 - val_trvae_loss: 1092.4510904948 |██████████----------| 54.0%  - val_loss: 1079.7438507080 - val_trvae_loss: 1079.7438507080 |███████████---------| 55.0%  - val_loss: 1086.0708719889 - val_trvae_loss: 1086.0708719889 |███████████---------| 56.0%  - val_loss: 1086.8137512207 - val_trvae_loss: 1086.8137512207 |███████████---------| 57.0%  - val_loss: 1087.8407185872 - val_trvae_loss: 1087.8407185872 |███████████---------| 58.0%  - val_loss: 1089.3148396810 - val_trvae_loss: 1089.3148396810 |███████████---------| 59.0%  - val_loss: 1082.5191192627 - val_trvae_loss: 1082.5191192627 |████████████--------| 60.0%  - val_loss: 1089.7505086263 - val_trvae_loss: 1089.7505086263 |████████████--------| 61.0%  - val_loss: 1087.7783813477 - val_trvae_loss: 1087.7783813477 |████████████--------| 62.0%  - val_loss: 1088.9730122884 - val_trvae_loss: 1088.9730122884 |████████████--------| 63.0%  - val_loss: 1087.7211100260 - val_trvae_loss: 1087.7211100260 |████████████--------| 64.0%  - val_loss: 1081.9554748535 - val_trvae_loss: 1081.9554748535 |█████████████-------| 65.0%  - val_loss: 1080.6462300618 - val_trvae_loss: 1080.6462300618 |█████████████-------| 66.0%  - val_loss: 1087.6003875732 - val_trvae_loss: 1087.6003875732 |█████████████-------| 67.0%  - val_loss: 1091.0259399414 - val_trvae_loss: 1091.0259399414 |█████████████-------| 68.0%  - val_loss: 1089.4464416504 - val_trvae_loss: 1089.4464416504 |█████████████-------| 69.0%  - val_loss: 1090.1181030273 - val_trvae_loss: 1090.1181030273 |██████████████------| 70.0%  - val_loss: 1091.1580301921 - val_trvae_loss: 1091.1580301921 |██████████████------| 71.0%  - val_loss: 1089.6798095703 - val_trvae_loss: 1089.6798095703 |██████████████------| 72.0%  - val_loss: 1090.1561381022 - val_trvae_loss: 1090.1561381022 |██████████████------| 73.0%  - val_loss: 1083.5331624349 - val_trvae_loss: 1083.5331624349 |██████████████------| 74.0%  - val_loss: 1086.5339152018 - val_trvae_loss: 1086.5339152018 |███████████████-----| 75.0%  - val_loss: 1087.5467529297 - val_trvae_loss: 1087.5467529297 |███████████████-----| 76.0%  - val_loss: 1084.1544901530 - val_trvae_loss: 1084.1544901530 |███████████████-----| 77.0%  - val_loss: 1084.6026814779 - val_trvae_loss: 1084.6026814779 |███████████████-----| 78.0%  - val_loss: 1084.3012084961 - val_trvae_loss: 1084.3012084961 |███████████████-----| 79.0%  - val_loss: 1084.4335225423 - val_trvae_loss: 1084.4335225423 |████████████████----| 80.0%  - val_loss: 1085.1712443034 - val_trvae_loss: 1085.1712443034 |████████████████----| 81.0%  - val_loss: 1093.4652913411 - val_trvae_loss: 1090.2120259603 - val_landmark_loss: 3.2532626987 - val_labeled_loss: 3.2532626987 |████████████████----| 82.0%  - val_loss: 1089.6701660156 - val_trvae_loss: 1087.5436299642 - val_landmark_loss: 2.1265374720 - val_labeled_loss: 2.1265374720 |████████████████----| 83.0%  - val_loss: 1091.7375081380 - val_trvae_loss: 1089.9364522298 - val_landmark_loss: 1.8010548254 - val_labeled_loss: 1.8010548254 |████████████████----| 84.0%  - val_loss: 1088.0737406413 - val_trvae_loss: 1086.3980102539 - val_landmark_loss: 1.6757077277 - val_labeled_loss: 1.6757077277 |█████████████████---| 85.0%  - val_loss: 1089.5861256917 - val_trvae_loss: 1088.0238494873 - val_landmark_loss: 1.5622763832 - val_labeled_loss: 1.5622763832 |█████████████████---| 86.0%  - val_loss: 1086.7312418620 - val_trvae_loss: 1085.4150390625 - val_landmark_loss: 1.3162047615 - val_labeled_loss: 1.3162047615 |█████████████████---| 87.0%  - val_loss: 1084.8757120768 - val_trvae_loss: 1083.5398559570 - val_landmark_loss: 1.3358511875 - val_labeled_loss: 1.3358511875 |█████████████████---| 88.0%  - val_loss: 1089.6717732747 - val_trvae_loss: 1088.3789978027 - val_landmark_loss: 1.2927700877 - val_labeled_loss: 1.2927700877 |█████████████████---| 89.0%  - val_loss: 1090.2121276855 - val_trvae_loss: 1089.0480957031 - val_landmark_loss: 1.1640336812 - val_labeled_loss: 1.1640336812 |██████████████████--| 90.0%  - val_loss: 1089.0340881348 - val_trvae_loss: 1088.0101725260 - val_landmark_loss: 1.0239152660 - val_labeled_loss: 1.0239152660 |██████████████████--| 91.0%  - val_loss: 1085.6104838053 - val_trvae_loss: 1084.4848531087 - val_landmark_loss: 1.1256466160 - val_labeled_loss: 1.1256466160 |██████████████████--| 92.0%  - val_loss: 1091.8001912435 - val_trvae_loss: 1090.8173980713 - val_landmark_loss: 0.9827935100 - val_labeled_loss: 0.9827935100 |██████████████████--| 93.0%  - val_loss: 1089.5572814941 - val_trvae_loss: 1088.6197306315 - val_landmark_loss: 0.9375536939 - val_labeled_loss: 0.9375536939 |██████████████████--| 94.0%  - val_loss: 1086.1647338867 - val_trvae_loss: 1085.2078857422 - val_landmark_loss: 0.9568502307 - val_labeled_loss: 0.9568502307 |███████████████████-| 95.0%  - val_loss: 1089.4790649414 - val_trvae_loss: 1088.4892985026 - val_landmark_loss: 0.9897650083 - val_labeled_loss: 0.9897650083 |███████████████████-| 96.0%  - val_loss: 1085.6324259440 - val_trvae_loss: 1084.4574178060 - val_landmark_loss: 1.1750076662 - val_labeled_loss: 1.1750076662 |███████████████████-| 97.0%  - val_loss: 1088.7419942220 - val_trvae_loss: 1087.7998250326 - val_landmark_loss: 0.9421706051 - val_labeled_loss: 0.9421706051 |███████████████████-| 98.0%  - val_loss: 1083.4566853841 - val_trvae_loss: 1082.5402323405 - val_landmark_loss: 0.9164525419 - val_labeled_loss: 0.9164525419 |███████████████████-| 99.0%  - val_loss: 1085.6614786784 - val_trvae_loss: 1084.8166707357 - val_landmark_loss: 0.8447930490 - val_labeled_loss: 0.8447930490 |████████████████████| 100.0%  - val_loss: 1082.8431498210 - val_trvae_loss: 1081.9745127360 - val_landmark_loss: 0.8686332305 - val_labeled_loss: 0.8686332305
2021-10-26 11:05:40 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 1937 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1008.7487487793 - val_trvae_loss: 1008.7487487793 |--------------------| 2.0%  - val_loss: 1020.8469543457 - val_trvae_loss: 1020.8469543457 |--------------------| 3.0%  - val_loss: 1025.0917053223 - val_trvae_loss: 1025.0917053223 |--------------------| 4.0%  - val_loss: 1019.0035705566 - val_trvae_loss: 1019.0035705566 |█-------------------| 5.0%  - val_loss: 1010.7133789062 - val_trvae_loss: 1010.7133789062 |█-------------------| 6.0%  - val_loss: 1009.2291259766 - val_trvae_loss: 1009.2291259766 |█-------------------| 7.0%  - val_loss: 1000.0403442383 - val_trvae_loss: 1000.0403442383 |█-------------------| 8.0%  - val_loss: 1019.8309020996 - val_trvae_loss: 1019.8309020996 |█-------------------| 9.0%  - val_loss: 1009.9799804688 - val_trvae_loss: 1009.9799804688 |██------------------| 10.0%  - val_loss: 1006.8113098145 - val_trvae_loss: 1006.8113098145 |██------------------| 11.0%  - val_loss: 1008.5817871094 - val_trvae_loss: 1008.5817871094 |██------------------| 12.0%  - val_loss: 1016.4906311035 - val_trvae_loss: 1016.4906311035 |██------------------| 13.0%  - val_loss: 1014.8919372559 - val_trvae_loss: 1014.8919372559 |██------------------| 14.0%  - val_loss: 1005.8238525391 - val_trvae_loss: 1005.8238525391 |███-----------------| 15.0%  - val_loss: 1012.8366088867 - val_trvae_loss: 1012.8366088867 |███-----------------| 16.0%  - val_loss: 1010.6926879883 - val_trvae_loss: 1010.6926879883 |███-----------------| 17.0%  - val_loss: 1013.3271179199 - val_trvae_loss: 1013.3271179199 |███-----------------| 18.0%  - val_loss: 1015.5690307617 - val_trvae_loss: 1015.5690307617 |███-----------------| 19.0%  - val_loss: 1014.4478149414 - val_trvae_loss: 1014.4478149414 |████----------------| 20.0%  - val_loss: 1009.3431701660 - val_trvae_loss: 1009.3431701660 |████----------------| 21.0%  - val_loss: 1013.9774475098 - val_trvae_loss: 1013.9774475098 |████----------------| 22.0%  - val_loss: 1015.4375610352 - val_trvae_loss: 1015.4375610352 |████----------------| 23.0%  - val_loss: 1014.3708496094 - val_trvae_loss: 1014.3708496094 |████----------------| 24.0%  - val_loss: 1015.8589477539 - val_trvae_loss: 1015.8589477539 |█████---------------| 25.0%  - val_loss: 1010.2751159668 - val_trvae_loss: 1010.2751159668 |█████---------------| 26.0%  - val_loss: 1004.2149353027 - val_trvae_loss: 1004.2149353027 |█████---------------| 27.0%  - val_loss: 1013.0591125488 - val_trvae_loss: 1013.0591125488 |█████---------------| 28.0%  - val_loss: 1009.6842041016 - val_trvae_loss: 1009.6842041016 |█████---------------| 29.0%  - val_loss: 1011.1761779785 - val_trvae_loss: 1011.1761779785 |██████--------------| 30.0%  - val_loss: 1019.2977600098 - val_trvae_loss: 1019.2977600098 |██████--------------| 31.0%  - val_loss: 1002.3811340332 - val_trvae_loss: 1002.3811340332 |██████--------------| 32.0%  - val_loss: 1015.1566467285 - val_trvae_loss: 1015.1566467285 |██████--------------| 33.0%  - val_loss: 1007.0072631836 - val_trvae_loss: 1007.0072631836 |██████--------------| 34.0%  - val_loss: 1018.2780151367 - val_trvae_loss: 1018.2780151367 |███████-------------| 35.0%  - val_loss: 1012.9488830566 - val_trvae_loss: 1012.9488830566 |███████-------------| 36.0%  - val_loss: 1014.5415649414 - val_trvae_loss: 1014.5415649414 |███████-------------| 37.0%  - val_loss: 1008.6334533691 - val_trvae_loss: 1008.6334533691 |███████-------------| 38.0%  - val_loss: 1019.6836242676 - val_trvae_loss: 1019.6836242676 |███████-------------| 39.0%  - val_loss: 1009.6565551758 - val_trvae_loss: 1009.6565551758 |████████------------| 40.0%  - val_loss: 1010.2786254883 - val_trvae_loss: 1010.2786254883 |████████------------| 41.0%  - val_loss: 1009.8386840820 - val_trvae_loss: 1009.8386840820 |████████------------| 42.0%  - val_loss: 992.3330688477 - val_trvae_loss: 992.3330688477 |████████------------| 43.0%  - val_loss: 1008.9267883301 - val_trvae_loss: 1008.9267883301 |████████------------| 44.0%  - val_loss: 1012.7372436523 - val_trvae_loss: 1012.7372436523 |█████████-----------| 45.0%  - val_loss: 1001.7483215332 - val_trvae_loss: 1001.7483215332 |█████████-----------| 46.0%  - val_loss: 1006.0752563477 - val_trvae_loss: 1006.0752563477 |█████████-----------| 47.0%  - val_loss: 1003.9806518555 - val_trvae_loss: 1003.9806518555 |█████████-----------| 48.0%  - val_loss: 1004.1252746582 - val_trvae_loss: 1004.1252746582 |█████████-----------| 49.0%  - val_loss: 1000.6833496094 - val_trvae_loss: 1000.6833496094 |██████████----------| 50.0%  - val_loss: 1004.2587890625 - val_trvae_loss: 1004.2587890625 |██████████----------| 51.0%  - val_loss: 1007.8804931641 - val_trvae_loss: 1007.8804931641 |██████████----------| 52.0%  - val_loss: 1001.4075927734 - val_trvae_loss: 1001.4075927734 |██████████----------| 53.0%  - val_loss: 997.8321533203 - val_trvae_loss: 997.8321533203 |██████████----------| 54.0%  - val_loss: 1006.9759521484 - val_trvae_loss: 1006.9759521484 |███████████---------| 55.0%  - val_loss: 1010.3830871582 - val_trvae_loss: 1010.3830871582 |███████████---------| 56.0%  - val_loss: 1008.0343933105 - val_trvae_loss: 1008.0343933105 |███████████---------| 57.0%  - val_loss: 1005.0686950684 - val_trvae_loss: 1005.0686950684 |███████████---------| 58.0%  - val_loss: 1011.8457946777 - val_trvae_loss: 1011.8457946777 |███████████---------| 59.0%  - val_loss: 1015.3468322754 - val_trvae_loss: 1015.3468322754 |████████████--------| 60.0%  - val_loss: 1011.0679626465 - val_trvae_loss: 1011.0679626465 |████████████--------| 61.0%  - val_loss: 1010.1448059082 - val_trvae_loss: 1010.1448059082 |████████████--------| 62.0%  - val_loss: 1020.5299072266 - val_trvae_loss: 1020.5299072266 |████████████--------| 63.0%  - val_loss: 1012.3997497559 - val_trvae_loss: 1012.3997497559 |████████████--------| 64.0%  - val_loss: 1007.6466064453 - val_trvae_loss: 1007.6466064453 |█████████████-------| 65.0%  - val_loss: 1016.2164916992 - val_trvae_loss: 1016.2164916992 |█████████████-------| 66.0%  - val_loss: 1004.7459106445 - val_trvae_loss: 1004.7459106445 |█████████████-------| 67.0%  - val_loss: 994.4248352051 - val_trvae_loss: 994.4248352051 |█████████████-------| 68.0%  - val_loss: 1008.6158752441 - val_trvae_loss: 1008.6158752441 |█████████████-------| 69.0%  - val_loss: 1012.3986206055 - val_trvae_loss: 1012.3986206055 |██████████████------| 70.0%  - val_loss: 1008.6849365234 - val_trvae_loss: 1008.6849365234 |██████████████------| 71.0%  - val_loss: 1021.8385925293 - val_trvae_loss: 1021.8385925293 |██████████████------| 72.0%  - val_loss: 1000.8221740723 - val_trvae_loss: 1000.8221740723 |██████████████------| 73.0%  - val_loss: 1008.7197570801 - val_trvae_loss: 1008.7197570801 |██████████████------| 74.0%  - val_loss: 998.6769409180 - val_trvae_loss: 998.6769409180 |███████████████-----| 75.0%  - val_loss: 1020.1351928711 - val_trvae_loss: 1020.1351928711 |███████████████-----| 76.0%  - val_loss: 1010.5384826660 - val_trvae_loss: 1010.5384826660 |███████████████-----| 77.0%  - val_loss: 1013.7991027832 - val_trvae_loss: 1013.7991027832 |███████████████-----| 78.0%  - val_loss: 1012.7304077148 - val_trvae_loss: 1012.7304077148 |███████████████-----| 79.0%  - val_loss: 1001.2583312988 - val_trvae_loss: 1001.2583312988 |████████████████----| 80.0%  - val_loss: 1009.2604370117 - val_trvae_loss: 1009.2604370117
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 14 clusters.
 |████████████████----| 81.0%  - val_loss: 1008.1896057129 - val_trvae_loss: 1008.1895446777 - val_landmark_loss: 0.0000781914 - val_unlabeled_loss: 0.0781914257 |████████████████----| 82.0%  - val_loss: 1017.0314636230 - val_trvae_loss: 1017.0313720703 - val_landmark_loss: 0.0000731043 - val_unlabeled_loss: 0.0731043220 |████████████████----| 83.0%  - val_loss: 999.7212524414 - val_trvae_loss: 999.7211914062 - val_landmark_loss: 0.0000704512 - val_unlabeled_loss: 0.0704511683 |████████████████----| 84.0%  - val_loss: 998.0502319336 - val_trvae_loss: 998.0501708984 - val_landmark_loss: 0.0000755882 - val_unlabeled_loss: 0.0755882412 |█████████████████---| 85.0%  - val_loss: 1015.7841186523 - val_trvae_loss: 1015.7840270996 - val_landmark_loss: 0.0000830502 - val_unlabeled_loss: 0.0830501765 |█████████████████---| 86.0%  - val_loss: 1004.6301879883 - val_trvae_loss: 1004.6301269531 - val_landmark_loss: 0.0000763400 - val_unlabeled_loss: 0.0763400383 |█████████████████---| 87.0%  - val_loss: 1003.2707214355 - val_trvae_loss: 1003.2706604004 - val_landmark_loss: 0.0000710269 - val_unlabeled_loss: 0.0710269436 |█████████████████---| 88.0%  - val_loss: 1011.0014953613 - val_trvae_loss: 1011.0014038086 - val_landmark_loss: 0.0000714976 - val_unlabeled_loss: 0.0714975744 |█████████████████---| 89.0%  - val_loss: 1022.4925231934 - val_trvae_loss: 1022.4924316406 - val_landmark_loss: 0.0000807604 - val_unlabeled_loss: 0.0807603560 |██████████████████--| 90.0%  - val_loss: 993.1184692383 - val_trvae_loss: 993.1183776855 - val_landmark_loss: 0.0000817489 - val_unlabeled_loss: 0.0817489438 |██████████████████--| 91.0%  - val_loss: 1012.4481811523 - val_trvae_loss: 1012.4480895996 - val_landmark_loss: 0.0000752422 - val_unlabeled_loss: 0.0752422288 |██████████████████--| 92.0%  - val_loss: 1002.9899597168 - val_trvae_loss: 1002.9898986816 - val_landmark_loss: 0.0000759307 - val_unlabeled_loss: 0.0759307072 |██████████████████--| 93.0%  - val_loss: 1003.8612976074 - val_trvae_loss: 1003.8612365723 - val_landmark_loss: 0.0000704346 - val_unlabeled_loss: 0.0704345573 |██████████████████--| 94.0%  - val_loss: 996.4639892578 - val_trvae_loss: 996.4639282227 - val_landmark_loss: 0.0000741078 - val_unlabeled_loss: 0.0741077513 |███████████████████-| 95.0%  - val_loss: 1002.6199951172 - val_trvae_loss: 1002.6199340820 - val_landmark_loss: 0.0000780547 - val_unlabeled_loss: 0.0780547336 |███████████████████-| 96.0%  - val_loss: 1004.6044616699 - val_trvae_loss: 1004.6044006348 - val_landmark_loss: 0.0000766975 - val_unlabeled_loss: 0.0766975060 |███████████████████-| 97.0%  - val_loss: 1012.2392578125 - val_trvae_loss: 1012.2391662598 - val_landmark_loss: 0.0000749662 - val_unlabeled_loss: 0.0749661922 |███████████████████-| 98.0%  - val_loss: 1004.5755310059 - val_trvae_loss: 1004.5754699707 - val_landmark_loss: 0.0000762318 - val_unlabeled_loss: 0.0762317479 |███████████████████-| 99.0%  - val_loss: 1011.5132751465 - val_trvae_loss: 1011.5131835938 - val_landmark_loss: 0.0000802663 - val_unlabeled_loss: 0.0802662559 |████████████████████| 100.0%  - val_loss: 1006.0030822754 - val_trvae_loss: 1006.0030212402 - val_landmark_loss: 0.0000729617 - val_unlabeled_loss: 0.0729616750
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 11:06:03 (INFO): Computing metrics
2021-10-26 11:06:04 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2021-10-26 11:08:51 (INFO): Result: {'distances':     condition      dist
0  fluidigmc1  0.750062
1     inDrop2  0.520242
2     inDrop3  0.872885
3     inDrop4  0.893167
4     smarter  0.994741
5   smartseq2  0.971093
6      celseq  0.730020
7     celseq2  0.730020
8     inDrop1  0.520242, 'classification_report':                     precision    recall  f1-score     support
acinar               0.901830  0.974236  0.936636   1669.0000
activated_stellate   0.962472  0.939655  0.950927    464.0000
alpha                0.995414  0.987803  0.991594   5493.0000
beta                 0.990111  0.984649  0.987372   4169.0000
delta                0.973435  0.972512  0.972973   1055.0000
ductal               0.981151  0.923436  0.951419   2142.0000
endothelial          0.993631  0.996805  0.995215    313.0000
epsilon              0.441176  0.937500  0.600000     32.0000
gamma                0.989840  0.975680  0.982709    699.0000
macrophage           0.621359  0.810127  0.703297     79.0000
mast                 0.111111  0.047619  0.066667     42.0000
quiescent_stellate   0.837838  0.963731  0.896386    193.0000
schwann              0.925926  1.000000  0.961538     25.0000
t_cell               0.222222  0.571429  0.320000      7.0000
accuracy             0.970700  0.970700  0.970700      0.9707
macro avg            0.781965  0.863227  0.808338  16382.0000
weighted avg         0.972598  0.970700  0.971025  16382.0000, 'classification_report_query':                     precision    recall  f1-score      support
acinar               0.982143  1.000000  0.990991   110.000000
activated_stellate   0.941176  0.941176  0.941176    51.000000
alpha                0.983051  0.983051  0.983051   236.000000
beta                 0.993088  0.988532  0.990805   872.000000
delta                0.963470  0.985981  0.974596   214.000000
ductal               1.000000  0.966667  0.983051   120.000000
endothelial          1.000000  0.992308  0.996139   130.000000
epsilon              0.687500  0.846154  0.758621    13.000000
gamma                1.000000  0.971429  0.985507    70.000000
macrophage           0.600000  0.857143  0.705882    14.000000
mast                 0.000000  0.000000  0.000000     8.000000
quiescent_stellate   0.956989  0.967391  0.962162    92.000000
schwann              1.000000  1.000000  1.000000     5.000000
t_cell               0.000000  0.000000  0.000000     2.000000
accuracy             0.977284  0.977284  0.977284     0.977284
macro avg            0.793387  0.821417  0.805142  1937.000000
weighted avg         0.976031  0.977284  0.976390  1937.000000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.921807           0.950492  ...                    0.81564    0.982322

[1 rows x 8 columns]}
Saving best state of network...
Best State was in Epoch 92
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2021-10-26 11:08:51 (INFO): Completed after 0:05:28
