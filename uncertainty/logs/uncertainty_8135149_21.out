Starting job 8135174
SLURM assigned me the node(s): gpusrv10
Experiments are running under the following process IDs:
Experiment ID: 22	Process ID: 45341

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 14:21:31 (INFO): Running command 'run'
2022-05-19 14:21:31 (INFO): Started run with ID "22"
2022-05-19 14:21:33 (INFO): Data loaded succesfully
2022-05-19 14:21:33 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.30027198791503906
 |--------------------| 1.0%  - val_loss: 1233.7421687200 - val_trvae_loss: 1233.7421687200 |--------------------| 2.0%  - val_loss: 1212.3099834736 - val_trvae_loss: 1212.3099834736 |--------------------| 3.0%  - val_loss: 1186.6834998498 - val_trvae_loss: 1186.6834998498 |--------------------| 4.0%  - val_loss: 1149.2964524489 - val_trvae_loss: 1149.2964524489 |█-------------------| 5.0%  - val_loss: 1140.9465519832 - val_trvae_loss: 1140.9465519832 |█-------------------| 6.0%  - val_loss: 1124.3183030349 - val_trvae_loss: 1124.3183030349 |█-------------------| 7.0%  - val_loss: 1111.0332688552 - val_trvae_loss: 1111.0332688552 |█-------------------| 8.0%  - val_loss: 1103.4376032903 - val_trvae_loss: 1103.4376032903 |█-------------------| 9.0%  - val_loss: 1096.9457256611 - val_trvae_loss: 1096.9457256611 |██------------------| 10.0%  - val_loss: 1102.2505446214 - val_trvae_loss: 1102.2505446214 |██------------------| 11.0%  - val_loss: 1094.6768047626 - val_trvae_loss: 1094.6768047626 |██------------------| 12.0%  - val_loss: 1088.3799203726 - val_trvae_loss: 1088.3799203726 |██------------------| 13.0%  - val_loss: 1091.2397930439 - val_trvae_loss: 1091.2397930439 |██------------------| 14.0%  - val_loss: 1086.5755239633 - val_trvae_loss: 1086.5755239633 |███-----------------| 15.0%  - val_loss: 1083.5820688101 - val_trvae_loss: 1083.5820688101 |███-----------------| 16.0%  - val_loss: 1082.2228158804 - val_trvae_loss: 1082.2228158804 |███-----------------| 17.0%  - val_loss: 1084.6666823167 - val_trvae_loss: 1084.6666823167 |███-----------------| 18.0%  - val_loss: 1077.9706092248 - val_trvae_loss: 1077.9706092248 |███-----------------| 19.0%  - val_loss: 1082.7341543344 - val_trvae_loss: 1082.7341543344 |████----------------| 20.0%  - val_loss: 1078.5360060472 - val_trvae_loss: 1078.5360060472 |████----------------| 21.0%  - val_loss: 1081.5263577975 - val_trvae_loss: 1081.5263577975 |████----------------| 22.0%  - val_loss: 1082.9729379507 - val_trvae_loss: 1082.9729379507 |████----------------| 23.0%  - val_loss: 1076.6120605469 - val_trvae_loss: 1076.6120605469 |████----------------| 24.0%  - val_loss: 1071.0277099609 - val_trvae_loss: 1071.0277099609 |█████---------------| 25.0%  - val_loss: 1071.0066950871 - val_trvae_loss: 1071.0066950871 |█████---------------| 26.0%  - val_loss: 1071.8274489183 - val_trvae_loss: 1071.8274489183 |█████---------------| 27.0%  - val_loss: 1066.1414701022 - val_trvae_loss: 1066.1414701022 |█████---------------| 28.0%  - val_loss: 1073.3832726112 - val_trvae_loss: 1073.3832726112 |█████---------------| 29.0%  - val_loss: 1072.8804649940 - val_trvae_loss: 1072.8804649940 |██████--------------| 30.0%  - val_loss: 1071.3553654597 - val_trvae_loss: 1071.3553654597 |██████--------------| 31.0%  - val_loss: 1069.5288649339 - val_trvae_loss: 1069.5288649339 |██████--------------| 32.0%  - val_loss: 1068.0653123122 - val_trvae_loss: 1068.0653123122 |██████--------------| 33.0%  - val_loss: 1069.3225003756 - val_trvae_loss: 1069.3225003756 |██████--------------| 34.0%  - val_loss: 1065.2022892879 - val_trvae_loss: 1065.2022892879 |███████-------------| 35.0%  - val_loss: 1063.8580838717 - val_trvae_loss: 1063.8580838717 |███████-------------| 36.0%  - val_loss: 1072.5848670373 - val_trvae_loss: 1072.5848670373 |███████-------------| 37.0%  - val_loss: 1071.5875713642 - val_trvae_loss: 1071.5875713642 |███████-------------| 38.0%  - val_loss: 1067.1339580829 - val_trvae_loss: 1067.1339580829 |███████-------------| 39.0%  - val_loss: 1069.3133732722 - val_trvae_loss: 1069.3133732722 |████████------------| 40.0%  - val_loss: 1072.1387469952 - val_trvae_loss: 1072.1387469952 |████████------------| 41.0%  - val_loss: 1069.3486891526 - val_trvae_loss: 1069.3486891526 |████████------------| 42.0%  - val_loss: 1067.1355168269 - val_trvae_loss: 1067.1355168269 |████████------------| 43.0%  - val_loss: 1069.3884183444 - val_trvae_loss: 1069.3884183444 |████████------------| 44.0%  - val_loss: 1067.5063476562 - val_trvae_loss: 1067.5063476562 |█████████-----------| 45.0%  - val_loss: 1066.7377178486 - val_trvae_loss: 1066.7377178486 |█████████-----------| 46.0%  - val_loss: 1068.7220834585 - val_trvae_loss: 1068.7220834585 |█████████-----------| 47.0%  - val_loss: 1063.6921011118 - val_trvae_loss: 1063.6921011118 |█████████-----------| 48.0%  - val_loss: 1069.8087158203 - val_trvae_loss: 1069.8087158203 |█████████-----------| 49.0%  - val_loss: 1063.9646512545 - val_trvae_loss: 1063.9646512545 |██████████----------| 50.0%  - val_loss: 1065.8868924654 - val_trvae_loss: 1065.8868924654 |██████████----------| 51.0%  - val_loss: 1064.2815317007 - val_trvae_loss: 1064.2815317007 |██████████----------| 52.0%  - val_loss: 1068.8471961388 - val_trvae_loss: 1068.8471961388 |██████████----------| 53.0%  - val_loss: 1066.0213998648 - val_trvae_loss: 1066.0213998648 |██████████----------| 54.0%  - val_loss: 1065.6707998422 - val_trvae_loss: 1065.6707998422 |███████████---------| 55.0%  - val_loss: 1063.7272714468 - val_trvae_loss: 1063.7272714468 |███████████---------| 56.0%  - val_loss: 1060.9016864483 - val_trvae_loss: 1060.9016864483 |███████████---------| 57.0%  - val_loss: 1068.4832481971 - val_trvae_loss: 1068.4832481971 |███████████---------| 58.0%  - val_loss: 1062.8999070388 - val_trvae_loss: 1062.8999070388 |███████████---------| 59.0%  - val_loss: 1067.2577843299 - val_trvae_loss: 1067.2577843299 |████████████--------| 60.0%  - val_loss: 1064.4590782752 - val_trvae_loss: 1064.4590782752 |████████████--------| 61.0%  - val_loss: 1065.8570556641 - val_trvae_loss: 1065.8570556641 |████████████--------| 62.0%  - val_loss: 1065.3488253080 - val_trvae_loss: 1065.3488253080 |████████████--------| 63.0%  - val_loss: 1068.8697321965 - val_trvae_loss: 1068.8697321965 |████████████--------| 64.0%  - val_loss: 1065.9261005108 - val_trvae_loss: 1065.9261005108 |█████████████-------| 65.0%  - val_loss: 1066.4591627855 - val_trvae_loss: 1066.4591627855 |█████████████-------| 66.0%  - val_loss: 1061.8669996995 - val_trvae_loss: 1061.8669996995 |█████████████-------| 67.0%  - val_loss: 1066.1159949669 - val_trvae_loss: 1066.1159949669 |█████████████-------| 68.0%  - val_loss: 1068.8994516226 - val_trvae_loss: 1068.8994516226 |█████████████-------| 69.0%  - val_loss: 1066.0370718149 - val_trvae_loss: 1066.0370718149 |██████████████------| 70.0%  - val_loss: 1067.2429856520 - val_trvae_loss: 1067.2429856520 |██████████████------| 71.0%  - val_loss: 1061.6071354793 - val_trvae_loss: 1061.6071354793 |██████████████------| 72.0%  - val_loss: 1067.0256817157 - val_trvae_loss: 1067.0256817157 |██████████████------| 73.0%  - val_loss: 1065.2462064303 - val_trvae_loss: 1065.2462064303 |██████████████------| 74.0%  - val_loss: 1060.6131169246 - val_trvae_loss: 1060.6131169246 |███████████████-----| 75.0%  - val_loss: 1063.4324199970 - val_trvae_loss: 1063.4324199970 |███████████████-----| 76.0%  - val_loss: 1066.2001765325 - val_trvae_loss: 1066.2001765325 |███████████████-----| 77.0%  - val_loss: 1064.9733135517 - val_trvae_loss: 1064.9733135517 |███████████████-----| 78.0%  - val_loss: 1060.9511812650 - val_trvae_loss: 1060.9511812650 |███████████████-----| 79.0%  - val_loss: 1063.9766845703 - val_trvae_loss: 1063.9766845703 |████████████████----| 80.0%  - val_loss: 1066.8090726412 - val_trvae_loss: 1066.8090726412 |████████████████----| 81.0%  - val_loss: 1074.0929987981 - val_trvae_loss: 1071.0241041917 - val_landmark_loss: 3.0689128271 - val_labeled_loss: 3.0689128271 |████████████████----| 82.0%  - val_loss: 1067.3626145583 - val_trvae_loss: 1064.3725116436 - val_landmark_loss: 2.9900876834 - val_labeled_loss: 2.9900876834 |████████████████----| 83.0%  - val_loss: 1067.8838829627 - val_trvae_loss: 1065.8363224910 - val_landmark_loss: 2.0475613154 - val_labeled_loss: 2.0475613154 |████████████████----| 84.0%  - val_loss: 1068.1968242939 - val_trvae_loss: 1065.9164006160 - val_landmark_loss: 2.2804336364 - val_labeled_loss: 2.2804336364 |█████████████████---| 85.0%  - val_loss: 1067.4084144005 - val_trvae_loss: 1065.1233051007 - val_landmark_loss: 2.2850998732 - val_labeled_loss: 2.2850998732 |█████████████████---| 86.0%  - val_loss: 1069.9293494591 - val_trvae_loss: 1068.2799541767 - val_landmark_loss: 1.6494004910 - val_labeled_loss: 1.6494004910 |█████████████████---| 87.0%  - val_loss: 1066.8431865986 - val_trvae_loss: 1065.3191856971 - val_landmark_loss: 1.5239905853 - val_labeled_loss: 1.5239905853 |█████████████████---| 88.0%  - val_loss: 1068.6815279447 - val_trvae_loss: 1067.3540414663 - val_landmark_loss: 1.3274920537 - val_labeled_loss: 1.3274920537 |█████████████████---| 89.0%  - val_loss: 1062.8953434871 - val_trvae_loss: 1061.4731727013 - val_landmark_loss: 1.4221610244 - val_labeled_loss: 1.4221610244 |██████████████████--| 90.0%  - val_loss: 1067.7811842698 - val_trvae_loss: 1066.3788592999 - val_landmark_loss: 1.4023220493 - val_labeled_loss: 1.4023220493 |██████████████████--| 91.0%  - val_loss: 1064.6424701397 - val_trvae_loss: 1063.2971848708 - val_landmark_loss: 1.3452819677 - val_labeled_loss: 1.3452819677 |██████████████████--| 92.0%  - val_loss: 1072.6476111779 - val_trvae_loss: 1071.3363788311 - val_landmark_loss: 1.3112303019 - val_labeled_loss: 1.3112303019 |██████████████████--| 93.0%  - val_loss: 1066.6132671650 - val_trvae_loss: 1065.5505418044 - val_landmark_loss: 1.0627329854 - val_labeled_loss: 1.0627329854 |██████████████████--| 94.0%  - val_loss: 1064.8342848558 - val_trvae_loss: 1063.4985539363 - val_landmark_loss: 1.3357314238 - val_labeled_loss: 1.3357314238 |███████████████████-| 95.0%  - val_loss: 1072.3034714919 - val_trvae_loss: 1071.2200364333 - val_landmark_loss: 1.0834108866 - val_labeled_loss: 1.0834108866 |███████████████████-| 96.0%  - val_loss: 1066.9949434721 - val_trvae_loss: 1066.0294283353 - val_landmark_loss: 0.9655354665 - val_labeled_loss: 0.9655354665 |███████████████████-| 97.0%  - val_loss: 1067.7019324669 - val_trvae_loss: 1066.4378286508 - val_landmark_loss: 1.2641093227 - val_labeled_loss: 1.2641093227 |███████████████████-| 98.0%  - val_loss: 1062.7882502629 - val_trvae_loss: 1061.5689509465 - val_landmark_loss: 1.2192958318 - val_labeled_loss: 1.2192958318 |███████████████████-| 99.0%  - val_loss: 1061.8118567834 - val_trvae_loss: 1060.8103919396 - val_landmark_loss: 1.0014729546 - val_labeled_loss: 1.0014729546 |████████████████████| 100.0%  - val_loss: 1066.3998553936 - val_trvae_loss: 1065.4194899339 - val_landmark_loss: 0.9803552719 - val_labeled_loss: 0.9803552719
2022-05-19 14:23:49 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 95
AnnData object with n_obs × n_vars = 638 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

8
loaders init
loaders init done
0.0033316612243652344
 |--------------------| 1.0%  - val_loss: 1701.0214843750 - val_trvae_loss: 1701.0214843750 |--------------------| 2.0%  - val_loss: 1699.1451416016 - val_trvae_loss: 1699.1451416016 |--------------------| 3.0%  - val_loss: 1697.8175048828 - val_trvae_loss: 1697.8175048828 |--------------------| 4.0%  - val_loss: 1696.6191406250 - val_trvae_loss: 1696.6191406250 |█-------------------| 5.0%  - val_loss: 1695.2452392578 - val_trvae_loss: 1695.2452392578 |█-------------------| 6.0%  - val_loss: 1693.3948974609 - val_trvae_loss: 1693.3948974609 |█-------------------| 7.0%  - val_loss: 1691.9102783203 - val_trvae_loss: 1691.9102783203 |█-------------------| 8.0%  - val_loss: 1690.4036865234 - val_trvae_loss: 1690.4036865234 |█-------------------| 9.0%  - val_loss: 1688.8198242188 - val_trvae_loss: 1688.8198242188 |██------------------| 10.0%  - val_loss: 1686.7520751953 - val_trvae_loss: 1686.7520751953 |██------------------| 11.0%  - val_loss: 1684.6243896484 - val_trvae_loss: 1684.6243896484 |██------------------| 12.0%  - val_loss: 1682.6508789062 - val_trvae_loss: 1682.6508789062 |██------------------| 13.0%  - val_loss: 1680.5509033203 - val_trvae_loss: 1680.5509033203 |██------------------| 14.0%  - val_loss: 1678.3166503906 - val_trvae_loss: 1678.3166503906 |███-----------------| 15.0%  - val_loss: 1675.3635253906 - val_trvae_loss: 1675.3635253906 |███-----------------| 16.0%  - val_loss: 1673.3177490234 - val_trvae_loss: 1673.3177490234 |███-----------------| 17.0%  - val_loss: 1670.8391113281 - val_trvae_loss: 1670.8391113281 |███-----------------| 18.0%  - val_loss: 1668.2629394531 - val_trvae_loss: 1668.2629394531 |███-----------------| 19.0%  - val_loss: 1665.9860839844 - val_trvae_loss: 1665.9860839844 |████----------------| 20.0%  - val_loss: 1664.3027343750 - val_trvae_loss: 1664.3027343750 |████----------------| 21.0%  - val_loss: 1661.5433349609 - val_trvae_loss: 1661.5433349609 |████----------------| 22.0%  - val_loss: 1659.8833007812 - val_trvae_loss: 1659.8833007812 |████----------------| 23.0%  - val_loss: 1657.5706787109 - val_trvae_loss: 1657.5706787109 |████----------------| 24.0%  - val_loss: 1656.6513671875 - val_trvae_loss: 1656.6513671875 |█████---------------| 25.0%  - val_loss: 1654.2834472656 - val_trvae_loss: 1654.2834472656 |█████---------------| 26.0%  - val_loss: 1652.5612792969 - val_trvae_loss: 1652.5612792969 |█████---------------| 27.0%  - val_loss: 1651.1444091797 - val_trvae_loss: 1651.1444091797 |█████---------------| 28.0%  - val_loss: 1649.4700927734 - val_trvae_loss: 1649.4700927734 |█████---------------| 29.0%  - val_loss: 1648.2377929688 - val_trvae_loss: 1648.2377929688 |██████--------------| 30.0%  - val_loss: 1647.2386474609 - val_trvae_loss: 1647.2386474609 |██████--------------| 31.0%  - val_loss: 1645.5881347656 - val_trvae_loss: 1645.5881347656 |██████--------------| 32.0%  - val_loss: 1645.0267333984 - val_trvae_loss: 1645.0267333984 |██████--------------| 33.0%  - val_loss: 1643.5501708984 - val_trvae_loss: 1643.5501708984 |██████--------------| 34.0%  - val_loss: 1642.3027343750 - val_trvae_loss: 1642.3027343750 |███████-------------| 35.0%  - val_loss: 1641.8066406250 - val_trvae_loss: 1641.8066406250 |███████-------------| 36.0%  - val_loss: 1640.4537353516 - val_trvae_loss: 1640.4537353516 |███████-------------| 37.0%  - val_loss: 1639.7868652344 - val_trvae_loss: 1639.7868652344 |███████-------------| 38.0%  - val_loss: 1638.9302978516 - val_trvae_loss: 1638.9302978516 |███████-------------| 39.0%  - val_loss: 1637.7268066406 - val_trvae_loss: 1637.7268066406 |████████------------| 40.0%  - val_loss: 1637.0439453125 - val_trvae_loss: 1637.0439453125 |████████------------| 41.0%  - val_loss: 1636.2949218750 - val_trvae_loss: 1636.2949218750 |████████------------| 42.0%  - val_loss: 1635.5760498047 - val_trvae_loss: 1635.5760498047 |████████------------| 43.0%  - val_loss: 1634.7425537109 - val_trvae_loss: 1634.7425537109 |████████------------| 44.0%  - val_loss: 1634.0804443359 - val_trvae_loss: 1634.0804443359 |█████████-----------| 45.0%  - val_loss: 1633.5214843750 - val_trvae_loss: 1633.5214843750 |█████████-----------| 46.0%  - val_loss: 1632.2801513672 - val_trvae_loss: 1632.2801513672 |█████████-----------| 47.0%  - val_loss: 1631.7884521484 - val_trvae_loss: 1631.7884521484 |█████████-----------| 48.0%  - val_loss: 1631.2053222656 - val_trvae_loss: 1631.2053222656 |█████████-----------| 49.0%  - val_loss: 1630.6868896484 - val_trvae_loss: 1630.6868896484 |██████████----------| 50.0%  - val_loss: 1629.9953613281 - val_trvae_loss: 1629.9953613281 |██████████----------| 51.0%  - val_loss: 1629.5910644531 - val_trvae_loss: 1629.5910644531 |██████████----------| 52.0%  - val_loss: 1628.8944091797 - val_trvae_loss: 1628.8944091797 |██████████----------| 53.0%  - val_loss: 1628.2153320312 - val_trvae_loss: 1628.2153320312 |██████████----------| 54.0%  - val_loss: 1627.7994384766 - val_trvae_loss: 1627.7994384766 |███████████---------| 55.0%  - val_loss: 1626.7015380859 - val_trvae_loss: 1626.7015380859 |███████████---------| 56.0%  - val_loss: 1626.7608642578 - val_trvae_loss: 1626.7608642578 |███████████---------| 57.0%  - val_loss: 1625.7497558594 - val_trvae_loss: 1625.7497558594 |███████████---------| 58.0%  - val_loss: 1625.1219482422 - val_trvae_loss: 1625.1219482422 |███████████---------| 59.0%  - val_loss: 1624.5837402344 - val_trvae_loss: 1624.5837402344 |████████████--------| 60.0%  - val_loss: 1624.0413818359 - val_trvae_loss: 1624.0413818359 |████████████--------| 61.0%  - val_loss: 1623.8424072266 - val_trvae_loss: 1623.8424072266 |████████████--------| 62.0%  - val_loss: 1623.0333251953 - val_trvae_loss: 1623.0333251953 |████████████--------| 63.0%  - val_loss: 1622.4833984375 - val_trvae_loss: 1622.4833984375 |████████████--------| 64.0%  - val_loss: 1622.1878662109 - val_trvae_loss: 1622.1878662109 |█████████████-------| 65.0%  - val_loss: 1621.2719726562 - val_trvae_loss: 1621.2719726562 |█████████████-------| 66.0%  - val_loss: 1620.5612792969 - val_trvae_loss: 1620.5612792969 |█████████████-------| 67.0%  - val_loss: 1620.6580810547 - val_trvae_loss: 1620.6580810547 |█████████████-------| 68.0%  - val_loss: 1619.8852539062 - val_trvae_loss: 1619.8852539062 |█████████████-------| 69.0%  - val_loss: 1619.4444580078 - val_trvae_loss: 1619.4444580078 |██████████████------| 70.0%  - val_loss: 1618.7114257812 - val_trvae_loss: 1618.7114257812 |██████████████------| 71.0%  - val_loss: 1618.7448730469 - val_trvae_loss: 1618.7448730469 |██████████████------| 72.0%  - val_loss: 1618.1976318359 - val_trvae_loss: 1618.1976318359 |██████████████------| 73.0%  - val_loss: 1617.7137451172 - val_trvae_loss: 1617.7137451172 |██████████████------| 74.0%  - val_loss: 1617.4649658203 - val_trvae_loss: 1617.4649658203 |███████████████-----| 75.0%  - val_loss: 1616.3782958984 - val_trvae_loss: 1616.3782958984 |███████████████-----| 76.0%  - val_loss: 1616.0352783203 - val_trvae_loss: 1616.0352783203 |███████████████-----| 77.0%  - val_loss: 1616.2502441406 - val_trvae_loss: 1616.2502441406 |███████████████-----| 78.0%  - val_loss: 1615.6152343750 - val_trvae_loss: 1615.6152343750 |███████████████-----| 79.0%  - val_loss: 1615.2423095703 - val_trvae_loss: 1615.2423095703 |████████████████----| 80.0%  - val_loss: 1614.2745361328 - val_trvae_loss: 1614.2745361328
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 11 clusters.
 |████████████████----| 81.0%  - val_loss: 1614.4768066406 - val_trvae_loss: 1614.4753417969 - val_landmark_loss: 0.0015135080 - val_unlabeled_loss: 1.5135079622 |████████████████----| 82.0%  - val_loss: 1613.5063476562 - val_trvae_loss: 1613.5048828125 - val_landmark_loss: 0.0015203313 - val_unlabeled_loss: 1.5203311443 |████████████████----| 83.0%  - val_loss: 1613.9300537109 - val_trvae_loss: 1613.9284667969 - val_landmark_loss: 0.0015315601 - val_unlabeled_loss: 1.5315600634 |████████████████----| 84.0%  - val_loss: 1613.0373535156 - val_trvae_loss: 1613.0358886719 - val_landmark_loss: 0.0015150969 - val_unlabeled_loss: 1.5150967836 |█████████████████---| 85.0%  - val_loss: 1612.8872070312 - val_trvae_loss: 1612.8858642578 - val_landmark_loss: 0.0013949504 - val_unlabeled_loss: 1.3949503899 |█████████████████---| 86.0%  - val_loss: 1612.3082275391 - val_trvae_loss: 1612.3067626953 - val_landmark_loss: 0.0015162998 - val_unlabeled_loss: 1.5162997246 |█████████████████---| 87.0%  - val_loss: 1611.9885253906 - val_trvae_loss: 1611.9870605469 - val_landmark_loss: 0.0015146778 - val_unlabeled_loss: 1.5146776438 |█████████████████---| 88.0%  - val_loss: 1611.7437744141 - val_trvae_loss: 1611.7421875000 - val_landmark_loss: 0.0015323968 - val_unlabeled_loss: 1.5323966742 |█████████████████---| 89.0%  - val_loss: 1611.1696777344 - val_trvae_loss: 1611.1680908203 - val_landmark_loss: 0.0015359159 - val_unlabeled_loss: 1.5359158516 |██████████████████--| 90.0%  - val_loss: 1610.6431884766 - val_trvae_loss: 1610.6417236328 - val_landmark_loss: 0.0015106665 - val_unlabeled_loss: 1.5106663704 |██████████████████--| 91.0%  - val_loss: 1610.5175781250 - val_trvae_loss: 1610.5161132812 - val_landmark_loss: 0.0015086960 - val_unlabeled_loss: 1.5086959600 |██████████████████--| 92.0%  - val_loss: 1610.5275878906 - val_trvae_loss: 1610.5260009766 - val_landmark_loss: 0.0015381065 - val_unlabeled_loss: 1.5381064415 |██████████████████--| 93.0%  - val_loss: 1609.5971679688 - val_trvae_loss: 1609.5957031250 - val_landmark_loss: 0.0015151142 - val_unlabeled_loss: 1.5151141882 |██████████████████--| 94.0%  - val_loss: 1609.8933105469 - val_trvae_loss: 1609.8918457031 - val_landmark_loss: 0.0015126470 - val_unlabeled_loss: 1.5126469135 |███████████████████-| 95.0%  - val_loss: 1609.1713867188 - val_trvae_loss: 1609.1697998047 - val_landmark_loss: 0.0015364578 - val_unlabeled_loss: 1.5364577770 |███████████████████-| 96.0%  - val_loss: 1608.7679443359 - val_trvae_loss: 1608.7663574219 - val_landmark_loss: 0.0015359292 - val_unlabeled_loss: 1.5359290838 |███████████████████-| 97.0%  - val_loss: 1608.3041992188 - val_trvae_loss: 1608.3027343750 - val_landmark_loss: 0.0015063566 - val_unlabeled_loss: 1.5063565969 |███████████████████-| 98.0%  - val_loss: 1608.4678955078 - val_trvae_loss: 1608.4664306641 - val_landmark_loss: 0.0015125053 - val_unlabeled_loss: 1.5125052929 |███████████████████-| 99.0%  - val_loss: 1607.6149902344 - val_trvae_loss: 1607.6135253906 - val_landmark_loss: 0.0015148420 - val_unlabeled_loss: 1.5148419142 |████████████████████| 100.0%  - val_loss: 1607.6151123047 - val_trvae_loss: 1607.6136474609 - val_landmark_loss: 0.0015019994 - val_unlabeled_loss: 1.5019993782
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 14:24:04 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2022-05-19 14:24:05 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2022-05-19 14:26:38 (INFO): Result: {'distances':     condition  cos_dist  eucl_dist
0     inDrop1  0.912304   0.919672
1     inDrop2  0.754710   0.841635
2     inDrop3  0.912304   0.907570
3     inDrop4  0.875590   0.841635
4     smarter  0.572120   0.805006
5   smartseq2  0.901130   0.939167
6      celseq  0.823302   0.870871
7     celseq2  0.776910   0.870871
8  fluidigmc1  0.572120   0.805006, 'classification_report':                     precision    recall  f1-score       support
acinar               0.904788  0.985021  0.943201   1669.000000
activated_stellate   0.966245  0.987069  0.976546    464.000000
alpha                0.996496  0.983798  0.990106   5493.000000
beta                 0.983087  0.989926  0.986495   4169.000000
delta                0.973435  0.972512  0.972973   1055.000000
ductal               0.989479  0.922035  0.954567   2142.000000
endothelial          0.993590  0.990415  0.992000    313.000000
epsilon              0.914286  1.000000  0.955224     32.000000
gamma                0.961433  0.998569  0.979649    699.000000
macrophage           0.985915  0.886076  0.933333     79.000000
mast                 0.771429  0.642857  0.701299     42.000000
quiescent_stellate   0.930348  0.968912  0.949239    193.000000
schwann              1.000000  0.760000  0.863636     25.000000
t_cell               0.285714  0.857143  0.428571      7.000000
accuracy             0.975644  0.975644  0.975644      0.975644
macro avg            0.904017  0.924595  0.901917  16382.000000
weighted avg         0.977063  0.975644  0.975867  16382.000000, 'classification_report_query':                     precision    recall  f1-score    support
acinar               0.954545  1.000000  0.976744   21.00000
activated_stellate   0.941176  1.000000  0.969697   16.00000
alpha                0.987395  0.983264  0.985325  239.00000
beta                 0.948529  1.000000  0.973585  258.00000
delta                0.950000  0.760000  0.844444   25.00000
ductal               1.000000  0.944444  0.971429   36.00000
endothelial          1.000000  0.785714  0.880000   14.00000
epsilon              1.000000  1.000000  1.000000    1.00000
gamma                1.000000  1.000000  1.000000   18.00000
macrophage           1.000000  1.000000  1.000000    1.00000
mast                 0.000000  0.000000  0.000000    3.00000
quiescent_stellate   0.333333  1.000000  0.500000    1.00000
schwann              0.000000  0.000000  0.000000    5.00000
t_cell               0.000000  0.000000  0.000000    0.00000
accuracy             0.963950  0.963950  0.963950    0.96395
macro avg            0.722499  0.748102  0.721516  638.00000
weighted avg         0.955949  0.963950  0.958631  638.00000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.924917           0.953558  ...                   0.791105    0.967543

[1 rows x 8 columns]}
2022-05-19 14:26:38 (INFO): Completed after 0:05:07
Saving best state of network...
Best State was in Epoch 84
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
