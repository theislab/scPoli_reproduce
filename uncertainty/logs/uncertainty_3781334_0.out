Starting job 3781335
SLURM assigned me the node(s): gpusrv12
Experiments are running under the following process IDs:
Experiment ID: 1	Process ID: 257417

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 11:15:13 (INFO): Running command 'run'
2021-10-26 11:15:13 (INFO): Started run with ID "1"
2021-10-26 11:15:18 (INFO): Data loaded succesfully
2021-10-26 11:15:18 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1457.6035630968 - val_trvae_loss: 1457.6035630968 |--------------------| 2.0%  - val_loss: 1421.4307725694 - val_trvae_loss: 1421.4307725694 |--------------------| 3.0%  - val_loss: 1397.4607679579 - val_trvae_loss: 1397.4607679579 |--------------------| 4.0%  - val_loss: 1386.6050008138 - val_trvae_loss: 1386.6050008138 |█-------------------| 5.0%  - val_loss: 1377.6606648763 - val_trvae_loss: 1377.6606648763 |█-------------------| 6.0%  - val_loss: 1371.7914225260 - val_trvae_loss: 1371.7914225260 |█-------------------| 7.0%  - val_loss: 1366.2829793294 - val_trvae_loss: 1366.2829793294 |█-------------------| 8.0%  - val_loss: 1362.9624837240 - val_trvae_loss: 1362.9624837240 |█-------------------| 9.0%  - val_loss: 1359.5859917535 - val_trvae_loss: 1359.5859917535 |██------------------| 10.0%  - val_loss: 1355.4857313368 - val_trvae_loss: 1355.4857313368 |██------------------| 11.0%  - val_loss: 1352.7817993164 - val_trvae_loss: 1352.7817993164 |██------------------| 12.0%  - val_loss: 1350.7759738498 - val_trvae_loss: 1350.7759738498 |██------------------| 13.0%  - val_loss: 1350.6611260308 - val_trvae_loss: 1350.6611260308 |██------------------| 14.0%  - val_loss: 1348.1911349826 - val_trvae_loss: 1348.1911349826 |███-----------------| 15.0%  - val_loss: 1347.4997151693 - val_trvae_loss: 1347.4997151693 |███-----------------| 16.0%  - val_loss: 1346.9008314345 - val_trvae_loss: 1346.9008314345 |███-----------------| 17.0%  - val_loss: 1345.7981770833 - val_trvae_loss: 1345.7981770833 |███-----------------| 18.0%  - val_loss: 1345.3141479492 - val_trvae_loss: 1345.3141479492 |███-----------------| 19.0%  - val_loss: 1344.6434597439 - val_trvae_loss: 1344.6434597439 |████----------------| 20.0%  - val_loss: 1344.4656846788 - val_trvae_loss: 1344.4656846788 |████----------------| 21.0%  - val_loss: 1345.1034884983 - val_trvae_loss: 1345.1034884983 |████----------------| 22.0%  - val_loss: 1344.7749769423 - val_trvae_loss: 1344.7749769423 |████----------------| 23.0%  - val_loss: 1344.8710327148 - val_trvae_loss: 1344.8710327148 |████----------------| 24.0%  - val_loss: 1342.2015584310 - val_trvae_loss: 1342.2015584310 |█████---------------| 25.0%  - val_loss: 1342.3754814996 - val_trvae_loss: 1342.3754814996 |█████---------------| 26.0%  - val_loss: 1340.9580010308 - val_trvae_loss: 1340.9580010308 |█████---------------| 27.0%  - val_loss: 1340.5488891602 - val_trvae_loss: 1340.5488891602 |█████---------------| 28.0%  - val_loss: 1342.1399807400 - val_trvae_loss: 1342.1399807400 |█████---------------| 29.0%  - val_loss: 1340.6362575955 - val_trvae_loss: 1340.6362575955 |██████--------------| 30.0%  - val_loss: 1341.4351264106 - val_trvae_loss: 1341.4351264106 |██████--------------| 31.0%  - val_loss: 1340.4697333442 - val_trvae_loss: 1340.4697333442 |██████--------------| 32.0%  - val_loss: 1340.3196546766 - val_trvae_loss: 1340.3196546766 |██████--------------| 33.0%  - val_loss: 1340.4309082031 - val_trvae_loss: 1340.4309082031 |██████--------------| 34.0%  - val_loss: 1340.9456108941 - val_trvae_loss: 1340.9456108941 |███████-------------| 35.0%  - val_loss: 1338.5259399414 - val_trvae_loss: 1338.5259399414 |███████-------------| 36.0%  - val_loss: 1338.0103149414 - val_trvae_loss: 1338.0103149414 |███████-------------| 37.0%  - val_loss: 1338.2494574653 - val_trvae_loss: 1338.2494574653 |███████-------------| 38.0%  - val_loss: 1339.5727267795 - val_trvae_loss: 1339.5727267795 |███████-------------| 39.0%  - val_loss: 1340.3519626194 - val_trvae_loss: 1340.3519626194 |████████------------| 40.0%  - val_loss: 1337.8898383247 - val_trvae_loss: 1337.8898383247 |████████------------| 41.0%  - val_loss: 1339.4175618490 - val_trvae_loss: 1339.4175618490 |████████------------| 42.0%  - val_loss: 1339.3637763129 - val_trvae_loss: 1339.3637763129 |████████------------| 43.0%  - val_loss: 1337.6199069553 - val_trvae_loss: 1337.6199069553 |████████------------| 44.0%  - val_loss: 1339.7330050998 - val_trvae_loss: 1339.7330050998 |█████████-----------| 45.0%  - val_loss: 1337.8834431966 - val_trvae_loss: 1337.8834431966 |█████████-----------| 46.0%  - val_loss: 1341.5556301541 - val_trvae_loss: 1341.5556301541 |█████████-----------| 47.0%  - val_loss: 1337.5455050998 - val_trvae_loss: 1337.5455050998 |█████████-----------| 48.0%  - val_loss: 1339.9073621962 - val_trvae_loss: 1339.9073621962 |█████████-----------| 49.0%  - val_loss: 1338.4563123915 - val_trvae_loss: 1338.4563123915 |██████████----------| 50.0%  - val_loss: 1337.3048163520 - val_trvae_loss: 1337.3048163520 |██████████----------| 51.0%  - val_loss: 1339.2155965169 - val_trvae_loss: 1339.2155965169 |██████████----------| 52.0%  - val_loss: 1337.5500488281 - val_trvae_loss: 1337.5500488281 |██████████----------| 53.0%  - val_loss: 1338.2266777886 - val_trvae_loss: 1338.2266777886 |██████████----------| 54.0%  - val_loss: 1336.6180013021 - val_trvae_loss: 1336.6180013021 |███████████---------| 55.0%  - val_loss: 1338.2292819553 - val_trvae_loss: 1338.2292819553 |███████████---------| 56.0%  - val_loss: 1337.9409993490 - val_trvae_loss: 1337.9409993490 |███████████---------| 57.0%  - val_loss: 1337.7329779731 - val_trvae_loss: 1337.7329779731 |███████████---------| 58.0%  - val_loss: 1337.8220960829 - val_trvae_loss: 1337.8220960829 |███████████---------| 59.0%  - val_loss: 1337.8304782444 - val_trvae_loss: 1337.8304782444 |████████████--------| 60.0%  - val_loss: 1336.6896904839 - val_trvae_loss: 1336.6896904839 |████████████--------| 61.0%  - val_loss: 1338.2517428928 - val_trvae_loss: 1338.2517428928 |████████████--------| 62.0%  - val_loss: 1336.6270005968 - val_trvae_loss: 1336.6270005968 |████████████--------| 63.0%  - val_loss: 1337.7520073785 - val_trvae_loss: 1337.7520073785 |████████████--------| 64.0%  - val_loss: 1336.0387369792 - val_trvae_loss: 1336.0387369792 |█████████████-------| 65.0%  - val_loss: 1337.3101535373 - val_trvae_loss: 1337.3101535373 |█████████████-------| 66.0%  - val_loss: 1340.7075602214 - val_trvae_loss: 1340.7075602214 |█████████████-------| 67.0%  - val_loss: 1336.6531846788 - val_trvae_loss: 1336.6531846788 |█████████████-------| 68.0%  - val_loss: 1336.3542344835 - val_trvae_loss: 1336.3542344835 |█████████████-------| 69.0%  - val_loss: 1337.7939724392 - val_trvae_loss: 1337.7939724392 |██████████████------| 70.0%  - val_loss: 1338.3778279622 - val_trvae_loss: 1338.3778279622 |██████████████------| 71.0%  - val_loss: 1336.3922322591 - val_trvae_loss: 1336.3922322591 |██████████████------| 72.0%  - val_loss: 1336.2379218207 - val_trvae_loss: 1336.2379218207 |██████████████------| 73.0%  - val_loss: 1337.6114773220 - val_trvae_loss: 1337.6114773220 |██████████████------| 74.0%  - val_loss: 1335.8987155490 - val_trvae_loss: 1335.8987155490 |███████████████-----| 75.0%  - val_loss: 1337.4361165365 - val_trvae_loss: 1337.4361165365 |███████████████-----| 76.0%  - val_loss: 1336.8963487413 - val_trvae_loss: 1336.8963487413 |███████████████-----| 77.0%  - val_loss: 1336.2046780056 - val_trvae_loss: 1336.2046780056 |███████████████-----| 78.0%  - val_loss: 1337.5709567600 - val_trvae_loss: 1337.5709567600 |███████████████-----| 79.0%  - val_loss: 1335.2102457682 - val_trvae_loss: 1335.2102457682 |████████████████----| 80.0%  - val_loss: 1336.0698852539 - val_trvae_loss: 1336.0698852539 |████████████████----| 81.0%  - val_loss: 1350.1537611220 - val_trvae_loss: 1341.0768093533 - val_landmark_loss: 9.0769503382 - val_labeled_loss: 9.0769503382 |████████████████----| 82.0%  - val_loss: 1346.4286092122 - val_trvae_loss: 1340.0120035807 - val_landmark_loss: 6.4166098701 - val_labeled_loss: 6.4166098701 |████████████████----| 83.0%  - val_loss: 1343.5957438151 - val_trvae_loss: 1338.1904229058 - val_landmark_loss: 5.4053237306 - val_labeled_loss: 5.4053237306 |████████████████----| 84.0%  - val_loss: 1342.5289442274 - val_trvae_loss: 1338.2140570747 - val_landmark_loss: 4.3148813513 - val_labeled_loss: 4.3148813513 |█████████████████---| 85.0%  - val_loss: 1343.8659193251 - val_trvae_loss: 1339.6782158746 - val_landmark_loss: 4.1876978079 - val_labeled_loss: 4.1876978079 |█████████████████---| 86.0%  - val_loss: 1341.3642442491 - val_trvae_loss: 1337.6019083659 - val_landmark_loss: 3.7623292075 - val_labeled_loss: 3.7623292075 |█████████████████---| 87.0%  - val_loss: 1341.6645372179 - val_trvae_loss: 1337.4469807943 - val_landmark_loss: 4.2175640331 - val_labeled_loss: 4.2175640331 |█████████████████---| 88.0%  - val_loss: 1343.6008775499 - val_trvae_loss: 1340.1490614149 - val_landmark_loss: 3.4518202411 - val_labeled_loss: 3.4518202411 |█████████████████---| 89.0%  - val_loss: 1341.8841417101 - val_trvae_loss: 1338.9536268446 - val_landmark_loss: 2.9305090970 - val_labeled_loss: 2.9305090970 |██████████████████--| 90.0%  - val_loss: 1342.5752699110 - val_trvae_loss: 1339.6883884006 - val_landmark_loss: 2.8868684636 - val_labeled_loss: 2.8868684636 |██████████████████--| 91.0%  - val_loss: 1340.4083387587 - val_trvae_loss: 1337.5852118598 - val_landmark_loss: 2.8231276406 - val_labeled_loss: 2.8231276406 |██████████████████--| 92.0%  - val_loss: 1340.1049872504 - val_trvae_loss: 1337.5662027995 - val_landmark_loss: 2.5387797687 - val_labeled_loss: 2.5387797687 |██████████████████--| 93.0%  - val_loss: 1341.6124674479 - val_trvae_loss: 1338.9267239041 - val_landmark_loss: 2.6857418716 - val_labeled_loss: 2.6857418716 |██████████████████--| 94.0%  - val_loss: 1337.7952270508 - val_trvae_loss: 1335.1138034397 - val_landmark_loss: 2.6814311345 - val_labeled_loss: 2.6814311345 |███████████████████-| 95.0%  - val_loss: 1340.3095770942 - val_trvae_loss: 1337.9022420247 - val_landmark_loss: 2.4073317515 - val_labeled_loss: 2.4073317515 |███████████████████-| 96.0%  - val_loss: 1338.7903984918 - val_trvae_loss: 1336.4934828016 - val_landmark_loss: 2.2969112794 - val_labeled_loss: 2.2969112794 |███████████████████-| 97.0%  - val_loss: 1338.5676472982 - val_trvae_loss: 1336.3531155056 - val_landmark_loss: 2.2145445181 - val_labeled_loss: 2.2145445181 |███████████████████-| 98.0%  - val_loss: 1339.2324218750 - val_trvae_loss: 1337.0138075087 - val_landmark_loss: 2.2186164757 - val_labeled_loss: 2.2186164757 |███████████████████-| 99.0%  - val_loss: 1338.7742784288 - val_trvae_loss: 1336.7028062609 - val_landmark_loss: 2.0714651512 - val_labeled_loss: 2.0714651512 |████████████████████| 100.0%  - val_loss: 1338.6644083659 - val_trvae_loss: 1336.5907999674 - val_landmark_loss: 2.0736138125 - val_labeled_loss: 2.0736138125
2021-10-26 11:18:44 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 9581 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
Warning: Labels in adata.obs[cell_type] is not a subset of label-encoder!
Therefore integer value of those labels is set to -1
 |--------------------| 1.0%  - val_loss: 1433.0270996094 - val_trvae_loss: 1433.0270996094 |--------------------| 2.0%  - val_loss: 1429.0731353760 - val_trvae_loss: 1429.0731353760 |--------------------| 3.0%  - val_loss: 1414.4808959961 - val_trvae_loss: 1414.4808959961 |--------------------| 4.0%  - val_loss: 1413.7300872803 - val_trvae_loss: 1413.7300872803 |█-------------------| 5.0%  - val_loss: 1419.5652618408 - val_trvae_loss: 1419.5652618408 |█-------------------| 6.0%  - val_loss: 1384.4966430664 - val_trvae_loss: 1384.4966430664 |█-------------------| 7.0%  - val_loss: 1385.7084960938 - val_trvae_loss: 1385.7084960938 |█-------------------| 8.0%  - val_loss: 1384.1477966309 - val_trvae_loss: 1384.1477966309 |█-------------------| 9.0%  - val_loss: 1384.8241271973 - val_trvae_loss: 1384.8241271973 |██------------------| 10.0%  - val_loss: 1391.9409790039 - val_trvae_loss: 1391.9409790039 |██------------------| 11.0%  - val_loss: 1380.0867462158 - val_trvae_loss: 1380.0867462158 |██------------------| 12.0%  - val_loss: 1369.0652465820 - val_trvae_loss: 1369.0652465820 |██------------------| 13.0%  - val_loss: 1357.0071258545 - val_trvae_loss: 1357.0071258545 |██------------------| 14.0%  - val_loss: 1368.5515747070 - val_trvae_loss: 1368.5515747070 |███-----------------| 15.0%  - val_loss: 1348.7280426025 - val_trvae_loss: 1348.7280426025 |███-----------------| 16.0%  - val_loss: 1344.2210540771 - val_trvae_loss: 1344.2210540771 |███-----------------| 17.0%  - val_loss: 1323.6598815918 - val_trvae_loss: 1323.6598815918 |███-----------------| 18.0%  - val_loss: 1324.7123413086 - val_trvae_loss: 1324.7123413086 |███-----------------| 19.0%  - val_loss: 1315.4377899170 - val_trvae_loss: 1315.4377899170 |████----------------| 20.0%  - val_loss: 1319.2489624023 - val_trvae_loss: 1319.2489624023 |████----------------| 21.0%  - val_loss: 1332.5301818848 - val_trvae_loss: 1332.5301818848 |████----------------| 22.0%  - val_loss: 1320.8113098145 - val_trvae_loss: 1320.8113098145 |████----------------| 23.0%  - val_loss: 1320.1276702881 - val_trvae_loss: 1320.1276702881 |████----------------| 24.0%  - val_loss: 1317.8641815186 - val_trvae_loss: 1317.8641815186 |█████---------------| 25.0%  - val_loss: 1302.0792846680 - val_trvae_loss: 1302.0792846680 |█████---------------| 26.0%  - val_loss: 1297.3073883057 - val_trvae_loss: 1297.3073883057 |█████---------------| 27.0%  - val_loss: 1298.3877868652 - val_trvae_loss: 1298.3877868652 |█████---------------| 28.0%  - val_loss: 1301.0199127197 - val_trvae_loss: 1301.0199127197 |█████---------------| 29.0%  - val_loss: 1282.8673858643 - val_trvae_loss: 1282.8673858643 |██████--------------| 30.0%  - val_loss: 1285.1550445557 - val_trvae_loss: 1285.1550445557 |██████--------------| 31.0%  - val_loss: 1286.7941436768 - val_trvae_loss: 1286.7941436768 |██████--------------| 32.0%  - val_loss: 1291.8073577881 - val_trvae_loss: 1291.8073577881 |██████--------------| 33.0%  - val_loss: 1287.8715515137 - val_trvae_loss: 1287.8715515137 |██████--------------| 34.0%  - val_loss: 1278.1053924561 - val_trvae_loss: 1278.1053924561 |███████-------------| 35.0%  - val_loss: 1272.6585845947 - val_trvae_loss: 1272.6585845947 |███████-------------| 36.0%  - val_loss: 1272.4264526367 - val_trvae_loss: 1272.4264526367 |███████-------------| 37.0%  - val_loss: 1266.5491180420 - val_trvae_loss: 1266.5491180420 |███████-------------| 38.0%  - val_loss: 1266.3288574219 - val_trvae_loss: 1266.3288574219 |███████-------------| 39.0%  - val_loss: 1262.2942962646 - val_trvae_loss: 1262.2942962646 |████████------------| 40.0%  - val_loss: 1252.6911468506 - val_trvae_loss: 1252.6911468506 |████████------------| 41.0%  - val_loss: 1247.8517608643 - val_trvae_loss: 1247.8517608643 |████████------------| 42.0%  - val_loss: 1252.3666839600 - val_trvae_loss: 1252.3666839600 |████████------------| 43.0%  - val_loss: 1252.1819305420 - val_trvae_loss: 1252.1819305420 |████████------------| 44.0%  - val_loss: 1250.3017120361 - val_trvae_loss: 1250.3017120361 |█████████-----------| 45.0%  - val_loss: 1251.9677886963 - val_trvae_loss: 1251.9677886963 |█████████-----------| 46.0%  - val_loss: 1240.7771606445 - val_trvae_loss: 1240.7771606445 |█████████-----------| 47.0%  - val_loss: 1241.0875854492 - val_trvae_loss: 1241.0875854492 |█████████-----------| 48.0%  - val_loss: 1244.4017944336 - val_trvae_loss: 1244.4017944336 |█████████-----------| 49.0%  - val_loss: 1235.5130767822 - val_trvae_loss: 1235.5130767822 |██████████----------| 50.0%  - val_loss: 1240.3644409180 - val_trvae_loss: 1240.3644409180 |██████████----------| 51.0%  - val_loss: 1233.3730926514 - val_trvae_loss: 1233.3730926514 |██████████----------| 52.0%  - val_loss: 1239.3825225830 - val_trvae_loss: 1239.3825225830 |██████████----------| 53.0%  - val_loss: 1229.7483825684 - val_trvae_loss: 1229.7483825684 |██████████----------| 54.0%  - val_loss: 1235.6171569824 - val_trvae_loss: 1235.6171569824 |███████████---------| 55.0%  - val_loss: 1219.6268005371 - val_trvae_loss: 1219.6268005371 |███████████---------| 56.0%  - val_loss: 1230.4949645996 - val_trvae_loss: 1230.4949645996 |███████████---------| 57.0%  - val_loss: 1232.3144683838 - val_trvae_loss: 1232.3144683838 |███████████---------| 58.0%  - val_loss: 1229.4105377197 - val_trvae_loss: 1229.4105377197 |███████████---------| 59.0%  - val_loss: 1217.7603454590 - val_trvae_loss: 1217.7603454590 |████████████--------| 60.0%  - val_loss: 1226.2225799561 - val_trvae_loss: 1226.2225799561 |████████████--------| 61.0%  - val_loss: 1217.5189666748 - val_trvae_loss: 1217.5189666748 |████████████--------| 62.0%  - val_loss: 1227.2416229248 - val_trvae_loss: 1227.2416229248 |████████████--------| 63.0%  - val_loss: 1213.5212097168 - val_trvae_loss: 1213.5212097168 |████████████--------| 64.0%  - val_loss: 1219.5882415771 - val_trvae_loss: 1219.5882415771 |█████████████-------| 65.0%  - val_loss: 1215.5342407227 - val_trvae_loss: 1215.5342407227 |█████████████-------| 66.0%  - val_loss: 1218.5753479004 - val_trvae_loss: 1218.5753479004 |█████████████-------| 67.0%  - val_loss: 1214.8538818359 - val_trvae_loss: 1214.8538818359 |█████████████-------| 68.0%  - val_loss: 1213.0441741943 - val_trvae_loss: 1213.0441741943 |█████████████-------| 69.0%  - val_loss: 1207.5930480957 - val_trvae_loss: 1207.5930480957 |██████████████------| 70.0%  - val_loss: 1205.1026458740 - val_trvae_loss: 1205.1026458740 |██████████████------| 71.0%  - val_loss: 1212.9619903564 - val_trvae_loss: 1212.9619903564 |██████████████------| 72.0%  - val_loss: 1212.4216308594 - val_trvae_loss: 1212.4216308594 |██████████████------| 73.0%  - val_loss: 1205.8038787842 - val_trvae_loss: 1205.8038787842 |██████████████------| 74.0%  - val_loss: 1205.7960662842 - val_trvae_loss: 1205.7960662842 |███████████████-----| 75.0%  - val_loss: 1200.3605804443 - val_trvae_loss: 1200.3605804443 |███████████████-----| 76.0%  - val_loss: 1202.0448150635 - val_trvae_loss: 1202.0448150635 |███████████████-----| 77.0%  - val_loss: 1200.5971527100 - val_trvae_loss: 1200.5971527100 |███████████████-----| 78.0%  - val_loss: 1204.9502868652 - val_trvae_loss: 1204.9502868652 |███████████████-----| 79.0%  - val_loss: 1193.8403625488 - val_trvae_loss: 1193.8403625488 |████████████████----| 80.0%  - val_loss: 1212.8455352783 - val_trvae_loss: 1212.8455352783
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 23 clusters.
 |████████████████----| 81.0%  - val_loss: 1195.7969970703 - val_trvae_loss: 1195.7967529297 - val_landmark_loss: 0.0002659433 - val_unlabeled_loss: 0.2659432460 |████████████████----| 82.0%  - val_loss: 1194.1145935059 - val_trvae_loss: 1194.1143341064 - val_landmark_loss: 0.0002775285 - val_unlabeled_loss: 0.2775284816 |████████████████----| 83.0%  - val_loss: 1194.3742370605 - val_trvae_loss: 1194.3739471436 - val_landmark_loss: 0.0002801211 - val_unlabeled_loss: 0.2801210433 |████████████████----| 84.0%  - val_loss: 1197.1309051514 - val_trvae_loss: 1197.1306457520 - val_landmark_loss: 0.0002756927 - val_unlabeled_loss: 0.2756926659 |█████████████████---| 85.0%  - val_loss: 1205.3479309082 - val_trvae_loss: 1205.3476562500 - val_landmark_loss: 0.0002736801 - val_unlabeled_loss: 0.2736800890 |█████████████████---| 86.0%  - val_loss: 1199.3531646729 - val_trvae_loss: 1199.3528747559 - val_landmark_loss: 0.0002703106 - val_unlabeled_loss: 0.2703106049 |█████████████████---| 87.0%  - val_loss: 1200.1494140625 - val_trvae_loss: 1200.1491241455 - val_landmark_loss: 0.0002694162 - val_unlabeled_loss: 0.2694161423 |█████████████████---| 88.0%  - val_loss: 1191.7089080811 - val_trvae_loss: 1191.7086029053 - val_landmark_loss: 0.0003055523 - val_unlabeled_loss: 0.3055523261 |█████████████████---| 89.0%  - val_loss: 1199.9471435547 - val_trvae_loss: 1199.9468841553 - val_landmark_loss: 0.0002826255 - val_unlabeled_loss: 0.2826254852 |██████████████████--| 90.0%  - val_loss: 1188.6690979004 - val_trvae_loss: 1188.6687927246 - val_landmark_loss: 0.0002943531 - val_unlabeled_loss: 0.2943530586 |██████████████████--| 91.0%  - val_loss: 1195.2069244385 - val_trvae_loss: 1195.2066497803 - val_landmark_loss: 0.0002714708 - val_unlabeled_loss: 0.2714708187 |██████████████████--| 92.0%  - val_loss: 1189.2263488770 - val_trvae_loss: 1189.2260742188 - val_landmark_loss: 0.0002817454 - val_unlabeled_loss: 0.2817453556 |██████████████████--| 93.0%  - val_loss: 1198.9739837646 - val_trvae_loss: 1198.9737243652 - val_landmark_loss: 0.0002599827 - val_unlabeled_loss: 0.2599827088 |██████████████████--| 94.0%  - val_loss: 1192.5886993408 - val_trvae_loss: 1192.5884552002 - val_landmark_loss: 0.0002703460 - val_unlabeled_loss: 0.2703460120 |███████████████████-| 95.0%  - val_loss: 1201.7259216309 - val_trvae_loss: 1201.7256317139 - val_landmark_loss: 0.0002826390 - val_unlabeled_loss: 0.2826390155 |███████████████████-| 96.0%  - val_loss: 1195.1705474854 - val_trvae_loss: 1195.1702728271 - val_landmark_loss: 0.0002647664 - val_unlabeled_loss: 0.2647663467 |███████████████████-| 97.0%  - val_loss: 1189.0719604492 - val_trvae_loss: 1189.0716857910 - val_landmark_loss: 0.0002797117 - val_unlabeled_loss: 0.2797117215 |███████████████████-| 98.0%  - val_loss: 1199.5361785889 - val_trvae_loss: 1199.5358734131 - val_landmark_loss: 0.0002930675 - val_unlabeled_loss: 0.2930675168 |███████████████████-| 99.0%  - val_loss: 1191.6954040527 - val_trvae_loss: 1191.6951446533 - val_landmark_loss: 0.0002591715 - val_unlabeled_loss: 0.2591714691 |████████████████████| 100.0%  - val_loss: 1195.6743927002 - val_trvae_loss: 1195.6741180420 - val_landmark_loss: 0.0002657968 - val_unlabeled_loss: 0.2657968178
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 11:20:00 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 11:20:01 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2021-10-26 11:34:13 (INFO): Result: {'distances':   condition      dist
0       10X  1.267891
1       Sun  0.582620
2   Freytag  0.982341
3    Oetjen  0.582620, 'classification_report':                                   precision    recall  f1-score      support
CD10+ B cells                      0.000000  0.000000  0.000000    207.00000
CD14+ Monocytes                    0.969416  0.955191  0.962251   6338.00000
CD16+ Monocytes                    0.921171  0.991515  0.955050    825.00000
CD20+ B cells                      0.988207  0.991646  0.989924   2873.00000
CD4+ T cells                       0.871490  0.904732  0.887800  11011.00000
CD8+ T cells                       0.603318  0.766377  0.675141   2183.00000
Erythrocytes                       0.000000  0.000000  0.000000   1502.00000
Erythroid progenitors              0.000000  0.000000  0.000000    463.00000
HSPCs                              0.245261  0.902748  0.385727    473.00000
Megakaryocyte progenitors          0.297297  0.203704  0.241758    270.00000
Monocyte progenitors               0.000000  0.000000  0.000000    428.00000
Monocyte-derived dendritic cells   0.516866  0.993724  0.680029    478.00000
NK cells                           0.971287  0.766783  0.857004   2294.00000
NKT cells                          0.784834  0.904918  0.840609   2745.00000
Plasma cells                       0.737805  0.937984  0.825939    129.00000
Plasmacytoid dendritic cells       0.935484  0.984906  0.959559    265.00000
accuracy                           0.829270  0.829270  0.829270      0.82927
macro avg                          0.552652  0.644014  0.578799  32484.00000
weighted avg                       0.795012  0.829270  0.806155  32484.00000, 'classification_report_query':                                   precision    recall  f1-score     support
CD10+ B cells                      0.000000  0.000000  0.000000   207.00000
CD14+ Monocytes                    0.829567  0.883651  0.855755   997.00000
CD16+ Monocytes                    0.916667  1.000000  0.956522   165.00000
CD20+ B cells                      0.937500  0.977597  0.957129   491.00000
CD4+ T cells                       0.606144  0.875594  0.716370  2524.00000
CD8+ T cells                       0.556805  0.502538  0.528282   985.00000
Erythrocytes                       0.000000  0.000000  0.000000  1502.00000
Erythroid progenitors              0.000000  0.000000  0.000000   463.00000
HSPCs                              0.232164  0.892135  0.368445   445.00000
Megakaryocyte progenitors          0.038462  0.022831  0.028653   219.00000
Monocyte progenitors               0.000000  0.000000  0.000000   428.00000
Monocyte-derived dendritic cells   0.388686  0.995327  0.559055   214.00000
NK cells                           0.731481  0.887640  0.802030    89.00000
NKT cells                          0.753906  0.634868  0.689286   608.00000
Plasma cells                       0.735714  0.927928  0.820717   111.00000
Plasmacytoid dendritic cells       0.909722  0.984962  0.945848   133.00000
accuracy                           0.578750  0.578750  0.578750     0.57875
macro avg                          0.477301  0.599067  0.514256  9581.00000
weighted avg                       0.463214  0.578750  0.501688  9581.00000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.823012           0.835558  ...                   0.532821     0.96403

[1 rows x 8 columns]}
Saving best state of network...
Best State was in Epoch 98
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2021-10-26 11:34:13 (INFO): Completed after 0:19:01
