Starting job 3781270
SLURM assigned me the node(s): gpusrv11
Experiments are running under the following process IDs:
Experiment ID: 7	Process ID: 41845

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 10:57:02 (INFO): Running command 'run'
2021-10-26 10:57:02 (INFO): Started run with ID "7"
2021-10-26 10:57:16 (INFO): Data loaded succesfully
2021-10-26 10:57:16 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1292.3798217773 - val_trvae_loss: 1292.3798217773 |--------------------| 2.0%  - val_loss: 1239.3849792480 - val_trvae_loss: 1239.3849792480 |--------------------| 3.0%  - val_loss: 1206.1133829753 - val_trvae_loss: 1206.1133829753 |--------------------| 4.0%  - val_loss: 1190.3779805501 - val_trvae_loss: 1190.3779805501 |█-------------------| 5.0%  - val_loss: 1179.8283894857 - val_trvae_loss: 1179.8283894857 |█-------------------| 6.0%  - val_loss: 1170.2930196126 - val_trvae_loss: 1170.2930196126 |█-------------------| 7.0%  - val_loss: 1162.0415039062 - val_trvae_loss: 1162.0415039062 |█-------------------| 8.0%  - val_loss: 1157.1434733073 - val_trvae_loss: 1157.1434733073 |█-------------------| 9.0%  - val_loss: 1154.4462280273 - val_trvae_loss: 1154.4462280273 |██------------------| 10.0%  - val_loss: 1148.5006306966 - val_trvae_loss: 1148.5006306966 |██------------------| 11.0%  - val_loss: 1145.7730712891 - val_trvae_loss: 1145.7730712891 |██------------------| 12.0%  - val_loss: 1143.1308390299 - val_trvae_loss: 1143.1308390299 |██------------------| 13.0%  - val_loss: 1140.8529256185 - val_trvae_loss: 1140.8529256185 |██------------------| 14.0%  - val_loss: 1138.4721781413 - val_trvae_loss: 1138.4721781413 |███-----------------| 15.0%  - val_loss: 1135.5901285807 - val_trvae_loss: 1135.5901285807 |███-----------------| 16.0%  - val_loss: 1134.3301188151 - val_trvae_loss: 1134.3301188151 |███-----------------| 17.0%  - val_loss: 1132.1577046712 - val_trvae_loss: 1132.1577046712 |███-----------------| 18.0%  - val_loss: 1130.2117309570 - val_trvae_loss: 1130.2117309570 |███-----------------| 19.0%  - val_loss: 1128.7081909180 - val_trvae_loss: 1128.7081909180 |████----------------| 20.0%  - val_loss: 1129.6209615072 - val_trvae_loss: 1129.6209615072 |████----------------| 21.0%  - val_loss: 1127.9098815918 - val_trvae_loss: 1127.9098815918 |████----------------| 22.0%  - val_loss: 1129.1968282064 - val_trvae_loss: 1129.1968282064 |████----------------| 23.0%  - val_loss: 1128.0058492025 - val_trvae_loss: 1128.0058492025 |████----------------| 24.0%  - val_loss: 1124.3343200684 - val_trvae_loss: 1124.3343200684 |█████---------------| 25.0%  - val_loss: 1124.4171447754 - val_trvae_loss: 1124.4171447754 |█████---------------| 26.0%  - val_loss: 1122.7710164388 - val_trvae_loss: 1122.7710164388 |█████---------------| 27.0%  - val_loss: 1124.6164754232 - val_trvae_loss: 1124.6164754232 |█████---------------| 28.0%  - val_loss: 1124.1928710938 - val_trvae_loss: 1124.1928710938 |█████---------------| 29.0%  - val_loss: 1122.6671854655 - val_trvae_loss: 1122.6671854655 |██████--------------| 30.0%  - val_loss: 1123.2538146973 - val_trvae_loss: 1123.2538146973 |██████--------------| 31.0%  - val_loss: 1117.4098256429 - val_trvae_loss: 1117.4098256429 |██████--------------| 32.0%  - val_loss: 1122.3953755697 - val_trvae_loss: 1122.3953755697 |██████--------------| 33.0%  - val_loss: 1121.6831461589 - val_trvae_loss: 1121.6831461589 |██████--------------| 34.0%  - val_loss: 1117.9512939453 - val_trvae_loss: 1117.9512939453 |███████-------------| 35.0%  - val_loss: 1118.7200520833 - val_trvae_loss: 1118.7200520833 |███████-------------| 36.0%  - val_loss: 1120.3877868652 - val_trvae_loss: 1120.3877868652 |███████-------------| 37.0%  - val_loss: 1120.6795043945 - val_trvae_loss: 1120.6795043945 |███████-------------| 38.0%  - val_loss: 1118.4440816243 - val_trvae_loss: 1118.4440816243 |███████-------------| 39.0%  - val_loss: 1118.3149210612 - val_trvae_loss: 1118.3149210612 |████████------------| 40.0%  - val_loss: 1119.5074869792 - val_trvae_loss: 1119.5074869792 |████████------------| 41.0%  - val_loss: 1118.4193522135 - val_trvae_loss: 1118.4193522135 |████████------------| 42.0%  - val_loss: 1118.5760091146 - val_trvae_loss: 1118.5760091146 |████████------------| 43.0%  - val_loss: 1117.6501668294 - val_trvae_loss: 1117.6501668294 |████████------------| 44.0%  - val_loss: 1117.3521423340 - val_trvae_loss: 1117.3521423340 |█████████-----------| 45.0%  - val_loss: 1116.3791402181 - val_trvae_loss: 1116.3791402181 |█████████-----------| 46.0%  - val_loss: 1119.3872273763 - val_trvae_loss: 1119.3872273763 |█████████-----------| 47.0%  - val_loss: 1118.2400105794 - val_trvae_loss: 1118.2400105794 |█████████-----------| 48.0%  - val_loss: 1117.1827087402 - val_trvae_loss: 1117.1827087402 |█████████-----------| 49.0%  - val_loss: 1116.7388305664 - val_trvae_loss: 1116.7388305664 |██████████----------| 50.0%  - val_loss: 1118.8953145345 - val_trvae_loss: 1118.8953145345 |██████████----------| 51.0%  - val_loss: 1117.8089701335 - val_trvae_loss: 1117.8089701335 |██████████----------| 52.0%  - val_loss: 1116.8957316081 - val_trvae_loss: 1116.8957316081 |██████████----------| 53.0%  - val_loss: 1116.5815327962 - val_trvae_loss: 1116.5815327962 |██████████----------| 54.0%  - val_loss: 1117.9095967611 - val_trvae_loss: 1117.9095967611 |███████████---------| 55.0%  - val_loss: 1117.1665954590 - val_trvae_loss: 1117.1665954590 |███████████---------| 56.0%  - val_loss: 1116.3391011556 - val_trvae_loss: 1116.3391011556 |███████████---------| 57.0%  - val_loss: 1115.8598225911 - val_trvae_loss: 1115.8598225911 |███████████---------| 58.0%  - val_loss: 1114.7432454427 - val_trvae_loss: 1114.7432454427 |███████████---------| 59.0%  - val_loss: 1117.1803894043 - val_trvae_loss: 1117.1803894043 |████████████--------| 60.0%  - val_loss: 1117.0768330892 - val_trvae_loss: 1117.0768330892 |████████████--------| 61.0%  - val_loss: 1116.5062255859 - val_trvae_loss: 1116.5062255859 |████████████--------| 62.0%  - val_loss: 1115.6586507161 - val_trvae_loss: 1115.6586507161 |████████████--------| 63.0%  - val_loss: 1117.4326477051 - val_trvae_loss: 1117.4326477051 |████████████--------| 64.0%  - val_loss: 1115.2228698730 - val_trvae_loss: 1115.2228698730 |█████████████-------| 65.0%  - val_loss: 1115.1810607910 - val_trvae_loss: 1115.1810607910 |█████████████-------| 66.0%  - val_loss: 1117.6500040690 - val_trvae_loss: 1117.6500040690 |█████████████-------| 67.0%  - val_loss: 1115.2883809408 - val_trvae_loss: 1115.2883809408 |█████████████-------| 68.0%  - val_loss: 1115.6566975911 - val_trvae_loss: 1115.6566975911 |█████████████-------| 69.0%  - val_loss: 1115.4886474609 - val_trvae_loss: 1115.4886474609 |██████████████------| 70.0%  - val_loss: 1114.2383219401 - val_trvae_loss: 1114.2383219401 |██████████████------| 71.0%  - val_loss: 1115.8623453776 - val_trvae_loss: 1115.8623453776 |██████████████------| 72.0%  - val_loss: 1116.2310384115 - val_trvae_loss: 1116.2310384115 |██████████████------| 73.0%  - val_loss: 1114.5902303060 - val_trvae_loss: 1114.5902303060 |██████████████------| 74.0%  - val_loss: 1115.3355204264 - val_trvae_loss: 1115.3355204264 |███████████████-----| 75.0%  - val_loss: 1114.2581380208 - val_trvae_loss: 1114.2581380208 |███████████████-----| 76.0%  - val_loss: 1116.4536234538 - val_trvae_loss: 1116.4536234538 |███████████████-----| 77.0%  - val_loss: 1115.2669881185 - val_trvae_loss: 1115.2669881185 |███████████████-----| 78.0%  - val_loss: 1114.5329284668 - val_trvae_loss: 1114.5329284668 |███████████████-----| 79.0%  - val_loss: 1113.9928181966 - val_trvae_loss: 1113.9928181966 |████████████████----| 80.0%  - val_loss: 1114.0389404297 - val_trvae_loss: 1114.0389404297 |████████████████----| 81.0%  - val_loss: 1120.0726420085 - val_trvae_loss: 1116.8846638997 - val_landmark_loss: 3.1879926125 - val_labeled_loss: 3.1879926125 |████████████████----| 82.0%  - val_loss: 1117.2319437663 - val_trvae_loss: 1114.9572957357 - val_landmark_loss: 2.2746537924 - val_labeled_loss: 2.2746537924 |████████████████----| 83.0%  - val_loss: 1118.6454671224 - val_trvae_loss: 1116.6059061686 - val_landmark_loss: 2.0395569801 - val_labeled_loss: 2.0395569801 |████████████████----| 84.0%  - val_loss: 1117.0375467936 - val_trvae_loss: 1115.2038879395 - val_landmark_loss: 1.8336687783 - val_labeled_loss: 1.8336687783 |█████████████████---| 85.0%  - val_loss: 1117.0857950846 - val_trvae_loss: 1115.2561543783 - val_landmark_loss: 1.8296259046 - val_labeled_loss: 1.8296259046 |█████████████████---| 86.0%  - val_loss: 1116.7855326335 - val_trvae_loss: 1115.4463399251 - val_landmark_loss: 1.3391789198 - val_labeled_loss: 1.3391789198 |█████████████████---| 87.0%  - val_loss: 1116.8415934245 - val_trvae_loss: 1115.6356506348 - val_landmark_loss: 1.2059517900 - val_labeled_loss: 1.2059517900 |█████████████████---| 88.0%  - val_loss: 1117.4749552409 - val_trvae_loss: 1116.2169392904 - val_landmark_loss: 1.2580061555 - val_labeled_loss: 1.2580061555 |█████████████████---| 89.0%  - val_loss: 1116.1783447266 - val_trvae_loss: 1115.0013326009 - val_landmark_loss: 1.1770164569 - val_labeled_loss: 1.1770164569 |██████████████████--| 90.0%  - val_loss: 1116.5470174154 - val_trvae_loss: 1115.4137064616 - val_landmark_loss: 1.1333161543 - val_labeled_loss: 1.1333161543 |██████████████████--| 91.0%  - val_loss: 1118.3692525228 - val_trvae_loss: 1117.3615824382 - val_landmark_loss: 1.0076673528 - val_labeled_loss: 1.0076673528 |██████████████████--| 92.0%  - val_loss: 1118.2889811198 - val_trvae_loss: 1117.3020426432 - val_landmark_loss: 0.9869394551 - val_labeled_loss: 0.9869394551 |██████████████████--| 93.0%  - val_loss: 1116.3894246419 - val_trvae_loss: 1115.4716389974 - val_landmark_loss: 0.9177923451 - val_labeled_loss: 0.9177923451 |██████████████████--| 94.0%  - val_loss: 1116.9246927897 - val_trvae_loss: 1116.0154418945 - val_landmark_loss: 0.9092465142 - val_labeled_loss: 0.9092465142 |███████████████████-| 95.0%  - val_loss: 1116.4966939290 - val_trvae_loss: 1115.5979003906 - val_landmark_loss: 0.8987954656 - val_labeled_loss: 0.8987954656 |███████████████████-| 96.0%  - val_loss: 1117.6549275716 - val_trvae_loss: 1116.8965454102 - val_landmark_loss: 0.7583830406 - val_labeled_loss: 0.7583830406 |███████████████████-| 97.0%  - val_loss: 1116.0515238444 - val_trvae_loss: 1115.2558593750 - val_landmark_loss: 0.7956577390 - val_labeled_loss: 0.7956577390 |███████████████████-| 98.0%  - val_loss: 1114.0132853190 - val_trvae_loss: 1113.2835286458 - val_landmark_loss: 0.7297716836 - val_labeled_loss: 0.7297716836 |███████████████████-| 99.0%  - val_loss: 1116.5180460612 - val_trvae_loss: 1115.8252360026 - val_landmark_loss: 0.6928155969 - val_labeled_loss: 0.6928155969 |████████████████████| 100.0%  - val_loss: 1116.2987874349 - val_trvae_loss: 1115.5697428385 - val_landmark_loss: 0.7290482720 - val_labeled_loss: 0.7290482720
2021-10-26 10:59:33 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 1492 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 889.5056152344 - val_trvae_loss: 889.5056152344 |--------------------| 2.0%  - val_loss: 887.1618957520 - val_trvae_loss: 887.1618957520 |--------------------| 3.0%  - val_loss: 878.5668640137 - val_trvae_loss: 878.5668640137 |--------------------| 4.0%  - val_loss: 883.8085632324 - val_trvae_loss: 883.8085632324 |█-------------------| 5.0%  - val_loss: 873.5347290039 - val_trvae_loss: 873.5347290039 |█-------------------| 6.0%  - val_loss: 899.7505493164 - val_trvae_loss: 899.7505493164 |█-------------------| 7.0%  - val_loss: 862.2453308105 - val_trvae_loss: 862.2453308105 |█-------------------| 8.0%  - val_loss: 886.8139038086 - val_trvae_loss: 886.8139038086 |█-------------------| 9.0%  - val_loss: 870.0560302734 - val_trvae_loss: 870.0560302734 |██------------------| 10.0%  - val_loss: 916.9518432617 - val_trvae_loss: 916.9518432617 |██------------------| 11.0%  - val_loss: 898.5192565918 - val_trvae_loss: 898.5192565918 |██------------------| 12.0%  - val_loss: 900.7183227539 - val_trvae_loss: 900.7183227539 |██------------------| 13.0%  - val_loss: 866.3791809082 - val_trvae_loss: 866.3791809082 |██------------------| 14.0%  - val_loss: 863.9807434082 - val_trvae_loss: 863.9807434082 |███-----------------| 15.0%  - val_loss: 883.6913146973 - val_trvae_loss: 883.6913146973 |███-----------------| 16.0%  - val_loss: 878.6152343750 - val_trvae_loss: 878.6152343750 |███-----------------| 17.0%  - val_loss: 877.3927001953 - val_trvae_loss: 877.3927001953 |███-----------------| 18.0%  - val_loss: 898.6658630371 - val_trvae_loss: 898.6658630371 |███-----------------| 19.0%  - val_loss: 883.8913574219 - val_trvae_loss: 883.8913574219 |████----------------| 20.0%  - val_loss: 888.5150756836 - val_trvae_loss: 888.5150756836 |████----------------| 21.0%  - val_loss: 874.5875549316 - val_trvae_loss: 874.5875549316 |████----------------| 22.0%  - val_loss: 884.2015991211 - val_trvae_loss: 884.2015991211 |████----------------| 23.0%  - val_loss: 886.6217041016 - val_trvae_loss: 886.6217041016 |████----------------| 24.0%  - val_loss: 878.6994934082 - val_trvae_loss: 878.6994934082 |█████---------------| 25.0%  - val_loss: 893.8638916016 - val_trvae_loss: 893.8638916016 |█████---------------| 26.0%  - val_loss: 877.5727233887 - val_trvae_loss: 877.5727233887 |█████---------------| 27.0%  - val_loss: 881.5739440918 - val_trvae_loss: 881.5739440918 |█████---------------| 28.0%  - val_loss: 879.2930603027 - val_trvae_loss: 879.2930603027 |█████---------------| 29.0%  - val_loss: 858.8901367188 - val_trvae_loss: 858.8901367188 |██████--------------| 30.0%  - val_loss: 873.3561706543 - val_trvae_loss: 873.3561706543 |██████--------------| 31.0%  - val_loss: 886.2075500488 - val_trvae_loss: 886.2075500488 |██████--------------| 32.0%  - val_loss: 882.7067871094 - val_trvae_loss: 882.7067871094 |██████--------------| 33.0%  - val_loss: 913.5240783691 - val_trvae_loss: 913.5240783691 |██████--------------| 34.0%  - val_loss: 872.7417602539 - val_trvae_loss: 872.7417602539 |███████-------------| 35.0%  - val_loss: 851.4759216309 - val_trvae_loss: 851.4759216309 |███████-------------| 36.0%  - val_loss: 887.1763305664 - val_trvae_loss: 887.1763305664 |███████-------------| 37.0%  - val_loss: 862.1212463379 - val_trvae_loss: 862.1212463379 |███████-------------| 38.0%  - val_loss: 874.8694152832 - val_trvae_loss: 874.8694152832 |███████-------------| 39.0%  - val_loss: 878.9137573242 - val_trvae_loss: 878.9137573242 |████████------------| 40.0%  - val_loss: 901.5098571777 - val_trvae_loss: 901.5098571777 |████████------------| 41.0%  - val_loss: 860.7893371582 - val_trvae_loss: 860.7893371582 |████████------------| 42.0%  - val_loss: 880.2613830566 - val_trvae_loss: 880.2613830566 |████████------------| 43.0%  - val_loss: 851.3449096680 - val_trvae_loss: 851.3449096680 |████████------------| 44.0%  - val_loss: 880.3518371582 - val_trvae_loss: 880.3518371582 |█████████-----------| 45.0%  - val_loss: 879.2796630859 - val_trvae_loss: 879.2796630859 |█████████-----------| 46.0%  - val_loss: 876.1609802246 - val_trvae_loss: 876.1609802246 |█████████-----------| 47.0%  - val_loss: 881.6824340820 - val_trvae_loss: 881.6824340820 |█████████-----------| 48.0%  - val_loss: 882.2258911133 - val_trvae_loss: 882.2258911133 |█████████-----------| 49.0%  - val_loss: 888.4111633301 - val_trvae_loss: 888.4111633301 |██████████----------| 50.0%  - val_loss: 884.2837219238 - val_trvae_loss: 884.2837219238 |██████████----------| 51.0%  - val_loss: 865.5005493164 - val_trvae_loss: 865.5005493164 |██████████----------| 52.0%  - val_loss: 876.4293518066 - val_trvae_loss: 876.4293518066 |██████████----------| 53.0%  - val_loss: 857.2848205566 - val_trvae_loss: 857.2848205566 |██████████----------| 54.0%  - val_loss: 870.5796813965 - val_trvae_loss: 870.5796813965 |███████████---------| 55.0%  - val_loss: 863.1429748535 - val_trvae_loss: 863.1429748535 |███████████---------| 56.0%  - val_loss: 885.4711608887 - val_trvae_loss: 885.4711608887 |███████████---------| 57.0%  - val_loss: 849.2962951660 - val_trvae_loss: 849.2962951660 |███████████---------| 58.0%  - val_loss: 876.3353271484 - val_trvae_loss: 876.3353271484 |███████████---------| 59.0%  - val_loss: 885.2255859375 - val_trvae_loss: 885.2255859375 |████████████--------| 60.0%  - val_loss: 876.4469909668 - val_trvae_loss: 876.4469909668 |████████████--------| 61.0%  - val_loss: 872.6721801758 - val_trvae_loss: 872.6721801758 |████████████--------| 62.0%  - val_loss: 872.0747375488 - val_trvae_loss: 872.0747375488 |████████████--------| 63.0%  - val_loss: 858.9391784668 - val_trvae_loss: 858.9391784668 |████████████--------| 64.0%  - val_loss: 870.7163085938 - val_trvae_loss: 870.7163085938 |█████████████-------| 65.0%  - val_loss: 853.8529663086 - val_trvae_loss: 853.8529663086 |█████████████-------| 66.0%  - val_loss: 857.0404968262 - val_trvae_loss: 857.0404968262 |█████████████-------| 67.0%  - val_loss: 864.0806274414 - val_trvae_loss: 864.0806274414 |█████████████-------| 68.0%  - val_loss: 891.7690124512 - val_trvae_loss: 891.7690124512 |█████████████-------| 69.0%  - val_loss: 897.9417724609 - val_trvae_loss: 897.9417724609 |██████████████------| 70.0%  - val_loss: 873.5631713867 - val_trvae_loss: 873.5631713867 |██████████████------| 71.0%  - val_loss: 890.5415344238 - val_trvae_loss: 890.5415344238 |██████████████------| 72.0%  - val_loss: 861.3566589355 - val_trvae_loss: 861.3566589355 |██████████████------| 73.0%  - val_loss: 867.7605895996 - val_trvae_loss: 867.7605895996 |██████████████------| 74.0%  - val_loss: 901.4566650391 - val_trvae_loss: 901.4566650391 |███████████████-----| 75.0%  - val_loss: 848.5140991211 - val_trvae_loss: 848.5140991211 |███████████████-----| 76.0%  - val_loss: 859.1542663574 - val_trvae_loss: 859.1542663574 |███████████████-----| 77.0%  - val_loss: 896.2336730957 - val_trvae_loss: 896.2336730957 |███████████████-----| 78.0%  - val_loss: 869.5743713379 - val_trvae_loss: 869.5743713379 |███████████████-----| 79.0%  - val_loss: 893.7787475586 - val_trvae_loss: 893.7787475586 |████████████████----| 80.0%  - val_loss: 856.6701660156 - val_trvae_loss: 856.6701660156
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 12 clusters.
 |████████████████----| 81.0%  - val_loss: 882.9961242676 - val_trvae_loss: 882.9960327148 - val_landmark_loss: 0.0000964732 - val_unlabeled_loss: 0.0964731537 |████████████████----| 82.0%  - val_loss: 858.9513244629 - val_trvae_loss: 858.9512634277 - val_landmark_loss: 0.0000474461 - val_unlabeled_loss: 0.0474460889 |████████████████----| 83.0%  - val_loss: 851.3641662598 - val_trvae_loss: 851.3641052246 - val_landmark_loss: 0.0000547901 - val_unlabeled_loss: 0.0547900833 |████████████████----| 84.0%  - val_loss: 878.7599182129 - val_trvae_loss: 878.7598571777 - val_landmark_loss: 0.0000533308 - val_unlabeled_loss: 0.0533307791 |█████████████████---| 85.0%  - val_loss: 875.6713256836 - val_trvae_loss: 875.6712036133 - val_landmark_loss: 0.0001143158 - val_unlabeled_loss: 0.1143158339 |█████████████████---| 86.0%  - val_loss: 868.6334838867 - val_trvae_loss: 868.6334228516 - val_landmark_loss: 0.0000492263 - val_unlabeled_loss: 0.0492263138 |█████████████████---| 87.0%  - val_loss: 853.3226013184 - val_trvae_loss: 853.3225708008 - val_landmark_loss: 0.0000450269 - val_unlabeled_loss: 0.0450269282 |█████████████████---| 88.0%  - val_loss: 839.3919372559 - val_trvae_loss: 839.3918762207 - val_landmark_loss: 0.0000478894 - val_unlabeled_loss: 0.0478893854 |█████████████████---| 89.0%  - val_loss: 880.2083129883 - val_trvae_loss: 880.2082519531 - val_landmark_loss: 0.0000501913 - val_unlabeled_loss: 0.0501912963 |██████████████████--| 90.0%  - val_loss: 882.4014587402 - val_trvae_loss: 882.4013977051 - val_landmark_loss: 0.0000509705 - val_unlabeled_loss: 0.0509704910 |██████████████████--| 91.0%  - val_loss: 865.3338928223 - val_trvae_loss: 865.3338317871 - val_landmark_loss: 0.0000480299 - val_unlabeled_loss: 0.0480299089 |██████████████████--| 92.0%  - val_loss: 869.0812988281 - val_trvae_loss: 869.0812377930 - val_landmark_loss: 0.0000476636 - val_unlabeled_loss: 0.0476636253 |██████████████████--| 93.0%  - val_loss: 875.0297241211 - val_trvae_loss: 875.0296630859 - val_landmark_loss: 0.0000458659 - val_unlabeled_loss: 0.0458659083 |██████████████████--| 94.0%  - val_loss: 857.5786132812 - val_trvae_loss: 857.5785522461 - val_landmark_loss: 0.0000459140 - val_unlabeled_loss: 0.0459139906 |███████████████████-| 95.0%  - val_loss: 862.0279541016 - val_trvae_loss: 862.0278930664 - val_landmark_loss: 0.0000587076 - val_unlabeled_loss: 0.0587075595 |███████████████████-| 96.0%  - val_loss: 854.4483642578 - val_trvae_loss: 854.4483032227 - val_landmark_loss: 0.0000486549 - val_unlabeled_loss: 0.0486549158 |███████████████████-| 97.0%  - val_loss: 871.7350769043 - val_trvae_loss: 871.7350158691 - val_landmark_loss: 0.0000476887 - val_unlabeled_loss: 0.0476886872 |███████████████████-| 98.0%  - val_loss: 834.0390930176 - val_trvae_loss: 834.0390319824 - val_landmark_loss: 0.0000438375 - val_unlabeled_loss: 0.0438374672 |███████████████████-| 99.0%  - val_loss: 866.3119812012 - val_trvae_loss: 866.3119201660 - val_landmark_loss: 0.0000464619 - val_unlabeled_loss: 0.0464619175 |████████████████████| 100.0%  - val_loss: 874.2539978027 - val_trvae_loss: 874.2539062500 - val_landmark_loss: 0.0000769332 - val_unlabeled_loss: 0.0769331530
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 10:59:54 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 10:59:55 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
slurmstepd: error: *** JOB 3781270 ON gpusrv11 CANCELLED AT 2021-10-26T11:01:37 ***
