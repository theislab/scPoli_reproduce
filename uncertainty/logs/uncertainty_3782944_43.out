Starting job 3783078
SLURM assigned me the node(s): gpusrv11
Experiments are running under the following process IDs:
Experiment ID: 44	Process ID: 62373

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 15:54:17 (INFO): Running command 'run'
2021-10-26 15:54:17 (INFO): Started run with ID "44"
2021-10-26 15:54:18 (INFO): Data loaded succesfully
2021-10-26 15:54:18 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1183.3928000710 - val_trvae_loss: 1183.3928000710 |--------------------| 2.0%  - val_loss: 1135.2928133878 - val_trvae_loss: 1135.2928133878 |--------------------| 3.0%  - val_loss: 1102.0225053267 - val_trvae_loss: 1102.0225053267 |--------------------| 4.0%  - val_loss: 1089.3499755859 - val_trvae_loss: 1089.3499755859 |█-------------------| 5.0%  - val_loss: 1080.0841397372 - val_trvae_loss: 1080.0841397372 |█-------------------| 6.0%  - val_loss: 1071.9745205966 - val_trvae_loss: 1071.9745205966 |█-------------------| 7.0%  - val_loss: 1065.4855180220 - val_trvae_loss: 1065.4855180220 |█-------------------| 8.0%  - val_loss: 1060.1215098988 - val_trvae_loss: 1060.1215098988 |█-------------------| 9.0%  - val_loss: 1056.3638971502 - val_trvae_loss: 1056.3638971502 |██------------------| 10.0%  - val_loss: 1053.2114313299 - val_trvae_loss: 1053.2114313299 |██------------------| 11.0%  - val_loss: 1050.2765114524 - val_trvae_loss: 1050.2765114524 |██------------------| 12.0%  - val_loss: 1048.1677301580 - val_trvae_loss: 1048.1677301580 |██------------------| 13.0%  - val_loss: 1045.9834761186 - val_trvae_loss: 1045.9834761186 |██------------------| 14.0%  - val_loss: 1043.8223765980 - val_trvae_loss: 1043.8223765980 |███-----------------| 15.0%  - val_loss: 1042.7143554688 - val_trvae_loss: 1042.7143554688 |███-----------------| 16.0%  - val_loss: 1040.7453446822 - val_trvae_loss: 1040.7453446822 |███-----------------| 17.0%  - val_loss: 1039.4605047053 - val_trvae_loss: 1039.4605047053 |███-----------------| 18.0%  - val_loss: 1038.5786632191 - val_trvae_loss: 1038.5786632191 |███-----------------| 19.0%  - val_loss: 1037.3842052113 - val_trvae_loss: 1037.3842052113 |████----------------| 20.0%  - val_loss: 1035.8931440874 - val_trvae_loss: 1035.8931440874 |████----------------| 21.0%  - val_loss: 1034.9623579545 - val_trvae_loss: 1034.9623579545 |████----------------| 22.0%  - val_loss: 1034.0730035955 - val_trvae_loss: 1034.0730035955 |████----------------| 23.0%  - val_loss: 1034.1325461648 - val_trvae_loss: 1034.1325461648 |████----------------| 24.0%  - val_loss: 1032.9493630149 - val_trvae_loss: 1032.9493630149 |█████---------------| 25.0%  - val_loss: 1032.4225130948 - val_trvae_loss: 1032.4225130948 |█████---------------| 26.0%  - val_loss: 1031.5674493963 - val_trvae_loss: 1031.5674493963 |█████---------------| 27.0%  - val_loss: 1031.0667502663 - val_trvae_loss: 1031.0667502663 |█████---------------| 28.0%  - val_loss: 1030.6150401722 - val_trvae_loss: 1030.6150401722 |█████---------------| 29.0%  - val_loss: 1030.0711392489 - val_trvae_loss: 1030.0711392489 |██████--------------| 30.0%  - val_loss: 1029.3979214755 - val_trvae_loss: 1029.3979214755 |██████--------------| 31.0%  - val_loss: 1029.2204700817 - val_trvae_loss: 1029.2204700817 |██████--------------| 32.0%  - val_loss: 1028.9393477006 - val_trvae_loss: 1028.9393477006 |██████--------------| 33.0%  - val_loss: 1028.3636696555 - val_trvae_loss: 1028.3636696555 |██████--------------| 34.0%  - val_loss: 1028.0046275746 - val_trvae_loss: 1028.0046275746 |███████-------------| 35.0%  - val_loss: 1027.8872736151 - val_trvae_loss: 1027.8872736151 |███████-------------| 36.0%  - val_loss: 1027.4695101651 - val_trvae_loss: 1027.4695101651 |███████-------------| 37.0%  - val_loss: 1027.8037886186 - val_trvae_loss: 1027.8037886186 |███████-------------| 38.0%  - val_loss: 1027.0896661932 - val_trvae_loss: 1027.0896661932 |███████-------------| 39.0%  - val_loss: 1026.7147938121 - val_trvae_loss: 1026.7147938121 |████████------------| 40.0%  - val_loss: 1026.6648781516 - val_trvae_loss: 1026.6648781516 |████████------------| 41.0%  - val_loss: 1026.6423839222 - val_trvae_loss: 1026.6423839222 |████████------------| 42.0%  - val_loss: 1026.6014348810 - val_trvae_loss: 1026.6014348810 |████████------------| 43.0%  - val_loss: 1027.0127397017 - val_trvae_loss: 1027.0127397017 |████████------------| 44.0%  - val_loss: 1025.9643610174 - val_trvae_loss: 1025.9643610174 |█████████-----------| 45.0%  - val_loss: 1026.2533569336 - val_trvae_loss: 1026.2533569336 |█████████-----------| 46.0%  - val_loss: 1026.0546264648 - val_trvae_loss: 1026.0546264648 |█████████-----------| 47.0%  - val_loss: 1025.8867908825 - val_trvae_loss: 1025.8867908825 |█████████-----------| 48.0%  - val_loss: 1025.5501320579 - val_trvae_loss: 1025.5501320579 |█████████-----------| 49.0%  - val_loss: 1025.8981378729 - val_trvae_loss: 1025.8981378729 |██████████----------| 50.0%  - val_loss: 1025.7230557528 - val_trvae_loss: 1025.7230557528 |██████████----------| 51.0%  - val_loss: 1025.3419189453 - val_trvae_loss: 1025.3419189453 |██████████----------| 52.0%  - val_loss: 1025.3894375888 - val_trvae_loss: 1025.3894375888 |██████████----------| 53.0%  - val_loss: 1025.3112349077 - val_trvae_loss: 1025.3112349077 |██████████----------| 54.0%  - val_loss: 1025.0626775568 - val_trvae_loss: 1025.0626775568 |███████████---------| 55.0%  - val_loss: 1025.4315407493 - val_trvae_loss: 1025.4315407493 |███████████---------| 56.0%  - val_loss: 1024.6697443182 - val_trvae_loss: 1024.6697443182 |███████████---------| 57.0%  - val_loss: 1024.9597944780 - val_trvae_loss: 1024.9597944780 |███████████---------| 58.0%  - val_loss: 1024.5657515092 - val_trvae_loss: 1024.5657515092 |███████████---------| 59.0%  - val_loss: 1024.2296919389 - val_trvae_loss: 1024.2296919389 |████████████--------| 60.0%  - val_loss: 1024.5220558860 - val_trvae_loss: 1024.5220558860 |████████████--------| 61.0%  - val_loss: 1024.4611483487 - val_trvae_loss: 1024.4611483487 |████████████--------| 62.0%  - val_loss: 1024.0022139116 - val_trvae_loss: 1024.0022139116 |████████████--------| 63.0%  - val_loss: 1024.8538818359 - val_trvae_loss: 1024.8538818359 |████████████--------| 64.0%  - val_loss: 1024.4597112482 - val_trvae_loss: 1024.4597112482 |█████████████-------| 65.0%  - val_loss: 1024.0483231978 - val_trvae_loss: 1024.0483231978 |█████████████-------| 66.0%  - val_loss: 1024.5376032049 - val_trvae_loss: 1024.5376032049 |█████████████-------| 67.0%  - val_loss: 1024.0930342241 - val_trvae_loss: 1024.0930342241 |█████████████-------| 68.0%  - val_loss: 1024.1881103516 - val_trvae_loss: 1024.1881103516 |█████████████-------| 69.0%  - val_loss: 1023.8843217330 - val_trvae_loss: 1023.8843217330 |██████████████------| 70.0%  - val_loss: 1024.2494950728 - val_trvae_loss: 1024.2494950728 |██████████████------| 71.0%  - val_loss: 1024.0707286488 - val_trvae_loss: 1024.0707286488 |██████████████------| 72.0%  - val_loss: 1023.8853149414 - val_trvae_loss: 1023.8853149414 |██████████████------| 73.0%  - val_loss: 1023.9918712269 - val_trvae_loss: 1023.9918712269 |██████████████------| 74.0%  - val_loss: 1023.5942382812 - val_trvae_loss: 1023.5942382812 |███████████████-----| 75.0%  - val_loss: 1024.0620172674 - val_trvae_loss: 1024.0620172674 |███████████████-----| 76.0%  - val_loss: 1023.7443015359 - val_trvae_loss: 1023.7443015359 |███████████████-----| 77.0%  - val_loss: 1023.8180486506 - val_trvae_loss: 1023.8180486506 |███████████████-----| 78.0%  - val_loss: 1023.9633733576 - val_trvae_loss: 1023.9633733576 |███████████████-----| 79.0%  - val_loss: 1023.6532315341 - val_trvae_loss: 1023.6532315341 |████████████████----| 80.0%  - val_loss: 1023.6312866211 - val_trvae_loss: 1023.6312866211 |████████████████----| 81.0%  - val_loss: 1029.6521939364 - val_trvae_loss: 1025.8842052113 - val_landmark_loss: 3.7679772160 - val_labeled_loss: 3.7679772160 |████████████████----| 82.0%  - val_loss: 1028.3380071467 - val_trvae_loss: 1025.5643587979 - val_landmark_loss: 2.7736480344 - val_labeled_loss: 2.7736480344 |████████████████----| 83.0%  - val_loss: 1028.0402610085 - val_trvae_loss: 1025.4150224165 - val_landmark_loss: 2.6252347014 - val_labeled_loss: 2.6252347014 |████████████████----| 84.0%  - val_loss: 1027.5664228960 - val_trvae_loss: 1025.2669455788 - val_landmark_loss: 2.2994777723 - val_labeled_loss: 2.2994777723 |█████████████████---| 85.0%  - val_loss: 1027.0241477273 - val_trvae_loss: 1025.0811934038 - val_landmark_loss: 1.9429495335 - val_labeled_loss: 1.9429495335 |█████████████████---| 86.0%  - val_loss: 1027.2880526456 - val_trvae_loss: 1025.1533591531 - val_landmark_loss: 2.1346877055 - val_labeled_loss: 2.1346877055 |█████████████████---| 87.0%  - val_loss: 1026.5215509588 - val_trvae_loss: 1024.7350685813 - val_landmark_loss: 1.7864845774 - val_labeled_loss: 1.7864845774 |█████████████████---| 88.0%  - val_loss: 1026.7915982333 - val_trvae_loss: 1024.8984707919 - val_landmark_loss: 1.8931228139 - val_labeled_loss: 1.8931228139 |█████████████████---| 89.0%  - val_loss: 1025.6019453569 - val_trvae_loss: 1024.1059681286 - val_landmark_loss: 1.4959683852 - val_labeled_loss: 1.4959683852 |██████████████████--| 90.0%  - val_loss: 1026.2619240501 - val_trvae_loss: 1024.4040638317 - val_landmark_loss: 1.8578648242 - val_labeled_loss: 1.8578648242 |██████████████████--| 91.0%  - val_loss: 1025.8551524769 - val_trvae_loss: 1024.2357177734 - val_landmark_loss: 1.6194250909 - val_labeled_loss: 1.6194250909 |██████████████████--| 92.0%  - val_loss: 1026.3889825994 - val_trvae_loss: 1024.7447454279 - val_landmark_loss: 1.6442462910 - val_labeled_loss: 1.6442462910 |██████████████████--| 93.0%  - val_loss: 1027.3464577415 - val_trvae_loss: 1025.9103892933 - val_landmark_loss: 1.4360691255 - val_labeled_loss: 1.4360691255 |██████████████████--| 94.0%  - val_loss: 1025.5653353604 - val_trvae_loss: 1024.2530573065 - val_landmark_loss: 1.3122673902 - val_labeled_loss: 1.3122673902 |███████████████████-| 95.0%  - val_loss: 1025.6690451882 - val_trvae_loss: 1024.4144564542 - val_landmark_loss: 1.2545918389 - val_labeled_loss: 1.2545918389 |███████████████████-| 96.0%  - val_loss: 1026.2122025923 - val_trvae_loss: 1024.8939874822 - val_landmark_loss: 1.3182118643 - val_labeled_loss: 1.3182118643 |███████████████████-| 97.0%  - val_loss: 1025.7660744407 - val_trvae_loss: 1024.5695800781 - val_landmark_loss: 1.1964948719 - val_labeled_loss: 1.1964948719 |███████████████████-| 98.0%  - val_loss: 1025.4033036665 - val_trvae_loss: 1024.2680275657 - val_landmark_loss: 1.1352892626 - val_labeled_loss: 1.1352892626 |███████████████████-| 99.0%  - val_loss: 1025.3601351651 - val_trvae_loss: 1024.2506769354 - val_landmark_loss: 1.1094549136 - val_labeled_loss: 1.1094549136 |████████████████████| 100.0%  - val_loss: 1024.9513438832 - val_trvae_loss: 1023.9000743519 - val_landmark_loss: 1.0512619831 - val_labeled_loss: 1.0512619831
2021-10-26 15:56:19 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 2285 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 2059.2270507812 - val_trvae_loss: 2059.2270507812 |--------------------| 2.0%  - val_loss: 2057.9575195312 - val_trvae_loss: 2057.9575195312 |--------------------| 3.0%  - val_loss: 2056.3769531250 - val_trvae_loss: 2056.3769531250 |--------------------| 4.0%  - val_loss: 2050.7453613281 - val_trvae_loss: 2050.7453613281 |█-------------------| 5.0%  - val_loss: 2049.0422363281 - val_trvae_loss: 2049.0422363281 |█-------------------| 6.0%  - val_loss: 2047.3662109375 - val_trvae_loss: 2047.3662109375 |█-------------------| 7.0%  - val_loss: 2045.6890869141 - val_trvae_loss: 2045.6890869141 |█-------------------| 8.0%  - val_loss: 2043.4334106445 - val_trvae_loss: 2043.4334106445 |█-------------------| 9.0%  - val_loss: 2038.7823486328 - val_trvae_loss: 2038.7823486328 |██------------------| 10.0%  - val_loss: 2039.3823852539 - val_trvae_loss: 2039.3823852539 |██------------------| 11.0%  - val_loss: 2035.9256591797 - val_trvae_loss: 2035.9256591797 |██------------------| 12.0%  - val_loss: 2034.4182128906 - val_trvae_loss: 2034.4182128906 |██------------------| 13.0%  - val_loss: 2031.8302001953 - val_trvae_loss: 2031.8302001953 |██------------------| 14.0%  - val_loss: 2028.4304809570 - val_trvae_loss: 2028.4304809570 |███-----------------| 15.0%  - val_loss: 2026.9612426758 - val_trvae_loss: 2026.9612426758 |███-----------------| 16.0%  - val_loss: 2025.2972412109 - val_trvae_loss: 2025.2972412109 |███-----------------| 17.0%  - val_loss: 2021.7092285156 - val_trvae_loss: 2021.7092285156 |███-----------------| 18.0%  - val_loss: 2019.3180541992 - val_trvae_loss: 2019.3180541992 |███-----------------| 19.0%  - val_loss: 2018.6586303711 - val_trvae_loss: 2018.6586303711 |████----------------| 20.0%  - val_loss: 2017.0583496094 - val_trvae_loss: 2017.0583496094 |████----------------| 21.0%  - val_loss: 2013.9887695312 - val_trvae_loss: 2013.9887695312 |████----------------| 22.0%  - val_loss: 2013.5514526367 - val_trvae_loss: 2013.5514526367 |████----------------| 23.0%  - val_loss: 2011.0484619141 - val_trvae_loss: 2011.0484619141 |████----------------| 24.0%  - val_loss: 2010.6503906250 - val_trvae_loss: 2010.6503906250 |█████---------------| 25.0%  - val_loss: 2007.1749267578 - val_trvae_loss: 2007.1749267578 |█████---------------| 26.0%  - val_loss: 2005.5794677734 - val_trvae_loss: 2005.5794677734 |█████---------------| 27.0%  - val_loss: 2003.2854003906 - val_trvae_loss: 2003.2854003906 |█████---------------| 28.0%  - val_loss: 2001.3516845703 - val_trvae_loss: 2001.3516845703 |█████---------------| 29.0%  - val_loss: 2002.4601440430 - val_trvae_loss: 2002.4601440430 |██████--------------| 30.0%  - val_loss: 1997.4445190430 - val_trvae_loss: 1997.4445190430 |██████--------------| 31.0%  - val_loss: 1997.4421997070 - val_trvae_loss: 1997.4421997070 |██████--------------| 32.0%  - val_loss: 1994.2653808594 - val_trvae_loss: 1994.2653808594 |██████--------------| 33.0%  - val_loss: 1992.9227294922 - val_trvae_loss: 1992.9227294922 |██████--------------| 34.0%  - val_loss: 1992.7757568359 - val_trvae_loss: 1992.7757568359 |███████-------------| 35.0%  - val_loss: 1990.5330810547 - val_trvae_loss: 1990.5330810547 |███████-------------| 36.0%  - val_loss: 1989.5059204102 - val_trvae_loss: 1989.5059204102 |███████-------------| 37.0%  - val_loss: 1987.7760009766 - val_trvae_loss: 1987.7760009766 |███████-------------| 38.0%  - val_loss: 1986.1134643555 - val_trvae_loss: 1986.1134643555 |███████-------------| 39.0%  - val_loss: 1984.1813964844 - val_trvae_loss: 1984.1813964844 |████████------------| 40.0%  - val_loss: 1985.8787231445 - val_trvae_loss: 1985.8787231445 |████████------------| 41.0%  - val_loss: 1983.2498168945 - val_trvae_loss: 1983.2498168945 |████████------------| 42.0%  - val_loss: 1981.8995971680 - val_trvae_loss: 1981.8995971680 |████████------------| 43.0%  - val_loss: 1979.1276245117 - val_trvae_loss: 1979.1276245117 |████████------------| 44.0%  - val_loss: 1978.7180175781 - val_trvae_loss: 1978.7180175781 |█████████-----------| 45.0%  - val_loss: 1977.9444580078 - val_trvae_loss: 1977.9444580078 |█████████-----------| 46.0%  - val_loss: 1977.9285278320 - val_trvae_loss: 1977.9285278320 |█████████-----------| 47.0%  - val_loss: 1975.5037841797 - val_trvae_loss: 1975.5037841797 |█████████-----------| 48.0%  - val_loss: 1974.8071289062 - val_trvae_loss: 1974.8071289062 |█████████-----------| 49.0%  - val_loss: 1973.0761718750 - val_trvae_loss: 1973.0761718750 |██████████----------| 50.0%  - val_loss: 1970.4932861328 - val_trvae_loss: 1970.4932861328 |██████████----------| 51.0%  - val_loss: 1970.1328125000 - val_trvae_loss: 1970.1328125000 |██████████----------| 52.0%  - val_loss: 1969.1533203125 - val_trvae_loss: 1969.1533203125 |██████████----------| 53.0%  - val_loss: 1970.2443237305 - val_trvae_loss: 1970.2443237305 |██████████----------| 54.0%  - val_loss: 1968.3256225586 - val_trvae_loss: 1968.3256225586 |███████████---------| 55.0%  - val_loss: 1966.5966186523 - val_trvae_loss: 1966.5966186523 |███████████---------| 56.0%  - val_loss: 1966.3067016602 - val_trvae_loss: 1966.3067016602 |███████████---------| 57.0%  - val_loss: 1964.9981079102 - val_trvae_loss: 1964.9981079102 |███████████---------| 58.0%  - val_loss: 1963.2352905273 - val_trvae_loss: 1963.2352905273 |███████████---------| 59.0%  - val_loss: 1963.1596069336 - val_trvae_loss: 1963.1596069336 |████████████--------| 60.0%  - val_loss: 1960.2604370117 - val_trvae_loss: 1960.2604370117 |████████████--------| 61.0%  - val_loss: 1958.9858398438 - val_trvae_loss: 1958.9858398438 |████████████--------| 62.0%  - val_loss: 1958.8266601562 - val_trvae_loss: 1958.8266601562 |████████████--------| 63.0%  - val_loss: 1957.9128417969 - val_trvae_loss: 1957.9128417969 |████████████--------| 64.0%  - val_loss: 1956.9784545898 - val_trvae_loss: 1956.9784545898 |█████████████-------| 65.0%  - val_loss: 1954.3684082031 - val_trvae_loss: 1954.3684082031 |█████████████-------| 66.0%  - val_loss: 1956.9183959961 - val_trvae_loss: 1956.9183959961 |█████████████-------| 67.0%  - val_loss: 1954.7455444336 - val_trvae_loss: 1954.7455444336 |█████████████-------| 68.0%  - val_loss: 1953.4808349609 - val_trvae_loss: 1953.4808349609 |█████████████-------| 69.0%  - val_loss: 1951.5291137695 - val_trvae_loss: 1951.5291137695 |██████████████------| 70.0%  - val_loss: 1951.3038940430 - val_trvae_loss: 1951.3038940430 |██████████████------| 71.0%  - val_loss: 1951.7137451172 - val_trvae_loss: 1951.7137451172 |██████████████------| 72.0%  - val_loss: 1952.2528686523 - val_trvae_loss: 1952.2528686523 |██████████████------| 73.0%  - val_loss: 1951.4142456055 - val_trvae_loss: 1951.4142456055 |██████████████------| 74.0%  - val_loss: 1947.4263305664 - val_trvae_loss: 1947.4263305664 |███████████████-----| 75.0%  - val_loss: 1947.5758666992 - val_trvae_loss: 1947.5758666992 |███████████████-----| 76.0%  - val_loss: 1947.3852539062 - val_trvae_loss: 1947.3852539062 |███████████████-----| 77.0%  - val_loss: 1947.9852905273 - val_trvae_loss: 1947.9852905273 |███████████████-----| 78.0%  - val_loss: 1946.4213867188 - val_trvae_loss: 1946.4213867188 |███████████████-----| 79.0%  - val_loss: 1945.4595336914 - val_trvae_loss: 1945.4595336914 |████████████████----| 80.0%  - val_loss: 1944.6350708008 - val_trvae_loss: 1944.6350708008
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 12 clusters.
 |████████████████----| 81.0%  - val_loss: 1944.0447387695 - val_trvae_loss: 1944.0419311523 - val_landmark_loss: 0.0027865977 - val_unlabeled_loss: 2.7865974903 |████████████████----| 82.0%  - val_loss: 1943.9697875977 - val_trvae_loss: 1943.9675292969 - val_landmark_loss: 0.0022468733 - val_unlabeled_loss: 2.2468732595 |████████████████----| 83.0%  - val_loss: 1942.7843017578 - val_trvae_loss: 1942.7817993164 - val_landmark_loss: 0.0025280269 - val_unlabeled_loss: 2.5280268192 |████████████████----| 84.0%  - val_loss: 1943.8601074219 - val_trvae_loss: 1943.8578491211 - val_landmark_loss: 0.0022417519 - val_unlabeled_loss: 2.2417517900 |█████████████████---| 85.0%  - val_loss: 1941.4367065430 - val_trvae_loss: 1941.4344482422 - val_landmark_loss: 0.0022657493 - val_unlabeled_loss: 2.2657492161 |█████████████████---| 86.0%  - val_loss: 1940.9105834961 - val_trvae_loss: 1940.9083251953 - val_landmark_loss: 0.0022674727 - val_unlabeled_loss: 2.2674725652 |█████████████████---| 87.0%  - val_loss: 1939.0452880859 - val_trvae_loss: 1939.0430297852 - val_landmark_loss: 0.0022603673 - val_unlabeled_loss: 2.2603671551 |█████████████████---| 88.0%  - val_loss: 1939.6520996094 - val_trvae_loss: 1939.6490478516 - val_landmark_loss: 0.0030619389 - val_unlabeled_loss: 3.0619387627 |█████████████████---| 89.0%  - val_loss: 1939.5275878906 - val_trvae_loss: 1939.5253295898 - val_landmark_loss: 0.0022463185 - val_unlabeled_loss: 2.2463183403 |██████████████████--| 90.0%  - val_loss: 1937.6914062500 - val_trvae_loss: 1937.6888427734 - val_landmark_loss: 0.0025276548 - val_unlabeled_loss: 2.5276546478 |██████████████████--| 91.0%  - val_loss: 1938.9770507812 - val_trvae_loss: 1938.9745483398 - val_landmark_loss: 0.0025221113 - val_unlabeled_loss: 2.5221111774 |██████████████████--| 92.0%  - val_loss: 1938.6559448242 - val_trvae_loss: 1938.6528930664 - val_landmark_loss: 0.0030556499 - val_unlabeled_loss: 3.0556497574 |██████████████████--| 93.0%  - val_loss: 1936.2369995117 - val_trvae_loss: 1936.2347412109 - val_landmark_loss: 0.0022622584 - val_unlabeled_loss: 2.2622582912 |██████████████████--| 94.0%  - val_loss: 1937.3934936523 - val_trvae_loss: 1937.3909912109 - val_landmark_loss: 0.0025136094 - val_unlabeled_loss: 2.5136092901 |███████████████████-| 95.0%  - val_loss: 1934.2532348633 - val_trvae_loss: 1934.2501831055 - val_landmark_loss: 0.0030633037 - val_unlabeled_loss: 3.0633035898 |███████████████████-| 96.0%  - val_loss: 1936.2695312500 - val_trvae_loss: 1936.2669677734 - val_landmark_loss: 0.0025516863 - val_unlabeled_loss: 2.5516860485 |███████████████████-| 97.0%  - val_loss: 1933.4944458008 - val_trvae_loss: 1933.4919433594 - val_landmark_loss: 0.0025168253 - val_unlabeled_loss: 2.5168251991 |███████████████████-| 98.0%  - val_loss: 1935.7658691406 - val_trvae_loss: 1935.7628784180 - val_landmark_loss: 0.0030229338 - val_unlabeled_loss: 3.0229337215 |███████████████████-| 99.0%  - val_loss: 1934.8742065430 - val_trvae_loss: 1934.8711547852 - val_landmark_loss: 0.0030540052 - val_unlabeled_loss: 3.0540050268 |████████████████████| 100.0%  - val_loss: 1932.2313842773 - val_trvae_loss: 1932.2288208008 - val_landmark_loss: 0.0025172782 - val_unlabeled_loss: 2.5172780752
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
Saving best state of network...
Best State was in Epoch 83
2021-10-26 15:56:43 (ERROR): Failed after 0:02:26!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/tmp/3563/uncertainty/uncertainty_seml.py", line 143, in run
    eucl_dist = euclidean_distances(embedding)
NameError: name 'euclidean_distances' is not defined

