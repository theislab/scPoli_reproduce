Starting job 8135130
SLURM assigned me the node(s): gpusrv13
gpusrv18
gpusrv13
gpusrv17
gpusrv17
gpusrv16
gpusrv11
gpusrv11
gpusrv10
gpusrv10
gpusrv09
gpusrv09
gpusrv12
gpusrv12
supergpu05
supergpu05
supergpu05
supergpu05
Experiments are running under the following process IDs:
Experiment ID: 20	Process ID: 1268

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 14:14:35 (INFO): Running command 'run'
2022-05-19 14:14:35 (INFO): Started run with ID "20"
2022-05-19 14:14:36 (INFO): Data loaded succesfully
2022-05-19 14:14:36 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.9390974044799805
 |--------------------| 1.0%  - val_loss: 1478.8592317001 - val_trvae_loss: 1478.8592317001 |--------------------| 2.0%  - val_loss: 1437.1981519616 - val_trvae_loss: 1437.1981519616 |--------------------| 3.0%  - val_loss: 1418.2125191067 - val_trvae_loss: 1418.2125191067 |--------------------| 4.0%  - val_loss: 1408.2368747877 - val_trvae_loss: 1408.2368747877 |█-------------------| 5.0%  - val_loss: 1400.1537820567 - val_trvae_loss: 1400.1537820567 |█-------------------| 6.0%  - val_loss: 1393.8356615149 - val_trvae_loss: 1393.8356615149 |█-------------------| 7.0%  - val_loss: 1389.3773140285 - val_trvae_loss: 1389.3773140285 |█-------------------| 8.0%  - val_loss: 1385.4803307575 - val_trvae_loss: 1385.4803307575 |█-------------------| 9.0%  - val_loss: 1383.3476350204 - val_trvae_loss: 1383.3476350204 |██------------------| 10.0%  - val_loss: 1381.8964313010 - val_trvae_loss: 1381.8964313010 |██------------------| 11.0%  - val_loss: 1380.0915739640 - val_trvae_loss: 1380.0915739640 |██------------------| 12.0%  - val_loss: 1377.7266102666 - val_trvae_loss: 1377.7266102666 |██------------------| 13.0%  - val_loss: 1375.7603069803 - val_trvae_loss: 1375.7603069803 |██------------------| 14.0%  - val_loss: 1374.9698698624 - val_trvae_loss: 1374.9698698624 |███-----------------| 15.0%  - val_loss: 1373.0064113451 - val_trvae_loss: 1373.0064113451 |███-----------------| 16.0%  - val_loss: 1372.4517450747 - val_trvae_loss: 1372.4517450747 |███-----------------| 17.0%  - val_loss: 1371.8142726732 - val_trvae_loss: 1371.8142726732 |███-----------------| 18.0%  - val_loss: 1371.4473240065 - val_trvae_loss: 1371.4473240065 |███-----------------| 19.0%  - val_loss: 1371.1121507728 - val_trvae_loss: 1371.1121507728 |████----------------| 20.0%  - val_loss: 1370.9547702955 - val_trvae_loss: 1370.9547702955 |████----------------| 21.0%  - val_loss: 1371.9695301885 - val_trvae_loss: 1371.9695301885 |████----------------| 22.0%  - val_loss: 1369.2017769192 - val_trvae_loss: 1369.2017769192 |████----------------| 23.0%  - val_loss: 1370.3614077361 - val_trvae_loss: 1370.3614077361 |████----------------| 24.0%  - val_loss: 1369.2858727497 - val_trvae_loss: 1369.2858727497 |█████---------------| 25.0%  - val_loss: 1368.9562722911 - val_trvae_loss: 1368.9562722911 |█████---------------| 26.0%  - val_loss: 1368.9115308679 - val_trvae_loss: 1368.9115308679 |█████---------------| 27.0%  - val_loss: 1368.2672278363 - val_trvae_loss: 1368.2672278363 |█████---------------| 28.0%  - val_loss: 1369.7233568274 - val_trvae_loss: 1369.7233568274 |█████---------------| 29.0%  - val_loss: 1369.1257801885 - val_trvae_loss: 1369.1257801885 |██████--------------| 30.0%  - val_loss: 1367.0540134596 - val_trvae_loss: 1367.0540134596 |██████--------------| 31.0%  - val_loss: 1369.6667639691 - val_trvae_loss: 1369.6667639691 |██████--------------| 32.0%  - val_loss: 1369.0343070652 - val_trvae_loss: 1369.0343070652 |██████--------------| 33.0%  - val_loss: 1366.6214334239 - val_trvae_loss: 1366.6214334239 |██████--------------| 34.0%  - val_loss: 1367.2215629246 - val_trvae_loss: 1367.2215629246 |███████-------------| 35.0%  - val_loss: 1369.4417883832 - val_trvae_loss: 1369.4417883832 |███████-------------| 36.0%  - val_loss: 1367.2250764266 - val_trvae_loss: 1367.2250764266 |███████-------------| 37.0%  - val_loss: 1369.5947000255 - val_trvae_loss: 1369.5947000255 |███████-------------| 38.0%  - val_loss: 1366.0583177649 - val_trvae_loss: 1366.0583177649 |███████-------------| 39.0%  - val_loss: 1369.0582275391 - val_trvae_loss: 1369.0582275391 |████████------------| 40.0%  - val_loss: 1369.7243917714 - val_trvae_loss: 1369.7243917714 |████████------------| 41.0%  - val_loss: 1366.5496773098 - val_trvae_loss: 1366.5496773098 |████████------------| 42.0%  - val_loss: 1366.1792522928 - val_trvae_loss: 1366.1792522928 |████████------------| 43.0%  - val_loss: 1365.9936841882 - val_trvae_loss: 1365.9936841882 |████████------------| 44.0%  - val_loss: 1366.1823889691 - val_trvae_loss: 1366.1823889691 |█████████-----------| 45.0%  - val_loss: 1363.9826872452 - val_trvae_loss: 1363.9826872452 |█████████-----------| 46.0%  - val_loss: 1366.5449324898 - val_trvae_loss: 1366.5449324898 |█████████-----------| 47.0%  - val_loss: 1366.0249713400 - val_trvae_loss: 1366.0249713400 |█████████-----------| 48.0%  - val_loss: 1366.4057457965 - val_trvae_loss: 1366.4057457965 |█████████-----------| 49.0%  - val_loss: 1366.3280931556 - val_trvae_loss: 1366.3280931556 |██████████----------| 50.0%  - val_loss: 1366.3732220194 - val_trvae_loss: 1366.3732220194 |██████████----------| 51.0%  - val_loss: 1366.7577116593 - val_trvae_loss: 1366.7577116593 |██████████----------| 52.0%  - val_loss: 1365.8152439283 - val_trvae_loss: 1365.8152439283 |██████████----------| 53.0%  - val_loss: 1368.3462232507 - val_trvae_loss: 1368.3462232507 |██████████----------| 54.0%  - val_loss: 1366.9313168733 - val_trvae_loss: 1366.9313168733 |███████████---------| 55.0%  - val_loss: 1365.5785602072 - val_trvae_loss: 1365.5785602072 |███████████---------| 56.0%  - val_loss: 1365.9830906080 - val_trvae_loss: 1365.9830906080 |███████████---------| 57.0%  - val_loss: 1366.1158553414 - val_trvae_loss: 1366.1158553414 |███████████---------| 58.0%  - val_loss: 1366.3149201766 - val_trvae_loss: 1366.3149201766 |███████████---------| 59.0%  - val_loss: 1368.3537544582 - val_trvae_loss: 1368.3537544582 |████████████--------| 60.0%  - val_loss: 1367.4862591287 - val_trvae_loss: 1367.4862591287 |████████████--------| 61.0%  - val_loss: 1365.6962359885 - val_trvae_loss: 1365.6962359885 |████████████--------| 62.0%  - val_loss: 1365.3469928244 - val_trvae_loss: 1365.3469928244 |████████████--------| 63.0%  - val_loss: 1366.3448114810 - val_trvae_loss: 1366.3448114810 |████████████--------| 64.0%  - val_loss: 1366.3140816067 - val_trvae_loss: 1366.3140816067 |█████████████-------| 65.0%  - val_loss: 1365.0336914062 - val_trvae_loss: 1365.0336914062 |█████████████-------| 66.0%  - val_loss: 1366.0236073370 - val_trvae_loss: 1366.0236073370 |█████████████-------| 67.0%  - val_loss: 1365.5006528108 - val_trvae_loss: 1365.5006528108 |█████████████-------| 68.0%  - val_loss: 1365.4800176206 - val_trvae_loss: 1365.4800176206 |█████████████-------| 69.0%  - val_loss: 1365.2898639181 - val_trvae_loss: 1365.2898639181 |██████████████------| 70.0%  - val_loss: 1365.9300484035 - val_trvae_loss: 1365.9300484035 |██████████████------| 71.0%  - val_loss: 1366.6037013842 - val_trvae_loss: 1366.6037013842 |██████████████------| 72.0%  - val_loss: 1365.7874278193 - val_trvae_loss: 1365.7874278193 |██████████████------| 73.0%  - val_loss: 1364.3996953550 - val_trvae_loss: 1364.3996953550 |██████████████------| 74.0%  - val_loss: 1364.2662035071 - val_trvae_loss: 1364.2662035071 |███████████████-----| 75.0%  - val_loss: 1366.5423265540 - val_trvae_loss: 1366.5423265540 |███████████████-----| 76.0%  - val_loss: 1365.8350670856 - val_trvae_loss: 1365.8350670856 |███████████████-----| 77.0%  - val_loss: 1366.1156218156 - val_trvae_loss: 1366.1156218156 |███████████████-----| 78.0%  - val_loss: 1365.5938561481 - val_trvae_loss: 1365.5938561481 |███████████████-----| 79.0%  - val_loss: 1366.4439591118 - val_trvae_loss: 1366.4439591118 |████████████████----| 80.0%  - val_loss: 1364.7976764181 - val_trvae_loss: 1364.7976764181 |████████████████----| 81.0%  - val_loss: 1385.6433848505 - val_trvae_loss: 1371.6106116253 - val_landmark_loss: 14.0327641031 - val_labeled_loss: 14.0327641031 |████████████████----| 82.0%  - val_loss: 1380.6311990489 - val_trvae_loss: 1369.4537937330 - val_landmark_loss: 11.1774080318 - val_labeled_loss: 11.1774080318 |████████████████----| 83.0%  - val_loss: 1377.2437425696 - val_trvae_loss: 1368.7744034477 - val_landmark_loss: 8.4693338871 - val_labeled_loss: 8.4693338871 |████████████████----| 84.0%  - val_loss: 1376.3912088145 - val_trvae_loss: 1368.7963124151 - val_landmark_loss: 7.5948866865 - val_labeled_loss: 7.5948866865 |█████████████████---| 85.0%  - val_loss: 1374.2366412619 - val_trvae_loss: 1367.9675770635 - val_landmark_loss: 6.2690615343 - val_labeled_loss: 6.2690615343 |█████████████████---| 86.0%  - val_loss: 1373.2864990234 - val_trvae_loss: 1367.2357867697 - val_landmark_loss: 6.0507034633 - val_labeled_loss: 6.0507034633 |█████████████████---| 87.0%  - val_loss: 1372.2483122452 - val_trvae_loss: 1366.6084674338 - val_landmark_loss: 5.6398467603 - val_labeled_loss: 5.6398467603 |█████████████████---| 88.0%  - val_loss: 1372.9269223421 - val_trvae_loss: 1367.5084918478 - val_landmark_loss: 5.4184228545 - val_labeled_loss: 5.4184228545 |█████████████████---| 89.0%  - val_loss: 1372.7620743461 - val_trvae_loss: 1368.0393915591 - val_landmark_loss: 4.7226786821 - val_labeled_loss: 4.7226786821 |██████████████████--| 90.0%  - val_loss: 1369.9213761039 - val_trvae_loss: 1365.5953528363 - val_landmark_loss: 4.3260241125 - val_labeled_loss: 4.3260241125 |██████████████████--| 91.0%  - val_loss: 1370.3784975798 - val_trvae_loss: 1366.6299518088 - val_landmark_loss: 3.7485546651 - val_labeled_loss: 3.7485546651 |██████████████████--| 92.0%  - val_loss: 1369.9896187160 - val_trvae_loss: 1366.3970894192 - val_landmark_loss: 3.5925440685 - val_labeled_loss: 3.5925440685 |██████████████████--| 93.0%  - val_loss: 1371.7494904891 - val_trvae_loss: 1368.2167703380 - val_landmark_loss: 3.5327226027 - val_labeled_loss: 3.5327226027 |██████████████████--| 94.0%  - val_loss: 1369.3908319888 - val_trvae_loss: 1366.2648076596 - val_landmark_loss: 3.1260226758 - val_labeled_loss: 3.1260226758 |███████████████████-| 95.0%  - val_loss: 1369.8621136209 - val_trvae_loss: 1366.7684803838 - val_landmark_loss: 3.0936278779 - val_labeled_loss: 3.0936278779 |███████████████████-| 96.0%  - val_loss: 1371.1150486158 - val_trvae_loss: 1368.1312415082 - val_landmark_loss: 2.9838148770 - val_labeled_loss: 2.9838148770 |███████████████████-| 97.0%  - val_loss: 1368.3724789827 - val_trvae_loss: 1365.8691724694 - val_landmark_loss: 2.5033073944 - val_labeled_loss: 2.5033073944 |███████████████████-| 98.0%  - val_loss: 1370.1709568190 - val_trvae_loss: 1367.4914656929 - val_landmark_loss: 2.6794864043 - val_labeled_loss: 2.6794864043 |███████████████████-| 99.0%  - val_loss: 1368.8793945312 - val_trvae_loss: 1366.6136686906 - val_landmark_loss: 2.2657193256 - val_labeled_loss: 2.2657193256 |████████████████████| 100.0%  - val_loss: 1370.4141208815 - val_trvae_loss: 1367.9604545262 - val_landmark_loss: 2.4536611464 - val_labeled_loss: 2.4536611464
2022-05-19 14:18:40 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 3347 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

3
loaders init
loaders init done
0.028259992599487305
 |--------------------| 1.0%  - val_loss: 905.1072794596 - val_trvae_loss: 905.1072794596 |--------------------| 2.0%  - val_loss: 905.0226236979 - val_trvae_loss: 905.0226236979 |--------------------| 3.0%  - val_loss: 907.1635538737 - val_trvae_loss: 907.1635538737 |--------------------| 4.0%  - val_loss: 910.6959025065 - val_trvae_loss: 910.6959025065 |█-------------------| 5.0%  - val_loss: 908.6597900391 - val_trvae_loss: 908.6597900391 |█-------------------| 6.0%  - val_loss: 910.7110595703 - val_trvae_loss: 910.7110595703 |█-------------------| 7.0%  - val_loss: 903.6387736003 - val_trvae_loss: 903.6387736003 |█-------------------| 8.0%  - val_loss: 908.0748087565 - val_trvae_loss: 908.0748087565 |█-------------------| 9.0%  - val_loss: 905.9323527018 - val_trvae_loss: 905.9323527018 |██------------------| 10.0%  - val_loss: 912.0203247070 - val_trvae_loss: 912.0203247070 |██------------------| 11.0%  - val_loss: 904.2930297852 - val_trvae_loss: 904.2930297852 |██------------------| 12.0%  - val_loss: 906.7971598307 - val_trvae_loss: 906.7971598307 |██------------------| 13.0%  - val_loss: 906.0803833008 - val_trvae_loss: 906.0803833008 |██------------------| 14.0%  - val_loss: 911.4583333333 - val_trvae_loss: 911.4583333333 |███-----------------| 15.0%  - val_loss: 903.3524576823 - val_trvae_loss: 903.3524576823 |███-----------------| 16.0%  - val_loss: 902.1166178385 - val_trvae_loss: 902.1166178385 |███-----------------| 17.0%  - val_loss: 904.4168701172 - val_trvae_loss: 904.4168701172 |███-----------------| 18.0%  - val_loss: 908.8181355794 - val_trvae_loss: 908.8181355794 |███-----------------| 19.0%  - val_loss: 901.4001261393 - val_trvae_loss: 901.4001261393 |████----------------| 20.0%  - val_loss: 898.3566080729 - val_trvae_loss: 898.3566080729 |████----------------| 21.0%  - val_loss: 900.4198811849 - val_trvae_loss: 900.4198811849 |████----------------| 22.0%  - val_loss: 900.0738932292 - val_trvae_loss: 900.0738932292 |████----------------| 23.0%  - val_loss: 900.0490519206 - val_trvae_loss: 900.0490519206 |████----------------| 24.0%  - val_loss: 896.7574055990 - val_trvae_loss: 896.7574055990 |█████---------------| 25.0%  - val_loss: 903.9416707357 - val_trvae_loss: 903.9416707357 |█████---------------| 26.0%  - val_loss: 904.5401407878 - val_trvae_loss: 904.5401407878 |█████---------------| 27.0%  - val_loss: 893.4745279948 - val_trvae_loss: 893.4745279948 |█████---------------| 28.0%  - val_loss: 901.5980631510 - val_trvae_loss: 901.5980631510 |█████---------------| 29.0%  - val_loss: 892.4204101562 - val_trvae_loss: 892.4204101562 |██████--------------| 30.0%  - val_loss: 900.3451131185 - val_trvae_loss: 900.3451131185 |██████--------------| 31.0%  - val_loss: 905.2800292969 - val_trvae_loss: 905.2800292969 |██████--------------| 32.0%  - val_loss: 900.5778808594 - val_trvae_loss: 900.5778808594 |██████--------------| 33.0%  - val_loss: 897.6927490234 - val_trvae_loss: 897.6927490234 |██████--------------| 34.0%  - val_loss: 897.8435262044 - val_trvae_loss: 897.8435262044 |███████-------------| 35.0%  - val_loss: 894.2836303711 - val_trvae_loss: 894.2836303711 |███████-------------| 36.0%  - val_loss: 896.9473470052 - val_trvae_loss: 896.9473470052 |███████-------------| 37.0%  - val_loss: 894.1395874023 - val_trvae_loss: 894.1395874023 |███████-------------| 38.0%  - val_loss: 889.0025024414 - val_trvae_loss: 889.0025024414 |███████-------------| 39.0%  - val_loss: 894.5142415365 - val_trvae_loss: 894.5142415365 |████████------------| 40.0%  - val_loss: 898.4749959310 - val_trvae_loss: 898.4749959310 |████████------------| 41.0%  - val_loss: 891.5899454753 - val_trvae_loss: 891.5899454753 |████████------------| 42.0%  - val_loss: 894.3358764648 - val_trvae_loss: 894.3358764648 |████████------------| 43.0%  - val_loss: 902.5557250977 - val_trvae_loss: 902.5557250977 |████████------------| 44.0%  - val_loss: 897.6132812500 - val_trvae_loss: 897.6132812500 |█████████-----------| 45.0%  - val_loss: 891.9372151693 - val_trvae_loss: 891.9372151693 |█████████-----------| 46.0%  - val_loss: 901.0786946615 - val_trvae_loss: 901.0786946615 |█████████-----------| 47.0%  - val_loss: 900.0932210286 - val_trvae_loss: 900.0932210286 |█████████-----------| 48.0%  - val_loss: 895.9405721029 - val_trvae_loss: 895.9405721029 |█████████-----------| 49.0%  - val_loss: 892.7864786784 - val_trvae_loss: 892.7864786784 |██████████----------| 50.0%  - val_loss: 887.9858601888 - val_trvae_loss: 887.9858601888 |██████████----------| 51.0%  - val_loss: 893.9842732747 - val_trvae_loss: 893.9842732747 |██████████----------| 52.0%  - val_loss: 895.4302368164 - val_trvae_loss: 895.4302368164 |██████████----------| 53.0%  - val_loss: 890.8916829427 - val_trvae_loss: 890.8916829427 |██████████----------| 54.0%  - val_loss: 899.1290486654 - val_trvae_loss: 899.1290486654 |███████████---------| 55.0%  - val_loss: 891.4272257487 - val_trvae_loss: 891.4272257487 |███████████---------| 56.0%  - val_loss: 895.0488077799 - val_trvae_loss: 895.0488077799 |███████████---------| 57.0%  - val_loss: 901.2031860352 - val_trvae_loss: 901.2031860352 |███████████---------| 58.0%  - val_loss: 890.8471272786 - val_trvae_loss: 890.8471272786 |███████████---------| 59.0%  - val_loss: 893.2405802409 - val_trvae_loss: 893.2405802409 |████████████--------| 60.0%  - val_loss: 899.2564086914 - val_trvae_loss: 899.2564086914 |████████████--------| 61.0%  - val_loss: 895.9985555013 - val_trvae_loss: 895.9985555013 |████████████--------| 62.0%  - val_loss: 893.0175984701 - val_trvae_loss: 893.0175984701 |████████████--------| 63.0%  - val_loss: 893.1955362956 - val_trvae_loss: 893.1955362956 |████████████--------| 64.0%  - val_loss: 896.7107747396 - val_trvae_loss: 896.7107747396 |█████████████-------| 65.0%  - val_loss: 901.5004882812 - val_trvae_loss: 901.5004882812 |█████████████-------| 66.0%  - val_loss: 895.4942423503 - val_trvae_loss: 895.4942423503 |█████████████-------| 67.0%  - val_loss: 893.8054809570 - val_trvae_loss: 893.8054809570 |█████████████-------| 68.0%  - val_loss: 892.8898111979 - val_trvae_loss: 892.8898111979 |█████████████-------| 69.0%  - val_loss: 894.7746582031 - val_trvae_loss: 894.7746582031 |██████████████------| 70.0%  - val_loss: 896.0077718099 - val_trvae_loss: 896.0077718099 |██████████████------| 71.0%  - val_loss: 897.9002888997 - val_trvae_loss: 897.9002888997 |██████████████------| 72.0%  - val_loss: 889.7451985677 - val_trvae_loss: 889.7451985677 |██████████████------| 73.0%  - val_loss: 891.9968058268 - val_trvae_loss: 891.9968058268 |██████████████------| 74.0%  - val_loss: 900.4321289062 - val_trvae_loss: 900.4321289062 |███████████████-----| 75.0%  - val_loss: 889.9878743490 - val_trvae_loss: 889.9878743490 |███████████████-----| 76.0%  - val_loss: 903.8079427083 - val_trvae_loss: 903.8079427083 |███████████████-----| 77.0%  - val_loss: 890.7156168620 - val_trvae_loss: 890.7156168620 |███████████████-----| 78.0%  - val_loss: 896.9053344727 - val_trvae_loss: 896.9053344727 |███████████████-----| 79.0%  - val_loss: 892.1242472331 - val_trvae_loss: 892.1242472331 |████████████████----| 80.0%  - val_loss: 891.8782145182 - val_trvae_loss: 891.8782145182
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 16 clusters.
 |████████████████----| 81.0%  - val_loss: 891.4134521484 - val_trvae_loss: 891.4133504232 - val_landmark_loss: 0.0001015555 - val_unlabeled_loss: 0.1015555163 |████████████████----| 82.0%  - val_loss: 893.0790812174 - val_trvae_loss: 893.0789794922 - val_landmark_loss: 0.0000918354 - val_unlabeled_loss: 0.0918354293 |████████████████----| 83.0%  - val_loss: 883.6285807292 - val_trvae_loss: 883.6284586589 - val_landmark_loss: 0.0000947390 - val_unlabeled_loss: 0.0947390149 |████████████████----| 84.0%  - val_loss: 893.8303426107 - val_trvae_loss: 893.8302612305 - val_landmark_loss: 0.0000949844 - val_unlabeled_loss: 0.0949843948 |█████████████████---| 85.0%  - val_loss: 893.2682088216 - val_trvae_loss: 893.2681070964 - val_landmark_loss: 0.0001030447 - val_unlabeled_loss: 0.1030447036 |█████████████████---| 86.0%  - val_loss: 884.1470743815 - val_trvae_loss: 884.1469726562 - val_landmark_loss: 0.0001042581 - val_unlabeled_loss: 0.1042580903 |█████████████████---| 87.0%  - val_loss: 894.4216715495 - val_trvae_loss: 894.4215698242 - val_landmark_loss: 0.0001093254 - val_unlabeled_loss: 0.1093253791 |█████████████████---| 88.0%  - val_loss: 896.6360270182 - val_trvae_loss: 896.6359252930 - val_landmark_loss: 0.0001066087 - val_unlabeled_loss: 0.1066086988 |█████████████████---| 89.0%  - val_loss: 892.6784667969 - val_trvae_loss: 892.6783650716 - val_landmark_loss: 0.0001079424 - val_unlabeled_loss: 0.1079423800 |██████████████████--| 90.0%  - val_loss: 895.1375528971 - val_trvae_loss: 895.1374715169 - val_landmark_loss: 0.0000903739 - val_unlabeled_loss: 0.0903738613 |██████████████████--| 91.0%  - val_loss: 891.3167521159 - val_trvae_loss: 891.3166503906 - val_landmark_loss: 0.0000934533 - val_unlabeled_loss: 0.0934533079 |██████████████████--| 92.0%  - val_loss: 891.9490559896 - val_trvae_loss: 891.9489746094 - val_landmark_loss: 0.0000916782 - val_unlabeled_loss: 0.0916781848 |██████████████████--| 93.0%  - val_loss: 893.4053955078 - val_trvae_loss: 893.4052937826 - val_landmark_loss: 0.0001043373 - val_unlabeled_loss: 0.1043372775 |██████████████████--| 94.0%  - val_loss: 887.7054646810 - val_trvae_loss: 887.7053833008 - val_landmark_loss: 0.0000940289 - val_unlabeled_loss: 0.0940289100 |███████████████████-| 95.0%  - val_loss: 896.1855061849 - val_trvae_loss: 896.1854044596 - val_landmark_loss: 0.0000959025 - val_unlabeled_loss: 0.0959025249 |███████████████████-| 96.0%  - val_loss: 893.0450032552 - val_trvae_loss: 893.0449218750 - val_landmark_loss: 0.0000930261 - val_unlabeled_loss: 0.0930261165 |███████████████████-| 97.0%  - val_loss: 889.4082845052 - val_trvae_loss: 889.4081827799 - val_landmark_loss: 0.0001029808 - val_unlabeled_loss: 0.1029807478 |███████████████████-| 98.0%  - val_loss: 887.2950032552 - val_trvae_loss: 887.2949015299 - val_landmark_loss: 0.0001002048 - val_unlabeled_loss: 0.1002047608 |███████████████████-| 99.0%  - val_loss: 886.7325032552 - val_trvae_loss: 886.7324015299 - val_landmark_loss: 0.0000988017 - val_unlabeled_loss: 0.0988017097 |████████████████████| 100.0%  - val_loss: 892.0267130534 - val_trvae_loss: 892.0266113281 - val_landmark_loss: 0.0001068452 - val_unlabeled_loss: 0.1068452174
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 14:19:13 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2022-05-19 14:19:14 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
Saving best state of network...
Best State was in Epoch 89
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2022-05-19 14:31:09 (ERROR): Failed after 0:16:33!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/tmp/1177/uncertainty/uncertainty_seml.py", line 252, in run
    rmtree(REF_PATH)
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 699, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 697, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/storage/groups/ml01/workspace/carlo.dedonno/lataq_reproduce/tmp/ref_model_embedcvae_20'

