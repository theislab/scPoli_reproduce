Starting job 3781265
SLURM assigned me the node(s): gpusrv12
Experiments are running under the following process IDs:
Experiment ID: 2	Process ID: 252392

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 10:57:03 (INFO): Running command 'run'
2021-10-26 10:57:03 (INFO): Started run with ID "2"
2021-10-26 10:57:17 (INFO): Data loaded succesfully
2021-10-26 10:57:17 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1230.2801005046 - val_trvae_loss: 1230.2801005046 |--------------------| 2.0%  - val_loss: 1187.4834289551 - val_trvae_loss: 1187.4834289551 |--------------------| 3.0%  - val_loss: 1154.3017679850 - val_trvae_loss: 1154.3017679850 |--------------------| 4.0%  - val_loss: 1140.9099934896 - val_trvae_loss: 1140.9099934896 |█-------------------| 5.0%  - val_loss: 1127.9337666829 - val_trvae_loss: 1127.9337666829 |█-------------------| 6.0%  - val_loss: 1123.4195251465 - val_trvae_loss: 1123.4195251465 |█-------------------| 7.0%  - val_loss: 1114.8128356934 - val_trvae_loss: 1114.8128356934 |█-------------------| 8.0%  - val_loss: 1108.9245503743 - val_trvae_loss: 1108.9245503743 |█-------------------| 9.0%  - val_loss: 1107.0377400716 - val_trvae_loss: 1107.0377400716 |██------------------| 10.0%  - val_loss: 1097.3810882568 - val_trvae_loss: 1097.3810882568 |██------------------| 11.0%  - val_loss: 1099.8349507650 - val_trvae_loss: 1099.8349507650 |██------------------| 12.0%  - val_loss: 1095.2276916504 - val_trvae_loss: 1095.2276916504 |██------------------| 13.0%  - val_loss: 1093.5210876465 - val_trvae_loss: 1093.5210876465 |██------------------| 14.0%  - val_loss: 1089.4467773438 - val_trvae_loss: 1089.4467773438 |███-----------------| 15.0%  - val_loss: 1085.6068267822 - val_trvae_loss: 1085.6068267822 |███-----------------| 16.0%  - val_loss: 1085.6518452962 - val_trvae_loss: 1085.6518452962 |███-----------------| 17.0%  - val_loss: 1086.1671244303 - val_trvae_loss: 1086.1671244303 |███-----------------| 18.0%  - val_loss: 1081.1757863363 - val_trvae_loss: 1081.1757863363 |███-----------------| 19.0%  - val_loss: 1084.3326619466 - val_trvae_loss: 1084.3326619466 |████----------------| 20.0%  - val_loss: 1080.2723693848 - val_trvae_loss: 1080.2723693848 |████----------------| 21.0%  - val_loss: 1081.9280395508 - val_trvae_loss: 1081.9280395508 |████----------------| 22.0%  - val_loss: 1077.7684020996 - val_trvae_loss: 1077.7684020996 |████----------------| 23.0%  - val_loss: 1082.7677103678 - val_trvae_loss: 1082.7677103678 |████----------------| 24.0%  - val_loss: 1080.8633931478 - val_trvae_loss: 1080.8633931478 |█████---------------| 25.0%  - val_loss: 1074.9436747233 - val_trvae_loss: 1074.9436747233 |█████---------------| 26.0%  - val_loss: 1077.8383789062 - val_trvae_loss: 1077.8383789062 |█████---------------| 27.0%  - val_loss: 1074.3124694824 - val_trvae_loss: 1074.3124694824 |█████---------------| 28.0%  - val_loss: 1077.7690938314 - val_trvae_loss: 1077.7690938314 |█████---------------| 29.0%  - val_loss: 1077.2409769694 - val_trvae_loss: 1077.2409769694 |██████--------------| 30.0%  - val_loss: 1077.4141540527 - val_trvae_loss: 1077.4141540527 |██████--------------| 31.0%  - val_loss: 1074.8113454183 - val_trvae_loss: 1074.8113454183 |██████--------------| 32.0%  - val_loss: 1075.8208516439 - val_trvae_loss: 1075.8208516439 |██████--------------| 33.0%  - val_loss: 1078.5150756836 - val_trvae_loss: 1078.5150756836 |██████--------------| 34.0%  - val_loss: 1074.8121236165 - val_trvae_loss: 1074.8121236165 |███████-------------| 35.0%  - val_loss: 1075.0060831706 - val_trvae_loss: 1075.0060831706 |███████-------------| 36.0%  - val_loss: 1076.5327707926 - val_trvae_loss: 1076.5327707926 |███████-------------| 37.0%  - val_loss: 1069.7320505778 - val_trvae_loss: 1069.7320505778 |███████-------------| 38.0%  - val_loss: 1072.7216593424 - val_trvae_loss: 1072.7216593424 |███████-------------| 39.0%  - val_loss: 1068.7991027832 - val_trvae_loss: 1068.7991027832 |████████------------| 40.0%  - val_loss: 1073.0863444010 - val_trvae_loss: 1073.0863444010 |████████------------| 41.0%  - val_loss: 1073.7741902669 - val_trvae_loss: 1073.7741902669 |████████------------| 42.0%  - val_loss: 1071.0123392741 - val_trvae_loss: 1071.0123392741 |████████------------| 43.0%  - val_loss: 1073.9431254069 - val_trvae_loss: 1073.9431254069 |████████------------| 44.0%  - val_loss: 1074.4048105876 - val_trvae_loss: 1074.4048105876 |█████████-----------| 45.0%  - val_loss: 1073.0891621908 - val_trvae_loss: 1073.0891621908 |█████████-----------| 46.0%  - val_loss: 1074.1107737223 - val_trvae_loss: 1074.1107737223 |█████████-----------| 47.0%  - val_loss: 1072.3311665853 - val_trvae_loss: 1072.3311665853 |█████████-----------| 48.0%  - val_loss: 1074.0067799886 - val_trvae_loss: 1074.0067799886 |█████████-----------| 49.0%  - val_loss: 1074.6507059733 - val_trvae_loss: 1074.6507059733 |██████████----------| 50.0%  - val_loss: 1072.9270426432 - val_trvae_loss: 1072.9270426432 |██████████----------| 51.0%  - val_loss: 1071.0093994141 - val_trvae_loss: 1071.0093994141 |██████████----------| 52.0%  - val_loss: 1073.1186421712 - val_trvae_loss: 1073.1186421712 |██████████----------| 53.0%  - val_loss: 1068.8360697428 - val_trvae_loss: 1068.8360697428 |██████████----------| 54.0%  - val_loss: 1072.2764485677 - val_trvae_loss: 1072.2764485677 |███████████---------| 55.0%  - val_loss: 1070.7650960286 - val_trvae_loss: 1070.7650960286 |███████████---------| 56.0%  - val_loss: 1072.6284077962 - val_trvae_loss: 1072.6284077962 |███████████---------| 57.0%  - val_loss: 1070.4833984375 - val_trvae_loss: 1070.4833984375 |███████████---------| 58.0%  - val_loss: 1071.3001251221 - val_trvae_loss: 1071.3001251221 |███████████---------| 59.0%  - val_loss: 1072.1159769694 - val_trvae_loss: 1072.1159769694 |████████████--------| 60.0%  - val_loss: 1071.2641398112 - val_trvae_loss: 1071.2641398112 |████████████--------| 61.0%  - val_loss: 1069.6669108073 - val_trvae_loss: 1069.6669108073 |████████████--------| 62.0%  - val_loss: 1072.3346964518 - val_trvae_loss: 1072.3346964518 |████████████--------| 63.0%  - val_loss: 1072.6687316895 - val_trvae_loss: 1072.6687316895 |████████████--------| 64.0%  - val_loss: 1071.8918965658 - val_trvae_loss: 1071.8918965658 |█████████████-------| 65.0%  - val_loss: 1074.1875712077 - val_trvae_loss: 1074.1875712077 |█████████████-------| 66.0%  - val_loss: 1068.3786366781 - val_trvae_loss: 1068.3786366781 |█████████████-------| 67.0%  - val_loss: 1073.5528208415 - val_trvae_loss: 1073.5528208415 |█████████████-------| 68.0%  - val_loss: 1070.4190673828 - val_trvae_loss: 1070.4190673828 |█████████████-------| 69.0%  - val_loss: 1066.9279530843 - val_trvae_loss: 1066.9279530843 |██████████████------| 70.0%  - val_loss: 1069.9088643392 - val_trvae_loss: 1069.9088643392 |██████████████------| 71.0%  - val_loss: 1073.0958404541 - val_trvae_loss: 1073.0958404541 |██████████████------| 72.0%  - val_loss: 1070.6131795247 - val_trvae_loss: 1070.6131795247 |██████████████------| 73.0%  - val_loss: 1072.5018513997 - val_trvae_loss: 1072.5018513997 |██████████████------| 74.0%  - val_loss: 1067.5111745199 - val_trvae_loss: 1067.5111745199 |███████████████-----| 75.0%  - val_loss: 1067.8072509766 - val_trvae_loss: 1067.8072509766 |███████████████-----| 76.0%  - val_loss: 1066.4096934001 - val_trvae_loss: 1066.4096934001 |███████████████-----| 77.0%  - val_loss: 1074.7875264486 - val_trvae_loss: 1074.7875264486 |███████████████-----| 78.0%  - val_loss: 1066.1179606120 - val_trvae_loss: 1066.1179606120 |███████████████-----| 79.0%  - val_loss: 1068.3076680501 - val_trvae_loss: 1068.3076680501 |████████████████----| 80.0%  - val_loss: 1071.9451599121 - val_trvae_loss: 1071.9451599121 |████████████████----| 81.0%  - val_loss: 1072.2125142415 - val_trvae_loss: 1068.7353973389 - val_landmark_loss: 3.4771179159 - val_labeled_loss: 3.4771179159 |████████████████----| 82.0%  - val_loss: 1075.6724141439 - val_trvae_loss: 1072.7924499512 - val_landmark_loss: 2.8799530268 - val_labeled_loss: 2.8799530268 |████████████████----| 83.0%  - val_loss: 1070.8138071696 - val_trvae_loss: 1068.6386922201 - val_landmark_loss: 2.1751131515 - val_labeled_loss: 2.1751131515 |████████████████----| 84.0%  - val_loss: 1071.1509501139 - val_trvae_loss: 1069.3842468262 - val_landmark_loss: 1.7667055329 - val_labeled_loss: 1.7667055329 |█████████████████---| 85.0%  - val_loss: 1073.6930541992 - val_trvae_loss: 1071.7421468099 - val_landmark_loss: 1.9509117703 - val_labeled_loss: 1.9509117703 |█████████████████---| 86.0%  - val_loss: 1073.8064575195 - val_trvae_loss: 1072.0249837240 - val_landmark_loss: 1.7814712028 - val_labeled_loss: 1.7814712028 |█████████████████---| 87.0%  - val_loss: 1072.1150512695 - val_trvae_loss: 1070.7236328125 - val_landmark_loss: 1.3914154470 - val_labeled_loss: 1.3914154470 |█████████████████---| 88.0%  - val_loss: 1071.7207946777 - val_trvae_loss: 1070.1811879476 - val_landmark_loss: 1.5395956834 - val_labeled_loss: 1.5395956834 |█████████████████---| 89.0%  - val_loss: 1068.5447845459 - val_trvae_loss: 1067.2343546549 - val_landmark_loss: 1.3104429195 - val_labeled_loss: 1.3104429195 |██████████████████--| 90.0%  - val_loss: 1074.0872599284 - val_trvae_loss: 1072.9464213053 - val_landmark_loss: 1.1408345699 - val_labeled_loss: 1.1408345699 |██████████████████--| 91.0%  - val_loss: 1071.5970611572 - val_trvae_loss: 1070.2201283773 - val_landmark_loss: 1.3769291490 - val_labeled_loss: 1.3769291490 |██████████████████--| 92.0%  - val_loss: 1070.0968627930 - val_trvae_loss: 1068.9600830078 - val_landmark_loss: 1.1367823035 - val_labeled_loss: 1.1367823035 |██████████████████--| 93.0%  - val_loss: 1072.3432922363 - val_trvae_loss: 1071.2716267904 - val_landmark_loss: 1.0716547916 - val_labeled_loss: 1.0716547916 |██████████████████--| 94.0%  - val_loss: 1071.6117655436 - val_trvae_loss: 1070.4984842936 - val_landmark_loss: 1.1132807980 - val_labeled_loss: 1.1132807980 |███████████████████-| 95.0%  - val_loss: 1074.1524454753 - val_trvae_loss: 1073.1080017090 - val_landmark_loss: 1.0444408357 - val_labeled_loss: 1.0444408357 |███████████████████-| 96.0%  - val_loss: 1072.2968241374 - val_trvae_loss: 1071.2694498698 - val_landmark_loss: 1.0273763835 - val_labeled_loss: 1.0273763835 |███████████████████-| 97.0%  - val_loss: 1071.2767130534 - val_trvae_loss: 1070.2424011230 - val_landmark_loss: 1.0342965623 - val_labeled_loss: 1.0342965623 |███████████████████-| 98.0%  - val_loss: 1076.3681640625 - val_trvae_loss: 1075.3357849121 - val_landmark_loss: 1.0323964953 - val_labeled_loss: 1.0323964953 |███████████████████-| 99.0%  - val_loss: 1073.9626871745 - val_trvae_loss: 1072.8765665690 - val_landmark_loss: 1.0861185938 - val_labeled_loss: 1.0861185938 |████████████████████| 100.0%  - val_loss: 1068.4524332682 - val_trvae_loss: 1067.6517435710 - val_landmark_loss: 0.8007001529 - val_labeled_loss: 0.8007001529
2021-10-26 10:59:48 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 1724 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1144.7515258789 - val_trvae_loss: 1144.7515258789 |--------------------| 2.0%  - val_loss: 1142.4147338867 - val_trvae_loss: 1142.4147338867 |--------------------| 3.0%  - val_loss: 1144.4010620117 - val_trvae_loss: 1144.4010620117 |--------------------| 4.0%  - val_loss: 1138.9583740234 - val_trvae_loss: 1138.9583740234 |█-------------------| 5.0%  - val_loss: 1137.3856201172 - val_trvae_loss: 1137.3856201172 |█-------------------| 6.0%  - val_loss: 1126.4838256836 - val_trvae_loss: 1126.4838256836 |█-------------------| 7.0%  - val_loss: 1126.8379516602 - val_trvae_loss: 1126.8379516602 |█-------------------| 8.0%  - val_loss: 1146.9980468750 - val_trvae_loss: 1146.9980468750 |█-------------------| 9.0%  - val_loss: 1161.1077880859 - val_trvae_loss: 1161.1077880859 |██------------------| 10.0%  - val_loss: 1135.0050659180 - val_trvae_loss: 1135.0050659180 |██------------------| 11.0%  - val_loss: 1155.9029541016 - val_trvae_loss: 1155.9029541016 |██------------------| 12.0%  - val_loss: 1127.4246826172 - val_trvae_loss: 1127.4246826172 |██------------------| 13.0%  - val_loss: 1117.2659912109 - val_trvae_loss: 1117.2659912109 |██------------------| 14.0%  - val_loss: 1160.6880493164 - val_trvae_loss: 1160.6880493164 |███-----------------| 15.0%  - val_loss: 1110.8054809570 - val_trvae_loss: 1110.8054809570 |███-----------------| 16.0%  - val_loss: 1144.3672485352 - val_trvae_loss: 1144.3672485352 |███-----------------| 17.0%  - val_loss: 1132.7291259766 - val_trvae_loss: 1132.7291259766 |███-----------------| 18.0%  - val_loss: 1144.8224487305 - val_trvae_loss: 1144.8224487305 |███-----------------| 19.0%  - val_loss: 1136.1324462891 - val_trvae_loss: 1136.1324462891 |████----------------| 20.0%  - val_loss: 1152.8392944336 - val_trvae_loss: 1152.8392944336 |████----------------| 21.0%  - val_loss: 1146.8056640625 - val_trvae_loss: 1146.8056640625 |████----------------| 22.0%  - val_loss: 1150.1446533203 - val_trvae_loss: 1150.1446533203 |████----------------| 23.0%  - val_loss: 1149.0067749023 - val_trvae_loss: 1149.0067749023 |████----------------| 24.0%  - val_loss: 1119.5471191406 - val_trvae_loss: 1119.5471191406 |█████---------------| 25.0%  - val_loss: 1148.0792236328 - val_trvae_loss: 1148.0792236328 |█████---------------| 26.0%  - val_loss: 1130.7643432617 - val_trvae_loss: 1130.7643432617 |█████---------------| 27.0%  - val_loss: 1122.5113525391 - val_trvae_loss: 1122.5113525391 |█████---------------| 28.0%  - val_loss: 1131.4675903320 - val_trvae_loss: 1131.4675903320 |█████---------------| 29.0%  - val_loss: 1132.0291748047 - val_trvae_loss: 1132.0291748047 |██████--------------| 30.0%  - val_loss: 1135.7337036133 - val_trvae_loss: 1135.7337036133 |██████--------------| 31.0%  - val_loss: 1150.7643432617 - val_trvae_loss: 1150.7643432617 |██████--------------| 32.0%  - val_loss: 1143.5552978516 - val_trvae_loss: 1143.5552978516 |██████--------------| 33.0%  - val_loss: 1142.5399780273 - val_trvae_loss: 1142.5399780273 |██████--------------| 34.0%  - val_loss: 1119.0742187500 - val_trvae_loss: 1119.0742187500 |███████-------------| 35.0%  - val_loss: 1138.0671997070 - val_trvae_loss: 1138.0671997070 |███████-------------| 36.0%  - val_loss: 1119.8068237305 - val_trvae_loss: 1119.8068237305 |███████-------------| 37.0%  - val_loss: 1126.7712402344 - val_trvae_loss: 1126.7712402344 |███████-------------| 38.0%  - val_loss: 1138.5751342773 - val_trvae_loss: 1138.5751342773 |███████-------------| 39.0%  - val_loss: 1137.1995239258 - val_trvae_loss: 1137.1995239258 |████████------------| 40.0%  - val_loss: 1138.8236694336 - val_trvae_loss: 1138.8236694336 |████████------------| 41.0%  - val_loss: 1139.1295166016 - val_trvae_loss: 1139.1295166016 |████████------------| 42.0%  - val_loss: 1156.1421508789 - val_trvae_loss: 1156.1421508789 |████████------------| 43.0%  - val_loss: 1140.8947753906 - val_trvae_loss: 1140.8947753906 |████████------------| 44.0%  - val_loss: 1126.2845458984 - val_trvae_loss: 1126.2845458984 |█████████-----------| 45.0%  - val_loss: 1135.2897338867 - val_trvae_loss: 1135.2897338867 |█████████-----------| 46.0%  - val_loss: 1107.9021606445 - val_trvae_loss: 1107.9021606445 |█████████-----------| 47.0%  - val_loss: 1135.5473632812 - val_trvae_loss: 1135.5473632812 |█████████-----------| 48.0%  - val_loss: 1138.1685180664 - val_trvae_loss: 1138.1685180664 |█████████-----------| 49.0%  - val_loss: 1116.2630615234 - val_trvae_loss: 1116.2630615234 |██████████----------| 50.0%  - val_loss: 1139.2355346680 - val_trvae_loss: 1139.2355346680 |██████████----------| 51.0%  - val_loss: 1146.3224487305 - val_trvae_loss: 1146.3224487305 |██████████----------| 52.0%  - val_loss: 1126.5582885742 - val_trvae_loss: 1126.5582885742 |██████████----------| 53.0%  - val_loss: 1131.7849121094 - val_trvae_loss: 1131.7849121094 |██████████----------| 54.0%  - val_loss: 1120.4882812500 - val_trvae_loss: 1120.4882812500 |███████████---------| 55.0%  - val_loss: 1134.0103759766 - val_trvae_loss: 1134.0103759766 |███████████---------| 56.0%  - val_loss: 1156.9196777344 - val_trvae_loss: 1156.9196777344 |███████████---------| 57.0%  - val_loss: 1138.8804321289 - val_trvae_loss: 1138.8804321289 |███████████---------| 58.0%  - val_loss: 1145.1503295898 - val_trvae_loss: 1145.1503295898 |███████████---------| 59.0%  - val_loss: 1149.1075439453 - val_trvae_loss: 1149.1075439453 |████████████--------| 60.0%  - val_loss: 1130.4211425781 - val_trvae_loss: 1130.4211425781 |████████████--------| 61.0%  - val_loss: 1147.4513549805 - val_trvae_loss: 1147.4513549805 |████████████--------| 62.0%  - val_loss: 1131.5134277344 - val_trvae_loss: 1131.5134277344 |████████████--------| 63.0%  - val_loss: 1135.2612915039 - val_trvae_loss: 1135.2612915039 |████████████--------| 64.0%  - val_loss: 1134.1135253906 - val_trvae_loss: 1134.1135253906 |█████████████-------| 65.0%  - val_loss: 1129.0859985352 - val_trvae_loss: 1129.0859985352 |█████████████-------| 66.0%  - val_loss: 1125.4071655273 - val_trvae_loss: 1125.4071655273 |█████████████-------| 67.0%  - val_loss: 1130.1854858398 - val_trvae_loss: 1130.1854858398 |█████████████-------| 68.0%  - val_loss: 1112.9907836914 - val_trvae_loss: 1112.9907836914 |█████████████-------| 69.0%  - val_loss: 1128.5888671875 - val_trvae_loss: 1128.5888671875 |██████████████------| 70.0%  - val_loss: 1112.8273315430 - val_trvae_loss: 1112.8273315430 |██████████████------| 71.0%  - val_loss: 1114.1008300781 - val_trvae_loss: 1114.1008300781 |██████████████------| 72.0%  - val_loss: 1161.0429077148 - val_trvae_loss: 1161.0429077148 |██████████████------| 73.0%  - val_loss: 1134.4722900391 - val_trvae_loss: 1134.4722900391 |██████████████------| 74.0%  - val_loss: 1112.6721191406 - val_trvae_loss: 1112.6721191406 |███████████████-----| 75.0%  - val_loss: 1111.0559082031 - val_trvae_loss: 1111.0559082031 |███████████████-----| 76.0%  - val_loss: 1128.3980712891 - val_trvae_loss: 1128.3980712891 |███████████████-----| 77.0%  - val_loss: 1112.4327392578 - val_trvae_loss: 1112.4327392578 |███████████████-----| 78.0%  - val_loss: 1121.3416137695 - val_trvae_loss: 1121.3416137695 |███████████████-----| 79.0%  - val_loss: 1134.8851928711 - val_trvae_loss: 1134.8851928711 |████████████████----| 80.0%  - val_loss: 1149.1743164062 - val_trvae_loss: 1149.1743164062
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 14 clusters.
 |████████████████----| 81.0%  - val_loss: 1119.1243896484 - val_trvae_loss: 1119.1243286133 - val_landmark_loss: 0.0000627499 - val_unlabeled_loss: 0.0627498869 |████████████████----| 82.0%  - val_loss: 1131.9082031250 - val_trvae_loss: 1131.9081420898 - val_landmark_loss: 0.0000842959 - val_unlabeled_loss: 0.0842958838 |████████████████----| 83.0%  - val_loss: 1130.1353759766 - val_trvae_loss: 1130.1353149414 - val_landmark_loss: 0.0000765038 - val_unlabeled_loss: 0.0765037723 |████████████████----| 84.0%  - val_loss: 1134.6875000000 - val_trvae_loss: 1134.6873779297 - val_landmark_loss: 0.0000705018 - val_unlabeled_loss: 0.0705017485 |█████████████████---| 85.0%  - val_loss: 1132.1619873047 - val_trvae_loss: 1132.1619262695 - val_landmark_loss: 0.0000598024 - val_unlabeled_loss: 0.0598023590 |█████████████████---| 86.0%  - val_loss: 1114.5852050781 - val_trvae_loss: 1114.5851440430 - val_landmark_loss: 0.0000615760 - val_unlabeled_loss: 0.0615760330 |█████████████████---| 87.0%  - val_loss: 1132.4516601562 - val_trvae_loss: 1132.4515991211 - val_landmark_loss: 0.0000697310 - val_unlabeled_loss: 0.0697309896 |█████████████████---| 88.0%  - val_loss: 1149.7526855469 - val_trvae_loss: 1149.7525634766 - val_landmark_loss: 0.0000664919 - val_unlabeled_loss: 0.0664919391 |█████████████████---| 89.0%  - val_loss: 1130.7738037109 - val_trvae_loss: 1130.7736816406 - val_landmark_loss: 0.0000662468 - val_unlabeled_loss: 0.0662467889 |██████████████████--| 90.0%  - val_loss: 1120.7272949219 - val_trvae_loss: 1120.7271728516 - val_landmark_loss: 0.0000657370 - val_unlabeled_loss: 0.0657369867 |██████████████████--| 91.0%  - val_loss: 1119.1826782227 - val_trvae_loss: 1119.1825561523 - val_landmark_loss: 0.0000705942 - val_unlabeled_loss: 0.0705942288 |██████████████████--| 92.0%  - val_loss: 1117.3456420898 - val_trvae_loss: 1117.3455200195 - val_landmark_loss: 0.0000685522 - val_unlabeled_loss: 0.0685522370 |██████████████████--| 93.0%  - val_loss: 1131.6763305664 - val_trvae_loss: 1131.6762695312 - val_landmark_loss: 0.0000646610 - val_unlabeled_loss: 0.0646609552 |██████████████████--| 94.0%  - val_loss: 1141.6869506836 - val_trvae_loss: 1141.6868896484 - val_landmark_loss: 0.0000611471 - val_unlabeled_loss: 0.0611471049 |███████████████████-| 95.0%  - val_loss: 1129.5437011719 - val_trvae_loss: 1129.5435791016 - val_landmark_loss: 0.0000773178 - val_unlabeled_loss: 0.0773177668 |███████████████████-| 96.0%  - val_loss: 1112.8581542969 - val_trvae_loss: 1112.8580932617 - val_landmark_loss: 0.0000624575 - val_unlabeled_loss: 0.0624574739 |███████████████████-| 97.0%  - val_loss: 1115.5557861328 - val_trvae_loss: 1115.5556640625 - val_landmark_loss: 0.0000671993 - val_unlabeled_loss: 0.0671993382 |███████████████████-| 98.0%  - val_loss: 1137.6404418945 - val_trvae_loss: 1137.6403808594 - val_landmark_loss: 0.0000623691 - val_unlabeled_loss: 0.0623690505 |███████████████████-| 99.0%  - val_loss: 1121.0949096680 - val_trvae_loss: 1121.0948486328 - val_landmark_loss: 0.0000603615 - val_unlabeled_loss: 0.0603614990 |████████████████████| 100.0%  - val_loss: 1121.2360229492 - val_trvae_loss: 1121.2359008789 - val_landmark_loss: 0.0000729792 - val_unlabeled_loss: 0.0729792267
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 11:00:11 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 11:00:11 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
slurmstepd: error: *** JOB 3781265 ON gpusrv12 CANCELLED AT 2021-10-26T11:01:37 ***
