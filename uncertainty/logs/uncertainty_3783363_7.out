Starting job 3783371
SLURM assigned me the node(s): gpusrv13
Experiments are running under the following process IDs:
Experiment ID: 8	Process ID: 45510

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 16:14:50 (INFO): Running command 'run'
2021-10-26 16:14:50 (INFO): Started run with ID "8"
2021-10-26 16:14:51 (INFO): Data loaded succesfully
2021-10-26 16:14:51 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1178.5932688994 - val_trvae_loss: 1178.5932688994 |--------------------| 2.0%  - val_loss: 1132.5893913718 - val_trvae_loss: 1132.5893913718 |--------------------| 3.0%  - val_loss: 1111.5712244370 - val_trvae_loss: 1111.5712244370 |--------------------| 4.0%  - val_loss: 1102.0391486673 - val_trvae_loss: 1102.0391486673 |█-------------------| 5.0%  - val_loss: 1097.1531695198 - val_trvae_loss: 1097.1531695198 |█-------------------| 6.0%  - val_loss: 1091.1368767233 - val_trvae_loss: 1091.1368767233 |█-------------------| 7.0%  - val_loss: 1087.1441865809 - val_trvae_loss: 1087.1441865809 |█-------------------| 8.0%  - val_loss: 1085.2123377183 - val_trvae_loss: 1085.2123377183 |█-------------------| 9.0%  - val_loss: 1081.8236658433 - val_trvae_loss: 1081.8236658433 |██------------------| 10.0%  - val_loss: 1079.1047686409 - val_trvae_loss: 1079.1047686409 |██------------------| 11.0%  - val_loss: 1077.4147661994 - val_trvae_loss: 1077.4147661994 |██------------------| 12.0%  - val_loss: 1074.9764440200 - val_trvae_loss: 1074.9764440200 |██------------------| 13.0%  - val_loss: 1074.4694536994 - val_trvae_loss: 1074.4694536994 |██------------------| 14.0%  - val_loss: 1072.5500129251 - val_trvae_loss: 1072.5500129251 |███-----------------| 15.0%  - val_loss: 1072.1382266774 - val_trvae_loss: 1072.1382266774 |███-----------------| 16.0%  - val_loss: 1071.6976533778 - val_trvae_loss: 1071.6976533778 |███-----------------| 17.0%  - val_loss: 1070.3860473633 - val_trvae_loss: 1070.3860473633 |███-----------------| 18.0%  - val_loss: 1069.2575001436 - val_trvae_loss: 1069.2575001436 |███-----------------| 19.0%  - val_loss: 1068.5361974380 - val_trvae_loss: 1068.5361974380 |████----------------| 20.0%  - val_loss: 1068.5338709214 - val_trvae_loss: 1068.5338709214 |████----------------| 21.0%  - val_loss: 1067.7646053539 - val_trvae_loss: 1067.7646053539 |████----------------| 22.0%  - val_loss: 1068.2041697783 - val_trvae_loss: 1068.2041697783 |████----------------| 23.0%  - val_loss: 1066.5941198012 - val_trvae_loss: 1066.5941198012 |████----------------| 24.0%  - val_loss: 1067.3341602999 - val_trvae_loss: 1067.3341602999 |█████---------------| 25.0%  - val_loss: 1066.5574017693 - val_trvae_loss: 1066.5574017693 |█████---------------| 26.0%  - val_loss: 1066.5451121611 - val_trvae_loss: 1066.5451121611 |█████---------------| 27.0%  - val_loss: 1066.2232558307 - val_trvae_loss: 1066.2232558307 |█████---------------| 28.0%  - val_loss: 1065.5022403493 - val_trvae_loss: 1065.5022403493 |█████---------------| 29.0%  - val_loss: 1065.4542667165 - val_trvae_loss: 1065.4542667165 |██████--------------| 30.0%  - val_loss: 1065.8370074104 - val_trvae_loss: 1065.8370074104 |██████--------------| 31.0%  - val_loss: 1065.1662956687 - val_trvae_loss: 1065.1662956687 |██████--------------| 32.0%  - val_loss: 1065.1483549230 - val_trvae_loss: 1065.1483549230 |██████--------------| 33.0%  - val_loss: 1064.7708058077 - val_trvae_loss: 1064.7708058077 |██████--------------| 34.0%  - val_loss: 1065.3777178596 - val_trvae_loss: 1065.3777178596 |███████-------------| 35.0%  - val_loss: 1065.2767333984 - val_trvae_loss: 1065.2767333984 |███████-------------| 36.0%  - val_loss: 1064.6347728056 - val_trvae_loss: 1064.6347728056 |███████-------------| 37.0%  - val_loss: 1065.2420546588 - val_trvae_loss: 1065.2420546588 |███████-------------| 38.0%  - val_loss: 1066.8646096622 - val_trvae_loss: 1066.8646096622 |███████-------------| 39.0%  - val_loss: 1064.2928394991 - val_trvae_loss: 1064.2928394991 |████████------------| 40.0%  - val_loss: 1065.3267247817 - val_trvae_loss: 1065.3267247817 |████████------------| 41.0%  - val_loss: 1063.9533404182 - val_trvae_loss: 1063.9533404182 |████████------------| 42.0%  - val_loss: 1064.3478034524 - val_trvae_loss: 1064.3478034524 |████████------------| 43.0%  - val_loss: 1064.6166704963 - val_trvae_loss: 1064.6166704963 |████████------------| 44.0%  - val_loss: 1063.9086124196 - val_trvae_loss: 1063.9086124196 |█████████-----------| 45.0%  - val_loss: 1064.5250998104 - val_trvae_loss: 1064.5250998104 |█████████-----------| 46.0%  - val_loss: 1064.0665534524 - val_trvae_loss: 1064.0665534524 |█████████-----------| 47.0%  - val_loss: 1064.5626795152 - val_trvae_loss: 1064.5626795152 |█████████-----------| 48.0%  - val_loss: 1065.6844626034 - val_trvae_loss: 1065.6844626034 |█████████-----------| 49.0%  - val_loss: 1064.2657075770 - val_trvae_loss: 1064.2657075770 |██████████----------| 50.0%  - val_loss: 1063.7089017980 - val_trvae_loss: 1063.7089017980 |██████████----------| 51.0%  - val_loss: 1063.9946540384 - val_trvae_loss: 1063.9946540384 |██████████----------| 52.0%  - val_loss: 1063.2668457031 - val_trvae_loss: 1063.2668457031 |██████████----------| 53.0%  - val_loss: 1063.7676858341 - val_trvae_loss: 1063.7676858341 |██████████----------| 54.0%  - val_loss: 1063.4197854435 - val_trvae_loss: 1063.4197854435 |███████████---------| 55.0%  - val_loss: 1064.6253231273 - val_trvae_loss: 1064.6253231273 |███████████---------| 56.0%  - val_loss: 1063.0496251723 - val_trvae_loss: 1063.0496251723 |███████████---------| 57.0%  - val_loss: 1063.2360301298 - val_trvae_loss: 1063.2360301298 |███████████---------| 58.0%  - val_loss: 1064.6546953987 - val_trvae_loss: 1064.6546953987 |███████████---------| 59.0%  - val_loss: 1063.1671214384 - val_trvae_loss: 1063.1671214384 |████████████--------| 60.0%  - val_loss: 1063.2777889476 - val_trvae_loss: 1063.2777889476 |████████████--------| 61.0%  - val_loss: 1062.9355899586 - val_trvae_loss: 1062.9355899586 |████████████--------| 62.0%  - val_loss: 1063.6266228171 - val_trvae_loss: 1063.6266228171 |████████████--------| 63.0%  - val_loss: 1062.8867977367 - val_trvae_loss: 1062.8867977367 |████████████--------| 64.0%  - val_loss: 1063.1186092601 - val_trvae_loss: 1063.1186092601 |█████████████-------| 65.0%  - val_loss: 1063.6996136834 - val_trvae_loss: 1063.6996136834 |█████████████-------| 66.0%  - val_loss: 1063.0671853458 - val_trvae_loss: 1063.0671853458 |█████████████-------| 67.0%  - val_loss: 1064.1475865981 - val_trvae_loss: 1064.1475865981 |█████████████-------| 68.0%  - val_loss: 1063.2178129308 - val_trvae_loss: 1063.2178129308 |█████████████-------| 69.0%  - val_loss: 1062.7745469037 - val_trvae_loss: 1062.7745469037 |██████████████------| 70.0%  - val_loss: 1063.0304350011 - val_trvae_loss: 1063.0304350011 |██████████████------| 71.0%  - val_loss: 1062.6902788948 - val_trvae_loss: 1062.6902788948 |██████████████------| 72.0%  - val_loss: 1062.7334307502 - val_trvae_loss: 1062.7334307502 |██████████████------| 73.0%  - val_loss: 1063.1235602884 - val_trvae_loss: 1063.1235602884 |██████████████------| 74.0%  - val_loss: 1062.4486586627 - val_trvae_loss: 1062.4486586627 |███████████████-----| 75.0%  - val_loss: 1063.0710054285 - val_trvae_loss: 1063.0710054285 |███████████████-----| 76.0%  - val_loss: 1064.1961418601 - val_trvae_loss: 1064.1961418601 |███████████████-----| 77.0%  - val_loss: 1062.9294720818 - val_trvae_loss: 1062.9294720818 |███████████████-----| 78.0%  - val_loss: 1062.6028980928 - val_trvae_loss: 1062.6028980928 |███████████████-----| 79.0%  - val_loss: 1063.7804852654 - val_trvae_loss: 1063.7804852654 |████████████████----| 80.0%  - val_loss: 1063.8530776080 - val_trvae_loss: 1063.8530776080 |████████████████----| 81.0%  - val_loss: 1088.2774586397 - val_trvae_loss: 1070.8230267693 - val_landmark_loss: 17.4544223898 - val_labeled_loss: 17.4544223898 |████████████████----| 82.0%  - val_loss: 1081.5110832663 - val_trvae_loss: 1069.3898961684 - val_landmark_loss: 12.1211859198 - val_labeled_loss: 12.1211859198 |████████████████----| 83.0%  - val_loss: 1079.6986155790 - val_trvae_loss: 1069.5008688534 - val_landmark_loss: 10.1977525599 - val_labeled_loss: 10.1977525599 |████████████████----| 84.0%  - val_loss: 1076.8433478860 - val_trvae_loss: 1067.8405761719 - val_landmark_loss: 9.0027638323 - val_labeled_loss: 9.0027638323 |█████████████████---| 85.0%  - val_loss: 1073.6625761144 - val_trvae_loss: 1066.4853515625 - val_landmark_loss: 7.1772099102 - val_labeled_loss: 7.1772099102 |█████████████████---| 86.0%  - val_loss: 1074.1216394761 - val_trvae_loss: 1067.5155675551 - val_landmark_loss: 6.6060622159 - val_labeled_loss: 6.6060622159 |█████████████████---| 87.0%  - val_loss: 1073.3263693417 - val_trvae_loss: 1066.7335815430 - val_landmark_loss: 6.5927836334 - val_labeled_loss: 6.5927836334 |█████████████████---| 88.0%  - val_loss: 1072.9367927102 - val_trvae_loss: 1065.9208409926 - val_landmark_loss: 7.0159634983 - val_labeled_loss: 7.0159634983 |█████████████████---| 89.0%  - val_loss: 1072.0458302217 - val_trvae_loss: 1066.1701085708 - val_landmark_loss: 5.8757262651 - val_labeled_loss: 5.8757262651 |██████████████████--| 90.0%  - val_loss: 1071.2632446289 - val_trvae_loss: 1065.8468484318 - val_landmark_loss: 5.4163932520 - val_labeled_loss: 5.4163932520 |██████████████████--| 91.0%  - val_loss: 1073.7840863396 - val_trvae_loss: 1068.5864186006 - val_landmark_loss: 5.1976809502 - val_labeled_loss: 5.1976809502 |██████████████████--| 92.0%  - val_loss: 1071.2230942670 - val_trvae_loss: 1066.1547707950 - val_landmark_loss: 5.0683130096 - val_labeled_loss: 5.0683130096 |██████████████████--| 93.0%  - val_loss: 1070.4949915269 - val_trvae_loss: 1065.8097103343 - val_landmark_loss: 4.6852789767 - val_labeled_loss: 4.6852789767 |██████████████████--| 94.0%  - val_loss: 1069.6482005400 - val_trvae_loss: 1065.4119549920 - val_landmark_loss: 4.2362504005 - val_labeled_loss: 4.2362504005 |███████████████████-| 95.0%  - val_loss: 1071.0309089212 - val_trvae_loss: 1067.0654799517 - val_landmark_loss: 3.9654363324 - val_labeled_loss: 3.9654363324 |███████████████████-| 96.0%  - val_loss: 1069.5900843003 - val_trvae_loss: 1065.4433629653 - val_landmark_loss: 4.1467152133 - val_labeled_loss: 4.1467152133 |███████████████████-| 97.0%  - val_loss: 1069.3290584789 - val_trvae_loss: 1065.6275670669 - val_landmark_loss: 3.7014864333 - val_labeled_loss: 3.7014864333 |███████████████████-| 98.0%  - val_loss: 1069.2077241785 - val_trvae_loss: 1065.2466933307 - val_landmark_loss: 3.9610256027 - val_labeled_loss: 3.9610256027 |███████████████████-| 99.0%  - val_loss: 1079.5882819681 - val_trvae_loss: 1076.0966832778 - val_landmark_loss: 3.4915950509 - val_labeled_loss: 3.4915950509 |████████████████████| 100.0%  - val_loss: 1070.4151072783 - val_trvae_loss: 1066.9465403837 - val_landmark_loss: 3.4685639704 - val_labeled_loss: 3.4685639704
2021-10-26 16:17:46 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 10727 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 2024.0646158854 - val_trvae_loss: 2024.0646158854 |--------------------| 2.0%  - val_loss: 2019.9368896484 - val_trvae_loss: 2019.9368896484 |--------------------| 3.0%  - val_loss: 2021.9121365017 - val_trvae_loss: 2021.9121365017 |--------------------| 4.0%  - val_loss: 2018.3165554470 - val_trvae_loss: 2018.3165554470 |█-------------------| 5.0%  - val_loss: 2010.4415283203 - val_trvae_loss: 2010.4415283203 |█-------------------| 6.0%  - val_loss: 1996.0093315972 - val_trvae_loss: 1996.0093315972 |█-------------------| 7.0%  - val_loss: 2003.0752224392 - val_trvae_loss: 2003.0752224392 |█-------------------| 8.0%  - val_loss: 1985.5138481988 - val_trvae_loss: 1985.5138481988 |█-------------------| 9.0%  - val_loss: 2000.5931125217 - val_trvae_loss: 2000.5931125217 |██------------------| 10.0%  - val_loss: 1985.0147976345 - val_trvae_loss: 1985.0147976345 |██------------------| 11.0%  - val_loss: 1978.0719807943 - val_trvae_loss: 1978.0719807943 |██------------------| 12.0%  - val_loss: 1978.8422715929 - val_trvae_loss: 1978.8422715929 |██------------------| 13.0%  - val_loss: 1986.7886691623 - val_trvae_loss: 1986.7886691623 |██------------------| 14.0%  - val_loss: 1973.6319173177 - val_trvae_loss: 1973.6319173177 |███-----------------| 15.0%  - val_loss: 1988.0519476997 - val_trvae_loss: 1988.0519476997 |███-----------------| 16.0%  - val_loss: 1976.0469563802 - val_trvae_loss: 1976.0469563802 |███-----------------| 17.0%  - val_loss: 1987.4144829644 - val_trvae_loss: 1987.4144829644 |███-----------------| 18.0%  - val_loss: 1972.2623562283 - val_trvae_loss: 1972.2623562283 |███-----------------| 19.0%  - val_loss: 1973.3335910373 - val_trvae_loss: 1973.3335910373 |████----------------| 20.0%  - val_loss: 1968.4264594184 - val_trvae_loss: 1968.4264594184 |████----------------| 21.0%  - val_loss: 1968.6697319878 - val_trvae_loss: 1968.6697319878 |████----------------| 22.0%  - val_loss: 1958.8444146050 - val_trvae_loss: 1958.8444146050 |████----------------| 23.0%  - val_loss: 1969.8863661024 - val_trvae_loss: 1969.8863661024 |████----------------| 24.0%  - val_loss: 1959.2460259332 - val_trvae_loss: 1959.2460259332 |█████---------------| 25.0%  - val_loss: 1959.0892876519 - val_trvae_loss: 1959.0892876519 |█████---------------| 26.0%  - val_loss: 1955.9881320530 - val_trvae_loss: 1955.9881320530 |█████---------------| 27.0%  - val_loss: 1955.4374593099 - val_trvae_loss: 1955.4374593099 |█████---------------| 28.0%  - val_loss: 1954.2269558377 - val_trvae_loss: 1954.2269558377 |█████---------------| 29.0%  - val_loss: 1966.8660753038 - val_trvae_loss: 1966.8660753038 |██████--------------| 30.0%  - val_loss: 1965.5922444661 - val_trvae_loss: 1965.5922444661 |██████--------------| 31.0%  - val_loss: 1969.7918836806 - val_trvae_loss: 1969.7918836806 |██████--------------| 32.0%  - val_loss: 1958.2257351345 - val_trvae_loss: 1958.2257351345 |██████--------------| 33.0%  - val_loss: 1968.2118462457 - val_trvae_loss: 1968.2118462457 |██████--------------| 34.0%  - val_loss: 1969.9024115668 - val_trvae_loss: 1969.9024115668 |███████-------------| 35.0%  - val_loss: 1951.9211697049 - val_trvae_loss: 1951.9211697049 |███████-------------| 36.0%  - val_loss: 1951.1035291884 - val_trvae_loss: 1951.1035291884 |███████-------------| 37.0%  - val_loss: 1972.3481445312 - val_trvae_loss: 1972.3481445312 |███████-------------| 38.0%  - val_loss: 1959.5965847439 - val_trvae_loss: 1959.5965847439 |███████-------------| 39.0%  - val_loss: 1950.1755913628 - val_trvae_loss: 1950.1755913628 |████████------------| 40.0%  - val_loss: 1939.6729193793 - val_trvae_loss: 1939.6729193793 |████████------------| 41.0%  - val_loss: 1950.7069769965 - val_trvae_loss: 1950.7069769965 |████████------------| 42.0%  - val_loss: 1945.3616807726 - val_trvae_loss: 1945.3616807726 |████████------------| 43.0%  - val_loss: 1956.7389458550 - val_trvae_loss: 1956.7389458550 |████████------------| 44.0%  - val_loss: 1952.7042914497 - val_trvae_loss: 1952.7042914497 |█████████-----------| 45.0%  - val_loss: 1958.6198323568 - val_trvae_loss: 1958.6198323568 |█████████-----------| 46.0%  - val_loss: 1947.0540907118 - val_trvae_loss: 1947.0540907118 |█████████-----------| 47.0%  - val_loss: 1949.3230523003 - val_trvae_loss: 1949.3230523003 |█████████-----------| 48.0%  - val_loss: 1947.4133436415 - val_trvae_loss: 1947.4133436415 |█████████-----------| 49.0%  - val_loss: 1942.1489257812 - val_trvae_loss: 1942.1489257812 |██████████----------| 50.0%  - val_loss: 1941.2191704644 - val_trvae_loss: 1941.2191704644 |██████████----------| 51.0%  - val_loss: 1952.6773681641 - val_trvae_loss: 1952.6773681641 |██████████----------| 52.0%  - val_loss: 1943.7273763021 - val_trvae_loss: 1943.7273763021 |██████████----------| 53.0%  - val_loss: 1956.7070855035 - val_trvae_loss: 1956.7070855035 |██████████----------| 54.0%  - val_loss: 1957.4545491536 - val_trvae_loss: 1957.4545491536 |███████████---------| 55.0%  - val_loss: 1951.2092420790 - val_trvae_loss: 1951.2092420790 |███████████---------| 56.0%  - val_loss: 1948.6639946832 - val_trvae_loss: 1948.6639946832 |███████████---------| 57.0%  - val_loss: 1939.4943440755 - val_trvae_loss: 1939.4943440755 |███████████---------| 58.0%  - val_loss: 1955.5857476128 - val_trvae_loss: 1955.5857476128 |███████████---------| 59.0%  - val_loss: 1947.6416965061 - val_trvae_loss: 1947.6416965061 |████████████--------| 60.0%  - val_loss: 1951.3953993056 - val_trvae_loss: 1951.3953993056 |████████████--------| 61.0%  - val_loss: 1946.5029296875 - val_trvae_loss: 1946.5029296875 |████████████--------| 62.0%  - val_loss: 1941.7467041016 - val_trvae_loss: 1941.7467041016 |████████████--------| 63.0%  - val_loss: 1941.0496554905 - val_trvae_loss: 1941.0496554905 |████████████--------| 64.0%  - val_loss: 1937.7749701606 - val_trvae_loss: 1937.7749701606 |█████████████-------| 65.0%  - val_loss: 1943.1457519531 - val_trvae_loss: 1943.1457519531 |█████████████-------| 66.0%  - val_loss: 1944.6648763021 - val_trvae_loss: 1944.6648763021 |█████████████-------| 67.0%  - val_loss: 1953.4725206163 - val_trvae_loss: 1953.4725206163 |█████████████-------| 68.0%  - val_loss: 1931.1665310330 - val_trvae_loss: 1931.1665310330 |█████████████-------| 69.0%  - val_loss: 1947.8360866970 - val_trvae_loss: 1947.8360866970 |██████████████------| 70.0%  - val_loss: 1944.7240804036 - val_trvae_loss: 1944.7240804036 |██████████████------| 71.0%  - val_loss: 1949.4517686632 - val_trvae_loss: 1949.4517686632 |██████████████------| 72.0%  - val_loss: 1964.1034749349 - val_trvae_loss: 1964.1034749349 |██████████████------| 73.0%  - val_loss: 1959.1133626302 - val_trvae_loss: 1959.1133626302 |██████████████------| 74.0%  - val_loss: 1942.1856689453 - val_trvae_loss: 1942.1856689453 |███████████████-----| 75.0%  - val_loss: 1943.9315321181 - val_trvae_loss: 1943.9315321181 |███████████████-----| 76.0%  - val_loss: 1964.7428521050 - val_trvae_loss: 1964.7428521050 |███████████████-----| 77.0%  - val_loss: 1951.1910536024 - val_trvae_loss: 1951.1910536024 |███████████████-----| 78.0%  - val_loss: 1938.2955050998 - val_trvae_loss: 1938.2955050998 |███████████████-----| 79.0%  - val_loss: 1957.1973741319 - val_trvae_loss: 1957.1973741319 |████████████████----| 80.0%  - val_loss: 1948.0742458767 - val_trvae_loss: 1948.0742458767
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 23 clusters.
 |████████████████----| 81.0%  - val_loss: 1959.3331027561 - val_trvae_loss: 1959.3329671224 - val_landmark_loss: 0.0001506806 - val_unlabeled_loss: 0.1506806388 |████████████████----| 82.0%  - val_loss: 1946.7396647135 - val_trvae_loss: 1946.7395019531 - val_landmark_loss: 0.0001467571 - val_unlabeled_loss: 0.1467571192 |████████████████----| 83.0%  - val_loss: 1944.6598714193 - val_trvae_loss: 1944.6597086589 - val_landmark_loss: 0.0001506344 - val_unlabeled_loss: 0.1506343683 |████████████████----| 84.0%  - val_loss: 1940.2736816406 - val_trvae_loss: 1940.2735324436 - val_landmark_loss: 0.0001544329 - val_unlabeled_loss: 0.1544328754 |█████████████████---| 85.0%  - val_loss: 1936.0022515191 - val_trvae_loss: 1936.0020887587 - val_landmark_loss: 0.0001609023 - val_unlabeled_loss: 0.1609022493 |█████████████████---| 86.0%  - val_loss: 1944.6017523872 - val_trvae_loss: 1944.6015896267 - val_landmark_loss: 0.0001483485 - val_unlabeled_loss: 0.1483484854 |█████████████████---| 87.0%  - val_loss: 1956.6006401910 - val_trvae_loss: 1956.6004909939 - val_landmark_loss: 0.0001477912 - val_unlabeled_loss: 0.1477912259 |█████████████████---| 88.0%  - val_loss: 1941.7227240668 - val_trvae_loss: 1941.7225748698 - val_landmark_loss: 0.0001491599 - val_unlabeled_loss: 0.1491599348 |█████████████████---| 89.0%  - val_loss: 1959.2440592448 - val_trvae_loss: 1959.2439100477 - val_landmark_loss: 0.0001508181 - val_unlabeled_loss: 0.1508181186 |██████████████████--| 90.0%  - val_loss: 1959.1749131944 - val_trvae_loss: 1959.1747504340 - val_landmark_loss: 0.0001501682 - val_unlabeled_loss: 0.1501681482 |██████████████████--| 91.0%  - val_loss: 1936.5775282118 - val_trvae_loss: 1936.5773654514 - val_landmark_loss: 0.0001746754 - val_unlabeled_loss: 0.1746754390 |██████████████████--| 92.0%  - val_loss: 1938.7543538411 - val_trvae_loss: 1938.7542046441 - val_landmark_loss: 0.0001577626 - val_unlabeled_loss: 0.1577626218 |██████████████████--| 93.0%  - val_loss: 1934.3464219835 - val_trvae_loss: 1934.3462727865 - val_landmark_loss: 0.0001482060 - val_unlabeled_loss: 0.1482060005 |██████████████████--| 94.0%  - val_loss: 1950.3424479167 - val_trvae_loss: 1950.3422851562 - val_landmark_loss: 0.0001608512 - val_unlabeled_loss: 0.1608511897 |███████████████████-| 95.0%  - val_loss: 1954.3677707248 - val_trvae_loss: 1954.3676215278 - val_landmark_loss: 0.0001506444 - val_unlabeled_loss: 0.1506444357 |███████████████████-| 96.0%  - val_loss: 1961.5116644965 - val_trvae_loss: 1961.5115152995 - val_landmark_loss: 0.0001500265 - val_unlabeled_loss: 0.1500264481 |███████████████████-| 97.0%  - val_loss: 1945.5147569444 - val_trvae_loss: 1945.5145941840 - val_landmark_loss: 0.0001519336 - val_unlabeled_loss: 0.1519336378 |███████████████████-| 98.0%  - val_loss: 1954.5218370226 - val_trvae_loss: 1954.5216878255 - val_landmark_loss: 0.0001472933 - val_unlabeled_loss: 0.1472932431 |███████████████████-| 99.0%  - val_loss: 1949.9720594618 - val_trvae_loss: 1949.9718695747 - val_landmark_loss: 0.0001616423 - val_unlabeled_loss: 0.1616422567 |████████████████████| 100.0%  - val_loss: 1949.0051405165 - val_trvae_loss: 1949.0050048828 - val_landmark_loss: 0.0001472918 - val_unlabeled_loss: 0.1472918226
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 16:19:05 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 16:19:07 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2021-10-26 16:35:08 (INFO): Result: {'distances':   condition  cos_dist  eucl_dist
0    Oetjen  0.881158   0.885845
1       Sun  0.999885   0.876565
2   Freytag  1.120708   0.876565
3       10X  0.881158   2.936015, 'classification_report':                                   precision    recall  f1-score      support
CD10+ B cells                      0.949309  0.995169  0.971698    207.00000
CD14+ Monocytes                    0.990256  0.978069  0.984124   6338.00000
CD16+ Monocytes                    0.923429  0.979394  0.950588    825.00000
CD20+ B cells                      0.997203  0.992691  0.994942   2873.00000
CD4+ T cells                       0.956675  0.914449  0.935085  11011.00000
CD8+ T cells                       0.689827  0.823179  0.750627   2183.00000
Erythrocytes                       0.947876  0.980692  0.964005   1502.00000
Erythroid progenitors              0.850254  0.723542  0.781797    463.00000
HSPCs                              0.945833  0.959831  0.952781    473.00000
Megakaryocyte progenitors          0.750000  0.844444  0.794425    270.00000
Monocyte progenitors               0.881466  0.955607  0.917040    428.00000
Monocyte-derived dendritic cells   0.945887  0.914226  0.929787    478.00000
NK cells                           0.919141  0.877071  0.897613   2294.00000
NKT cells                          0.860393  0.909290  0.884166   2745.00000
Plasma cells                       0.976562  0.968992  0.972763    129.00000
Plasmacytoid dendritic cells       0.992481  0.996226  0.994350    265.00000
accuracy                           0.928580  0.928580  0.928580      0.92858
macro avg                          0.911037  0.925805  0.917237  32484.00000
weighted avg                       0.932622  0.928580  0.929787  32484.00000, 'classification_report_query':                                   precision    recall  f1-score       support
CD10+ B cells                      0.000000  0.000000  0.000000      0.000000
CD14+ Monocytes                    0.984898  0.981700  0.983296   3388.000000
CD16+ Monocytes                    0.850490  0.953297  0.898964    364.000000
CD20+ B cells                      0.998048  0.992238  0.995135   1546.000000
CD4+ T cells                       0.974303  0.916582  0.944561   2937.000000
CD8+ T cells                       0.668627  0.974286  0.793023    350.000000
Erythroid progenitors              0.000000  0.000000  0.000000      0.000000
HSPCs                              0.857143  0.642857  0.734694     28.000000
Megakaryocyte progenitors          0.525000  1.000000  0.688525     21.000000
Monocyte-derived dendritic cells   0.993243  0.807692  0.890909    182.000000
NK cells                           0.901065  0.783069  0.837933    756.000000
NKT cells                          0.794674  0.875947  0.833333   1056.000000
Plasma cells                       1.000000  0.722222  0.838710     18.000000
Plasmacytoid dendritic cells       1.000000  0.987654  0.993789     81.000000
accuracy                           0.935583  0.935583  0.935583      0.935583
macro avg                          0.753392  0.759825  0.745205  10727.000000
weighted avg                       0.943425  0.935583  0.937363  10727.000000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.872361           0.868152  ...                   0.530602    0.984357

[1 rows x 8 columns]}
2021-10-26 16:35:08 (INFO): Completed after 0:20:18
Saving best state of network...
Best State was in Epoch 81
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
