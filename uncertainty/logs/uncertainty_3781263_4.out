Starting job 3781268
SLURM assigned me the node(s): gpusrv10
Experiments are running under the following process IDs:
Experiment ID: 5	Process ID: 10332

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 10:57:03 (INFO): Running command 'run'
2021-10-26 10:57:03 (INFO): Started run with ID "5"
2021-10-26 10:57:16 (INFO): Data loaded succesfully
2021-10-26 10:57:16 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1224.5152869591 - val_trvae_loss: 1224.5152869591 |--------------------| 2.0%  - val_loss: 1168.6403714694 - val_trvae_loss: 1168.6403714694 |--------------------| 3.0%  - val_loss: 1142.6091308594 - val_trvae_loss: 1142.6091308594 |--------------------| 4.0%  - val_loss: 1122.1741192157 - val_trvae_loss: 1122.1741192157 |█-------------------| 5.0%  - val_loss: 1118.1476205679 - val_trvae_loss: 1118.1476205679 |█-------------------| 6.0%  - val_loss: 1107.1638559195 - val_trvae_loss: 1107.1638559195 |█-------------------| 7.0%  - val_loss: 1099.8410926232 - val_trvae_loss: 1099.8410926232 |█-------------------| 8.0%  - val_loss: 1095.2647235577 - val_trvae_loss: 1095.2647235577 |█-------------------| 9.0%  - val_loss: 1095.1406719501 - val_trvae_loss: 1095.1406719501 |██------------------| 10.0%  - val_loss: 1091.9196965144 - val_trvae_loss: 1091.9196965144 |██------------------| 11.0%  - val_loss: 1082.8575345553 - val_trvae_loss: 1082.8575345553 |██------------------| 12.0%  - val_loss: 1079.7239802434 - val_trvae_loss: 1079.7239802434 |██------------------| 13.0%  - val_loss: 1080.7093036358 - val_trvae_loss: 1080.7093036358 |██------------------| 14.0%  - val_loss: 1084.1989370493 - val_trvae_loss: 1084.1989370493 |███-----------------| 15.0%  - val_loss: 1069.7189096304 - val_trvae_loss: 1069.7189096304 |███-----------------| 16.0%  - val_loss: 1068.6132953350 - val_trvae_loss: 1068.6132953350 |███-----------------| 17.0%  - val_loss: 1074.4199406550 - val_trvae_loss: 1074.4199406550 |███-----------------| 18.0%  - val_loss: 1078.2937293419 - val_trvae_loss: 1078.2937293419 |███-----------------| 19.0%  - val_loss: 1071.1454608624 - val_trvae_loss: 1071.1454608624 |████----------------| 20.0%  - val_loss: 1072.5566875751 - val_trvae_loss: 1072.5566875751 |████----------------| 21.0%  - val_loss: 1071.3498253456 - val_trvae_loss: 1071.3498253456 |████----------------| 22.0%  - val_loss: 1074.3862868089 - val_trvae_loss: 1074.3862868089 |████----------------| 23.0%  - val_loss: 1065.5204702524 - val_trvae_loss: 1065.5204702524 |████----------------| 24.0%  - val_loss: 1063.1678232046 - val_trvae_loss: 1063.1678232046 |█████---------------| 25.0%  - val_loss: 1065.9502093975 - val_trvae_loss: 1065.9502093975 |█████---------------| 26.0%  - val_loss: 1063.9309457632 - val_trvae_loss: 1063.9309457632 |█████---------------| 27.0%  - val_loss: 1061.3913574219 - val_trvae_loss: 1061.3913574219 |█████---------------| 28.0%  - val_loss: 1064.8889160156 - val_trvae_loss: 1064.8889160156 |█████---------------| 29.0%  - val_loss: 1062.2467933068 - val_trvae_loss: 1062.2467933068 |██████--------------| 30.0%  - val_loss: 1065.7129281851 - val_trvae_loss: 1065.7129281851 |██████--------------| 31.0%  - val_loss: 1061.3637413612 - val_trvae_loss: 1061.3637413612 |██████--------------| 32.0%  - val_loss: 1061.6156757061 - val_trvae_loss: 1061.6156757061 |██████--------------| 33.0%  - val_loss: 1061.1202909029 - val_trvae_loss: 1061.1202909029 |██████--------------| 34.0%  - val_loss: 1056.8150540865 - val_trvae_loss: 1056.8150540865 |███████-------------| 35.0%  - val_loss: 1060.5313720703 - val_trvae_loss: 1060.5313720703 |███████-------------| 36.0%  - val_loss: 1066.4822810246 - val_trvae_loss: 1066.4822810246 |███████-------------| 37.0%  - val_loss: 1065.5953228290 - val_trvae_loss: 1065.5953228290 |███████-------------| 38.0%  - val_loss: 1054.2154118465 - val_trvae_loss: 1054.2154118465 |███████-------------| 39.0%  - val_loss: 1056.1354276217 - val_trvae_loss: 1056.1354276217 |████████------------| 40.0%  - val_loss: 1058.9127009465 - val_trvae_loss: 1058.9127009465 |████████------------| 41.0%  - val_loss: 1056.6897864709 - val_trvae_loss: 1056.6897864709 |████████------------| 42.0%  - val_loss: 1057.9052077073 - val_trvae_loss: 1057.9052077073 |████████------------| 43.0%  - val_loss: 1059.4878774790 - val_trvae_loss: 1059.4878774790 |████████------------| 44.0%  - val_loss: 1061.3417968750 - val_trvae_loss: 1061.3417968750 |█████████-----------| 45.0%  - val_loss: 1054.7362717849 - val_trvae_loss: 1054.7362717849 |█████████-----------| 46.0%  - val_loss: 1058.5061880258 - val_trvae_loss: 1058.5061880258 |█████████-----------| 47.0%  - val_loss: 1060.5051222581 - val_trvae_loss: 1060.5051222581 |█████████-----------| 48.0%  - val_loss: 1060.7113271860 - val_trvae_loss: 1060.7113271860 |█████████-----------| 49.0%  - val_loss: 1056.5009859525 - val_trvae_loss: 1056.5009859525 |██████████----------| 50.0%  - val_loss: 1058.0929612380 - val_trvae_loss: 1058.0929612380 |██████████----------| 51.0%  - val_loss: 1056.9959341196 - val_trvae_loss: 1056.9959341196 |██████████----------| 52.0%  - val_loss: 1059.3430692233 - val_trvae_loss: 1059.3430692233 |██████████----------| 53.0%  - val_loss: 1057.9881216196 - val_trvae_loss: 1057.9881216196 |██████████----------| 54.0%  - val_loss: 1064.3724553035 - val_trvae_loss: 1064.3724553035 |███████████---------| 55.0%  - val_loss: 1052.9463970478 - val_trvae_loss: 1052.9463970478 |███████████---------| 56.0%  - val_loss: 1053.7038527269 - val_trvae_loss: 1053.7038527269 |███████████---------| 57.0%  - val_loss: 1058.8170166016 - val_trvae_loss: 1058.8170166016 |███████████---------| 58.0%  - val_loss: 1057.2842876728 - val_trvae_loss: 1057.2842876728 |███████████---------| 59.0%  - val_loss: 1065.0286677434 - val_trvae_loss: 1065.0286677434 |████████████--------| 60.0%  - val_loss: 1057.4269268329 - val_trvae_loss: 1057.4269268329 |████████████--------| 61.0%  - val_loss: 1053.9534020057 - val_trvae_loss: 1053.9534020057 |████████████--------| 62.0%  - val_loss: 1059.2482722356 - val_trvae_loss: 1059.2482722356 |████████████--------| 63.0%  - val_loss: 1057.4168325571 - val_trvae_loss: 1057.4168325571 |████████████--------| 64.0%  - val_loss: 1052.4467491737 - val_trvae_loss: 1052.4467491737 |█████████████-------| 65.0%  - val_loss: 1053.5493539663 - val_trvae_loss: 1053.5493539663 |█████████████-------| 66.0%  - val_loss: 1054.8023728591 - val_trvae_loss: 1054.8023728591 |█████████████-------| 67.0%  - val_loss: 1060.4929387019 - val_trvae_loss: 1060.4929387019 |█████████████-------| 68.0%  - val_loss: 1059.7693903996 - val_trvae_loss: 1059.7693903996 |█████████████-------| 69.0%  - val_loss: 1056.4517352764 - val_trvae_loss: 1056.4517352764 |██████████████------| 70.0%  - val_loss: 1057.7510798528 - val_trvae_loss: 1057.7510798528 |██████████████------| 71.0%  - val_loss: 1055.2259990986 - val_trvae_loss: 1055.2259990986 |██████████████------| 72.0%  - val_loss: 1057.7187687800 - val_trvae_loss: 1057.7187687800 |██████████████------| 73.0%  - val_loss: 1056.3257399339 - val_trvae_loss: 1056.3257399339 |██████████████------| 74.0%  - val_loss: 1051.7113037109 - val_trvae_loss: 1051.7113037109 |███████████████-----| 75.0%  - val_loss: 1053.2228346605 - val_trvae_loss: 1053.2228346605 |███████████████-----| 76.0%  - val_loss: 1057.8365619366 - val_trvae_loss: 1057.8365619366 |███████████████-----| 77.0%  - val_loss: 1056.0416259766 - val_trvae_loss: 1056.0416259766 |███████████████-----| 78.0%  - val_loss: 1057.1610529973 - val_trvae_loss: 1057.1610529973 |███████████████-----| 79.0%  - val_loss: 1054.3644221379 - val_trvae_loss: 1054.3644221379 |████████████████----| 80.0%  - val_loss: 1054.3238947942 - val_trvae_loss: 1054.3238947942 |████████████████----| 81.0%  - val_loss: 1064.8369234525 - val_trvae_loss: 1061.6671142578 - val_landmark_loss: 3.1698037478 - val_labeled_loss: 3.1698037478 |████████████████----| 82.0%  - val_loss: 1060.9864689754 - val_trvae_loss: 1057.7169424204 - val_landmark_loss: 3.2695142122 - val_labeled_loss: 3.2695142122 |████████████████----| 83.0%  - val_loss: 1057.7355299730 - val_trvae_loss: 1055.5206909180 - val_landmark_loss: 2.2148206876 - val_labeled_loss: 2.2148206876 |████████████████----| 84.0%  - val_loss: 1063.0204937275 - val_trvae_loss: 1060.9414438101 - val_landmark_loss: 2.0790530993 - val_labeled_loss: 2.0790530993 |█████████████████---| 85.0%  - val_loss: 1061.6513812725 - val_trvae_loss: 1059.6456580529 - val_landmark_loss: 2.0057325913 - val_labeled_loss: 2.0057325913 |█████████████████---| 86.0%  - val_loss: 1061.5741060697 - val_trvae_loss: 1059.9890981821 - val_landmark_loss: 1.5849896853 - val_labeled_loss: 1.5849896853 |█████████████████---| 87.0%  - val_loss: 1064.2245999850 - val_trvae_loss: 1062.3747840294 - val_landmark_loss: 1.8498248275 - val_labeled_loss: 1.8498248275 |█████████████████---| 88.0%  - val_loss: 1060.9641676683 - val_trvae_loss: 1059.3642202524 - val_landmark_loss: 1.5999442201 - val_labeled_loss: 1.5999442201 |█████████████████---| 89.0%  - val_loss: 1057.6664475661 - val_trvae_loss: 1056.2835834210 - val_landmark_loss: 1.3828529074 - val_labeled_loss: 1.3828529074 |██████████████████--| 90.0%  - val_loss: 1063.0041503906 - val_trvae_loss: 1061.6099665715 - val_landmark_loss: 1.3941795367 - val_labeled_loss: 1.3941795367 |██████████████████--| 91.0%  - val_loss: 1057.2703294020 - val_trvae_loss: 1056.1553767278 - val_landmark_loss: 1.1149538618 - val_labeled_loss: 1.1149538618 |██████████████████--| 92.0%  - val_loss: 1062.6439866286 - val_trvae_loss: 1061.4820556641 - val_landmark_loss: 1.1619273424 - val_labeled_loss: 1.1619273424 |██████████████████--| 93.0%  - val_loss: 1059.6833120493 - val_trvae_loss: 1058.4829664964 - val_landmark_loss: 1.2003499499 - val_labeled_loss: 1.2003499499 |██████████████████--| 94.0%  - val_loss: 1056.4147057166 - val_trvae_loss: 1055.1843496469 - val_landmark_loss: 1.2303643135 - val_labeled_loss: 1.2303643135 |███████████████████-| 95.0%  - val_loss: 1054.6434279222 - val_trvae_loss: 1053.5569411058 - val_landmark_loss: 1.0864959084 - val_labeled_loss: 1.0864959084 |███████████████████-| 96.0%  - val_loss: 1054.9847365159 - val_trvae_loss: 1053.9827927809 - val_landmark_loss: 1.0019437762 - val_labeled_loss: 1.0019437762 |███████████████████-| 97.0%  - val_loss: 1055.1307185246 - val_trvae_loss: 1054.0992196890 - val_landmark_loss: 1.0315018525 - val_labeled_loss: 1.0315018525 |███████████████████-| 98.0%  - val_loss: 1055.6120652419 - val_trvae_loss: 1054.4792480469 - val_landmark_loss: 1.1328263145 - val_labeled_loss: 1.1328263145 |███████████████████-| 99.0%  - val_loss: 1056.9848773663 - val_trvae_loss: 1056.0829514724 - val_landmark_loss: 0.9019438670 - val_labeled_loss: 0.9019438670 |████████████████████| 100.0%  - val_loss: 1057.1741426908 - val_trvae_loss: 1056.3387685922 - val_landmark_loss: 0.8353810631 - val_labeled_loss: 0.8353810631
2021-10-26 10:59:39 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 638 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1845.6812744141 - val_trvae_loss: 1845.6812744141 |--------------------| 2.0%  - val_loss: 1845.4644775391 - val_trvae_loss: 1845.4644775391 |--------------------| 3.0%  - val_loss: 1843.2344970703 - val_trvae_loss: 1843.2344970703 |--------------------| 4.0%  - val_loss: 1842.4718017578 - val_trvae_loss: 1842.4718017578 |█-------------------| 5.0%  - val_loss: 1843.9965820312 - val_trvae_loss: 1843.9965820312 |█-------------------| 6.0%  - val_loss: 1843.1035156250 - val_trvae_loss: 1843.1035156250 |█-------------------| 7.0%  - val_loss: 1842.2623291016 - val_trvae_loss: 1842.2623291016 |█-------------------| 8.0%  - val_loss: 1842.5576171875 - val_trvae_loss: 1842.5576171875 |█-------------------| 9.0%  - val_loss: 1840.6937255859 - val_trvae_loss: 1840.6937255859 |██------------------| 10.0%  - val_loss: 1840.5190429688 - val_trvae_loss: 1840.5190429688 |██------------------| 11.0%  - val_loss: 1840.3815917969 - val_trvae_loss: 1840.3815917969 |██------------------| 12.0%  - val_loss: 1839.7849121094 - val_trvae_loss: 1839.7849121094 |██------------------| 13.0%  - val_loss: 1839.7926025391 - val_trvae_loss: 1839.7926025391 |██------------------| 14.0%  - val_loss: 1838.5833740234 - val_trvae_loss: 1838.5833740234 |███-----------------| 15.0%  - val_loss: 1837.5438232422 - val_trvae_loss: 1837.5438232422 |███-----------------| 16.0%  - val_loss: 1838.5615234375 - val_trvae_loss: 1838.5615234375 |███-----------------| 17.0%  - val_loss: 1835.5067138672 - val_trvae_loss: 1835.5067138672 |███-----------------| 18.0%  - val_loss: 1836.6660156250 - val_trvae_loss: 1836.6660156250 |███-----------------| 19.0%  - val_loss: 1836.0975341797 - val_trvae_loss: 1836.0975341797 |████----------------| 20.0%  - val_loss: 1837.4680175781 - val_trvae_loss: 1837.4680175781 |████----------------| 21.0%  - val_loss: 1836.6645507812 - val_trvae_loss: 1836.6645507812 |████----------------| 22.0%  - val_loss: 1835.3488769531 - val_trvae_loss: 1835.3488769531 |████----------------| 23.0%  - val_loss: 1834.9404296875 - val_trvae_loss: 1834.9404296875 |████----------------| 24.0%  - val_loss: 1835.3154296875 - val_trvae_loss: 1835.3154296875 |█████---------------| 25.0%  - val_loss: 1833.1406250000 - val_trvae_loss: 1833.1406250000 |█████---------------| 26.0%  - val_loss: 1833.6054687500 - val_trvae_loss: 1833.6054687500 |█████---------------| 27.0%  - val_loss: 1832.7221679688 - val_trvae_loss: 1832.7221679688 |█████---------------| 28.0%  - val_loss: 1832.6223144531 - val_trvae_loss: 1832.6223144531 |█████---------------| 29.0%  - val_loss: 1831.7081298828 - val_trvae_loss: 1831.7081298828 |██████--------------| 30.0%  - val_loss: 1832.6490478516 - val_trvae_loss: 1832.6490478516 |██████--------------| 31.0%  - val_loss: 1832.5561523438 - val_trvae_loss: 1832.5561523438 |██████--------------| 32.0%  - val_loss: 1831.6156005859 - val_trvae_loss: 1831.6156005859 |██████--------------| 33.0%  - val_loss: 1831.4870605469 - val_trvae_loss: 1831.4870605469 |██████--------------| 34.0%  - val_loss: 1829.6442871094 - val_trvae_loss: 1829.6442871094 |███████-------------| 35.0%  - val_loss: 1829.4686279297 - val_trvae_loss: 1829.4686279297 |███████-------------| 36.0%  - val_loss: 1830.2031250000 - val_trvae_loss: 1830.2031250000 |███████-------------| 37.0%  - val_loss: 1828.9117431641 - val_trvae_loss: 1828.9117431641 |███████-------------| 38.0%  - val_loss: 1829.7749023438 - val_trvae_loss: 1829.7749023438 |███████-------------| 39.0%  - val_loss: 1828.0358886719 - val_trvae_loss: 1828.0358886719 |████████------------| 40.0%  - val_loss: 1827.0640869141 - val_trvae_loss: 1827.0640869141 |████████------------| 41.0%  - val_loss: 1827.5412597656 - val_trvae_loss: 1827.5412597656 |████████------------| 42.0%  - val_loss: 1826.8553466797 - val_trvae_loss: 1826.8553466797 |████████------------| 43.0%  - val_loss: 1826.6674804688 - val_trvae_loss: 1826.6674804688 |████████------------| 44.0%  - val_loss: 1825.4323730469 - val_trvae_loss: 1825.4323730469 |█████████-----------| 45.0%  - val_loss: 1826.2308349609 - val_trvae_loss: 1826.2308349609 |█████████-----------| 46.0%  - val_loss: 1823.6889648438 - val_trvae_loss: 1823.6889648438 |█████████-----------| 47.0%  - val_loss: 1824.5142822266 - val_trvae_loss: 1824.5142822266 |█████████-----------| 48.0%  - val_loss: 1824.7381591797 - val_trvae_loss: 1824.7381591797 |█████████-----------| 49.0%  - val_loss: 1824.6959228516 - val_trvae_loss: 1824.6959228516 |██████████----------| 50.0%  - val_loss: 1824.7189941406 - val_trvae_loss: 1824.7189941406 |██████████----------| 51.0%  - val_loss: 1824.2043457031 - val_trvae_loss: 1824.2043457031 |██████████----------| 52.0%  - val_loss: 1823.8779296875 - val_trvae_loss: 1823.8779296875 |██████████----------| 53.0%  - val_loss: 1823.2091064453 - val_trvae_loss: 1823.2091064453 |██████████----------| 54.0%  - val_loss: 1822.9919433594 - val_trvae_loss: 1822.9919433594 |███████████---------| 55.0%  - val_loss: 1822.6412353516 - val_trvae_loss: 1822.6412353516 |███████████---------| 56.0%  - val_loss: 1821.4013671875 - val_trvae_loss: 1821.4013671875 |███████████---------| 57.0%  - val_loss: 1823.1827392578 - val_trvae_loss: 1823.1827392578 |███████████---------| 58.0%  - val_loss: 1820.5521240234 - val_trvae_loss: 1820.5521240234 |███████████---------| 59.0%  - val_loss: 1819.9604492188 - val_trvae_loss: 1819.9604492188 |████████████--------| 60.0%  - val_loss: 1821.7451171875 - val_trvae_loss: 1821.7451171875 |████████████--------| 61.0%  - val_loss: 1820.4160156250 - val_trvae_loss: 1820.4160156250 |████████████--------| 62.0%  - val_loss: 1820.3736572266 - val_trvae_loss: 1820.3736572266 |████████████--------| 63.0%  - val_loss: 1818.5097656250 - val_trvae_loss: 1818.5097656250 |████████████--------| 64.0%  - val_loss: 1818.6690673828 - val_trvae_loss: 1818.6690673828 |█████████████-------| 65.0%  - val_loss: 1818.6027832031 - val_trvae_loss: 1818.6027832031 |█████████████-------| 66.0%  - val_loss: 1818.3886718750 - val_trvae_loss: 1818.3886718750 |█████████████-------| 67.0%  - val_loss: 1818.0052490234 - val_trvae_loss: 1818.0052490234 |█████████████-------| 68.0%  - val_loss: 1817.3868408203 - val_trvae_loss: 1817.3868408203 |█████████████-------| 69.0%  - val_loss: 1817.9118652344 - val_trvae_loss: 1817.9118652344 |██████████████------| 70.0%  - val_loss: 1818.3223876953 - val_trvae_loss: 1818.3223876953 |██████████████------| 71.0%  - val_loss: 1816.6929931641 - val_trvae_loss: 1816.6929931641 |██████████████------| 72.0%  - val_loss: 1815.6069335938 - val_trvae_loss: 1815.6069335938 |██████████████------| 73.0%  - val_loss: 1816.4687500000 - val_trvae_loss: 1816.4687500000 |██████████████------| 74.0%  - val_loss: 1816.9544677734 - val_trvae_loss: 1816.9544677734 |███████████████-----| 75.0%  - val_loss: 1814.9688720703 - val_trvae_loss: 1814.9688720703 |███████████████-----| 76.0%  - val_loss: 1815.9814453125 - val_trvae_loss: 1815.9814453125 |███████████████-----| 77.0%  - val_loss: 1815.7778320312 - val_trvae_loss: 1815.7778320312 |███████████████-----| 78.0%  - val_loss: 1814.1538085938 - val_trvae_loss: 1814.1538085938 |███████████████-----| 79.0%  - val_loss: 1815.2037353516 - val_trvae_loss: 1815.2037353516 |████████████████----| 80.0%  - val_loss: 1814.1975097656 - val_trvae_loss: 1814.1975097656
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 11 clusters.
 |████████████████----| 81.0%  - val_loss: 1812.9248046875 - val_trvae_loss: 1812.9235839844 - val_landmark_loss: 0.0012163685 - val_unlabeled_loss: 1.2163684368 |████████████████----| 82.0%  - val_loss: 1813.0664062500 - val_trvae_loss: 1813.0651855469 - val_landmark_loss: 0.0012063254 - val_unlabeled_loss: 1.2063252926 |████████████████----| 83.0%  - val_loss: 1812.8637695312 - val_trvae_loss: 1812.8625488281 - val_landmark_loss: 0.0012108622 - val_unlabeled_loss: 1.2108621597 |████████████████----| 84.0%  - val_loss: 1812.4790039062 - val_trvae_loss: 1812.4777832031 - val_landmark_loss: 0.0012132335 - val_unlabeled_loss: 1.2132333517 |█████████████████---| 85.0%  - val_loss: 1812.3662109375 - val_trvae_loss: 1812.3649902344 - val_landmark_loss: 0.0012267875 - val_unlabeled_loss: 1.2267874479 |█████████████████---| 86.0%  - val_loss: 1812.1574707031 - val_trvae_loss: 1812.1562500000 - val_landmark_loss: 0.0011940708 - val_unlabeled_loss: 1.1940706968 |█████████████████---| 87.0%  - val_loss: 1811.3999023438 - val_trvae_loss: 1811.3986816406 - val_landmark_loss: 0.0012061546 - val_unlabeled_loss: 1.2061545849 |█████████████████---| 88.0%  - val_loss: 1811.4910888672 - val_trvae_loss: 1811.4898681641 - val_landmark_loss: 0.0012109597 - val_unlabeled_loss: 1.2109596729 |█████████████████---| 89.0%  - val_loss: 1810.8162841797 - val_trvae_loss: 1810.8150634766 - val_landmark_loss: 0.0012066413 - val_unlabeled_loss: 1.2066413164 |██████████████████--| 90.0%  - val_loss: 1810.9739990234 - val_trvae_loss: 1810.9727783203 - val_landmark_loss: 0.0012021689 - val_unlabeled_loss: 1.2021688223 |██████████████████--| 91.0%  - val_loss: 1809.7437744141 - val_trvae_loss: 1809.7425537109 - val_landmark_loss: 0.0012085745 - val_unlabeled_loss: 1.2085744143 |██████████████████--| 92.0%  - val_loss: 1810.4078369141 - val_trvae_loss: 1810.4066162109 - val_landmark_loss: 0.0012155036 - val_unlabeled_loss: 1.2155034542 |██████████████████--| 93.0%  - val_loss: 1810.7642822266 - val_trvae_loss: 1810.7630615234 - val_landmark_loss: 0.0012056635 - val_unlabeled_loss: 1.2056634426 |██████████████████--| 94.0%  - val_loss: 1809.6529541016 - val_trvae_loss: 1809.6517333984 - val_landmark_loss: 0.0012075612 - val_unlabeled_loss: 1.2075611353 |███████████████████-| 95.0%  - val_loss: 1809.4923095703 - val_trvae_loss: 1809.4910888672 - val_landmark_loss: 0.0012341340 - val_unlabeled_loss: 1.2341339588 |███████████████████-| 96.0%  - val_loss: 1809.5991210938 - val_trvae_loss: 1809.5979003906 - val_landmark_loss: 0.0011904449 - val_unlabeled_loss: 1.1904448271 |███████████████████-| 97.0%  - val_loss: 1808.4348144531 - val_trvae_loss: 1808.4335937500 - val_landmark_loss: 0.0012031446 - val_unlabeled_loss: 1.2031445503 |███████████████████-| 98.0%  - val_loss: 1809.8181152344 - val_trvae_loss: 1809.8168945312 - val_landmark_loss: 0.0011977382 - val_unlabeled_loss: 1.1977381706 |███████████████████-| 99.0%  - val_loss: 1808.4229736328 - val_trvae_loss: 1808.4217529297 - val_landmark_loss: 0.0011976084 - val_unlabeled_loss: 1.1976083517 |████████████████████| 100.0%  - val_loss: 1807.9432373047 - val_trvae_loss: 1807.9420166016 - val_landmark_loss: 0.0012110801 - val_unlabeled_loss: 1.2110800743
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 10:59:55 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 10:59:55 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
slurmstepd: error: *** JOB 3781268 ON gpusrv10 CANCELLED AT 2021-10-26T11:01:37 ***
