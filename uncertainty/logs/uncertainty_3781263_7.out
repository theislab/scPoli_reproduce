Starting job 3781271
SLURM assigned me the node(s): gpusrv11
Experiments are running under the following process IDs:
Experiment ID: 8	Process ID: 41846

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 10:57:02 (INFO): Running command 'run'
2021-10-26 10:57:02 (INFO): Started run with ID "8"
2021-10-26 10:57:16 (INFO): Data loaded succesfully
2021-10-26 10:57:16 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1223.4198710124 - val_trvae_loss: 1223.4198710124 |--------------------| 2.0%  - val_loss: 1172.5855814616 - val_trvae_loss: 1172.5855814616 |--------------------| 3.0%  - val_loss: 1131.6751098633 - val_trvae_loss: 1131.6751098633 |--------------------| 4.0%  - val_loss: 1118.7164204915 - val_trvae_loss: 1118.7164204915 |█-------------------| 5.0%  - val_loss: 1108.2951354980 - val_trvae_loss: 1108.2951354980 |█-------------------| 6.0%  - val_loss: 1100.4887593587 - val_trvae_loss: 1100.4887593587 |█-------------------| 7.0%  - val_loss: 1093.4959615072 - val_trvae_loss: 1093.4959615072 |█-------------------| 8.0%  - val_loss: 1088.3634948730 - val_trvae_loss: 1088.3634948730 |█-------------------| 9.0%  - val_loss: 1084.4900512695 - val_trvae_loss: 1084.4900512695 |██------------------| 10.0%  - val_loss: 1080.8614705404 - val_trvae_loss: 1080.8614705404 |██------------------| 11.0%  - val_loss: 1078.1331990560 - val_trvae_loss: 1078.1331990560 |██------------------| 12.0%  - val_loss: 1075.4890340169 - val_trvae_loss: 1075.4890340169 |██------------------| 13.0%  - val_loss: 1073.4650980632 - val_trvae_loss: 1073.4650980632 |██------------------| 14.0%  - val_loss: 1071.8348388672 - val_trvae_loss: 1071.8348388672 |███-----------------| 15.0%  - val_loss: 1069.6037394206 - val_trvae_loss: 1069.6037394206 |███-----------------| 16.0%  - val_loss: 1067.8179626465 - val_trvae_loss: 1067.8179626465 |███-----------------| 17.0%  - val_loss: 1066.6376342773 - val_trvae_loss: 1066.6376342773 |███-----------------| 18.0%  - val_loss: 1065.3243459066 - val_trvae_loss: 1065.3243459066 |███-----------------| 19.0%  - val_loss: 1064.2229156494 - val_trvae_loss: 1064.2229156494 |████----------------| 20.0%  - val_loss: 1063.9681091309 - val_trvae_loss: 1063.9681091309 |████----------------| 21.0%  - val_loss: 1062.3172810872 - val_trvae_loss: 1062.3172810872 |████----------------| 22.0%  - val_loss: 1061.8304138184 - val_trvae_loss: 1061.8304138184 |████----------------| 23.0%  - val_loss: 1060.6402231852 - val_trvae_loss: 1060.6402231852 |████----------------| 24.0%  - val_loss: 1060.1491902669 - val_trvae_loss: 1060.1491902669 |█████---------------| 25.0%  - val_loss: 1059.4645233154 - val_trvae_loss: 1059.4645233154 |█████---------------| 26.0%  - val_loss: 1058.8397165934 - val_trvae_loss: 1058.8397165934 |█████---------------| 27.0%  - val_loss: 1058.7450052897 - val_trvae_loss: 1058.7450052897 |█████---------------| 28.0%  - val_loss: 1058.0912373861 - val_trvae_loss: 1058.0912373861 |█████---------------| 29.0%  - val_loss: 1057.4188639323 - val_trvae_loss: 1057.4188639323 |██████--------------| 30.0%  - val_loss: 1057.2035420736 - val_trvae_loss: 1057.2035420736 |██████--------------| 31.0%  - val_loss: 1056.5170949300 - val_trvae_loss: 1056.5170949300 |██████--------------| 32.0%  - val_loss: 1056.8169403076 - val_trvae_loss: 1056.8169403076 |██████--------------| 33.0%  - val_loss: 1056.1822662354 - val_trvae_loss: 1056.1822662354 |██████--------------| 34.0%  - val_loss: 1056.0043792725 - val_trvae_loss: 1056.0043792725 |███████-------------| 35.0%  - val_loss: 1056.0105387370 - val_trvae_loss: 1056.0105387370 |███████-------------| 36.0%  - val_loss: 1055.3062032064 - val_trvae_loss: 1055.3062032064 |███████-------------| 37.0%  - val_loss: 1055.6705525716 - val_trvae_loss: 1055.6705525716 |███████-------------| 38.0%  - val_loss: 1055.3597106934 - val_trvae_loss: 1055.3597106934 |███████-------------| 39.0%  - val_loss: 1054.6165364583 - val_trvae_loss: 1054.6165364583 |████████------------| 40.0%  - val_loss: 1054.8074595133 - val_trvae_loss: 1054.8074595133 |████████------------| 41.0%  - val_loss: 1054.6481526693 - val_trvae_loss: 1054.6481526693 |████████------------| 42.0%  - val_loss: 1054.4712626139 - val_trvae_loss: 1054.4712626139 |████████------------| 43.0%  - val_loss: 1053.9106140137 - val_trvae_loss: 1053.9106140137 |████████------------| 44.0%  - val_loss: 1054.1707712809 - val_trvae_loss: 1054.1707712809 |█████████-----------| 45.0%  - val_loss: 1054.1252441406 - val_trvae_loss: 1054.1252441406 |█████████-----------| 46.0%  - val_loss: 1053.4414723714 - val_trvae_loss: 1053.4414723714 |█████████-----------| 47.0%  - val_loss: 1053.7657623291 - val_trvae_loss: 1053.7657623291 |█████████-----------| 48.0%  - val_loss: 1053.7834370931 - val_trvae_loss: 1053.7834370931 |█████████-----------| 49.0%  - val_loss: 1053.3225809733 - val_trvae_loss: 1053.3225809733 |██████████----------| 50.0%  - val_loss: 1053.4319966634 - val_trvae_loss: 1053.4319966634 |██████████----------| 51.0%  - val_loss: 1053.6397908529 - val_trvae_loss: 1053.6397908529 |██████████----------| 52.0%  - val_loss: 1053.1231536865 - val_trvae_loss: 1053.1231536865 |██████████----------| 53.0%  - val_loss: 1052.9658508301 - val_trvae_loss: 1052.9658508301 |██████████----------| 54.0%  - val_loss: 1053.5333048503 - val_trvae_loss: 1053.5333048503 |███████████---------| 55.0%  - val_loss: 1053.1615804036 - val_trvae_loss: 1053.1615804036 |███████████---------| 56.0%  - val_loss: 1053.5629374186 - val_trvae_loss: 1053.5629374186 |███████████---------| 57.0%  - val_loss: 1053.2183430990 - val_trvae_loss: 1053.2183430990 |███████████---------| 58.0%  - val_loss: 1053.2836608887 - val_trvae_loss: 1053.2836608887 |███████████---------| 59.0%  - val_loss: 1053.1463877360 - val_trvae_loss: 1053.1463877360 |████████████--------| 60.0%  - val_loss: 1053.1002858480 - val_trvae_loss: 1053.1002858480 |████████████--------| 61.0%  - val_loss: 1052.6701965332 - val_trvae_loss: 1052.6701965332 |████████████--------| 62.0%  - val_loss: 1052.7246195475 - val_trvae_loss: 1052.7246195475 |████████████--------| 63.0%  - val_loss: 1052.8527781169 - val_trvae_loss: 1052.8527781169 |████████████--------| 64.0%  - val_loss: 1053.0436604818 - val_trvae_loss: 1053.0436604818 |█████████████-------| 65.0%  - val_loss: 1052.6992594401 - val_trvae_loss: 1052.6992594401 |█████████████-------| 66.0%  - val_loss: 1052.4426829020 - val_trvae_loss: 1052.4426829020 |█████████████-------| 67.0%  - val_loss: 1052.5928446452 - val_trvae_loss: 1052.5928446452 |█████████████-------| 68.0%  - val_loss: 1052.5575358073 - val_trvae_loss: 1052.5575358073 |█████████████-------| 69.0%  - val_loss: 1052.6297709147 - val_trvae_loss: 1052.6297709147 |██████████████------| 70.0%  - val_loss: 1052.6696573893 - val_trvae_loss: 1052.6696573893 |██████████████------| 71.0%  - val_loss: 1052.2905731201 - val_trvae_loss: 1052.2905731201 |██████████████------| 72.0%  - val_loss: 1052.3080546061 - val_trvae_loss: 1052.3080546061 |██████████████------| 73.0%  - val_loss: 1052.5890452067 - val_trvae_loss: 1052.5890452067 |██████████████------| 74.0%  - val_loss: 1052.2605845133 - val_trvae_loss: 1052.2605845133 |███████████████-----| 75.0%  - val_loss: 1052.2917785645 - val_trvae_loss: 1052.2917785645 |███████████████-----| 76.0%  - val_loss: 1052.0632578532 - val_trvae_loss: 1052.0632578532 |███████████████-----| 77.0%  - val_loss: 1051.9262288411 - val_trvae_loss: 1051.9262288411 |███████████████-----| 78.0%  - val_loss: 1052.1449381510 - val_trvae_loss: 1052.1449381510 |███████████████-----| 79.0%  - val_loss: 1051.7175038656 - val_trvae_loss: 1051.7175038656 |████████████████----| 80.0%  - val_loss: 1051.8762105306 - val_trvae_loss: 1051.8762105306 |████████████████----| 81.0%  - val_loss: 1058.4052785238 - val_trvae_loss: 1054.2572530111 - val_landmark_loss: 4.1480320195 - val_labeled_loss: 4.1480320195 |████████████████----| 82.0%  - val_loss: 1057.4644775391 - val_trvae_loss: 1053.9400838216 - val_landmark_loss: 3.5244102180 - val_labeled_loss: 3.5244102180 |████████████████----| 83.0%  - val_loss: 1056.4585469564 - val_trvae_loss: 1053.5378214518 - val_landmark_loss: 2.9207461874 - val_labeled_loss: 2.9207461874 |████████████████----| 84.0%  - val_loss: 1056.0728302002 - val_trvae_loss: 1053.1611633301 - val_landmark_loss: 2.9116660655 - val_labeled_loss: 2.9116660655 |█████████████████---| 85.0%  - val_loss: 1055.7030029297 - val_trvae_loss: 1052.8584543864 - val_landmark_loss: 2.8445469340 - val_labeled_loss: 2.8445469340 |█████████████████---| 86.0%  - val_loss: 1055.3539225260 - val_trvae_loss: 1052.6867065430 - val_landmark_loss: 2.6672270298 - val_labeled_loss: 2.6672270298 |█████████████████---| 87.0%  - val_loss: 1055.3383687337 - val_trvae_loss: 1052.7628529867 - val_landmark_loss: 2.5755215387 - val_labeled_loss: 2.5755215387 |█████████████████---| 88.0%  - val_loss: 1055.0046793620 - val_trvae_loss: 1052.8643646240 - val_landmark_loss: 2.1403117279 - val_labeled_loss: 2.1403117279 |█████████████████---| 89.0%  - val_loss: 1055.4135437012 - val_trvae_loss: 1053.4053802490 - val_landmark_loss: 2.0081728001 - val_labeled_loss: 2.0081728001 |██████████████████--| 90.0%  - val_loss: 1054.7865702311 - val_trvae_loss: 1052.6122843424 - val_landmark_loss: 2.1742791732 - val_labeled_loss: 2.1742791732 |██████████████████--| 91.0%  - val_loss: 1054.4479878743 - val_trvae_loss: 1052.7047220866 - val_landmark_loss: 1.7432825019 - val_labeled_loss: 1.7432825019 |██████████████████--| 92.0%  - val_loss: 1054.9243621826 - val_trvae_loss: 1052.7635294596 - val_landmark_loss: 2.1608373175 - val_labeled_loss: 2.1608373175 |██████████████████--| 93.0%  - val_loss: 1054.3426259359 - val_trvae_loss: 1052.2415008545 - val_landmark_loss: 2.1011180282 - val_labeled_loss: 2.1011180282 |██████████████████--| 94.0%  - val_loss: 1054.8036855062 - val_trvae_loss: 1052.6865946452 - val_landmark_loss: 2.1170869569 - val_labeled_loss: 2.1170869569 |███████████████████-| 95.0%  - val_loss: 1053.7339782715 - val_trvae_loss: 1052.3493448893 - val_landmark_loss: 1.3846287131 - val_labeled_loss: 1.3846287131 |███████████████████-| 96.0%  - val_loss: 1054.1964569092 - val_trvae_loss: 1052.4146779378 - val_landmark_loss: 1.7817630817 - val_labeled_loss: 1.7817630817 |███████████████████-| 97.0%  - val_loss: 1054.0886789958 - val_trvae_loss: 1052.2085469564 - val_landmark_loss: 1.8801140388 - val_labeled_loss: 1.8801140388 |███████████████████-| 98.0%  - val_loss: 1053.5122273763 - val_trvae_loss: 1052.0088348389 - val_landmark_loss: 1.5033613195 - val_labeled_loss: 1.5033613195 |███████████████████-| 99.0%  - val_loss: 1053.6537729899 - val_trvae_loss: 1052.0958760579 - val_landmark_loss: 1.5578935991 - val_labeled_loss: 1.5578935991 |████████████████████| 100.0%  - val_loss: 1053.1208190918 - val_trvae_loss: 1051.6992899577 - val_landmark_loss: 1.4215160956 - val_labeled_loss: 1.4215160956
2021-10-26 10:59:39 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 94
AnnData object with n_obs × n_vars = 1004 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1734.4958496094 - val_trvae_loss: 1734.4958496094 |--------------------| 2.0%  - val_loss: 1734.1270751953 - val_trvae_loss: 1734.1270751953 |--------------------| 3.0%  - val_loss: 1733.3363037109 - val_trvae_loss: 1733.3363037109 |--------------------| 4.0%  - val_loss: 1732.2946777344 - val_trvae_loss: 1732.2946777344 |█-------------------| 5.0%  - val_loss: 1731.7587890625 - val_trvae_loss: 1731.7587890625 |█-------------------| 6.0%  - val_loss: 1730.6154785156 - val_trvae_loss: 1730.6154785156 |█-------------------| 7.0%  - val_loss: 1729.9226074219 - val_trvae_loss: 1729.9226074219 |█-------------------| 8.0%  - val_loss: 1729.4720458984 - val_trvae_loss: 1729.4720458984 |█-------------------| 9.0%  - val_loss: 1729.0150146484 - val_trvae_loss: 1729.0150146484 |██------------------| 10.0%  - val_loss: 1727.8856201172 - val_trvae_loss: 1727.8856201172 |██------------------| 11.0%  - val_loss: 1727.4962158203 - val_trvae_loss: 1727.4962158203 |██------------------| 12.0%  - val_loss: 1726.9039306641 - val_trvae_loss: 1726.9039306641 |██------------------| 13.0%  - val_loss: 1725.7037353516 - val_trvae_loss: 1725.7037353516 |██------------------| 14.0%  - val_loss: 1725.0684814453 - val_trvae_loss: 1725.0684814453 |███-----------------| 15.0%  - val_loss: 1724.7214355469 - val_trvae_loss: 1724.7214355469 |███-----------------| 16.0%  - val_loss: 1723.8051757812 - val_trvae_loss: 1723.8051757812 |███-----------------| 17.0%  - val_loss: 1723.2315673828 - val_trvae_loss: 1723.2315673828 |███-----------------| 18.0%  - val_loss: 1722.4138183594 - val_trvae_loss: 1722.4138183594 |███-----------------| 19.0%  - val_loss: 1722.1219482422 - val_trvae_loss: 1722.1219482422 |████----------------| 20.0%  - val_loss: 1721.3250732422 - val_trvae_loss: 1721.3250732422 |████----------------| 21.0%  - val_loss: 1720.4587402344 - val_trvae_loss: 1720.4587402344 |████----------------| 22.0%  - val_loss: 1720.1695556641 - val_trvae_loss: 1720.1695556641 |████----------------| 23.0%  - val_loss: 1719.4499511719 - val_trvae_loss: 1719.4499511719 |████----------------| 24.0%  - val_loss: 1719.1726074219 - val_trvae_loss: 1719.1726074219 |█████---------------| 25.0%  - val_loss: 1718.0454101562 - val_trvae_loss: 1718.0454101562 |█████---------------| 26.0%  - val_loss: 1717.2396240234 - val_trvae_loss: 1717.2396240234 |█████---------------| 27.0%  - val_loss: 1717.1287841797 - val_trvae_loss: 1717.1287841797 |█████---------------| 28.0%  - val_loss: 1716.7125244141 - val_trvae_loss: 1716.7125244141 |█████---------------| 29.0%  - val_loss: 1715.7656250000 - val_trvae_loss: 1715.7656250000 |██████--------------| 30.0%  - val_loss: 1715.2274169922 - val_trvae_loss: 1715.2274169922 |██████--------------| 31.0%  - val_loss: 1714.7084960938 - val_trvae_loss: 1714.7084960938 |██████--------------| 32.0%  - val_loss: 1713.9605712891 - val_trvae_loss: 1713.9605712891 |██████--------------| 33.0%  - val_loss: 1713.4117431641 - val_trvae_loss: 1713.4117431641 |██████--------------| 34.0%  - val_loss: 1712.4227294922 - val_trvae_loss: 1712.4227294922 |███████-------------| 35.0%  - val_loss: 1712.3785400391 - val_trvae_loss: 1712.3785400391 |███████-------------| 36.0%  - val_loss: 1711.5705566406 - val_trvae_loss: 1711.5705566406 |███████-------------| 37.0%  - val_loss: 1711.2716064453 - val_trvae_loss: 1711.2716064453 |███████-------------| 38.0%  - val_loss: 1710.6136474609 - val_trvae_loss: 1710.6136474609 |███████-------------| 39.0%  - val_loss: 1710.0424804688 - val_trvae_loss: 1710.0424804688 |████████------------| 40.0%  - val_loss: 1709.3598632812 - val_trvae_loss: 1709.3598632812 |████████------------| 41.0%  - val_loss: 1708.8591308594 - val_trvae_loss: 1708.8591308594 |████████------------| 42.0%  - val_loss: 1708.0783691406 - val_trvae_loss: 1708.0783691406 |████████------------| 43.0%  - val_loss: 1707.6125488281 - val_trvae_loss: 1707.6125488281 |████████------------| 44.0%  - val_loss: 1707.2408447266 - val_trvae_loss: 1707.2408447266 |█████████-----------| 45.0%  - val_loss: 1706.6997070312 - val_trvae_loss: 1706.6997070312 |█████████-----------| 46.0%  - val_loss: 1706.0169677734 - val_trvae_loss: 1706.0169677734 |█████████-----------| 47.0%  - val_loss: 1705.5260009766 - val_trvae_loss: 1705.5260009766 |█████████-----------| 48.0%  - val_loss: 1705.0054931641 - val_trvae_loss: 1705.0054931641 |█████████-----------| 49.0%  - val_loss: 1704.6710205078 - val_trvae_loss: 1704.6710205078 |██████████----------| 50.0%  - val_loss: 1703.9084472656 - val_trvae_loss: 1703.9084472656 |██████████----------| 51.0%  - val_loss: 1703.6774902344 - val_trvae_loss: 1703.6774902344 |██████████----------| 52.0%  - val_loss: 1702.7888183594 - val_trvae_loss: 1702.7888183594 |██████████----------| 53.0%  - val_loss: 1702.6097412109 - val_trvae_loss: 1702.6097412109 |██████████----------| 54.0%  - val_loss: 1702.1689453125 - val_trvae_loss: 1702.1689453125 |███████████---------| 55.0%  - val_loss: 1702.0800781250 - val_trvae_loss: 1702.0800781250 |███████████---------| 56.0%  - val_loss: 1701.1213378906 - val_trvae_loss: 1701.1213378906 |███████████---------| 57.0%  - val_loss: 1700.5616455078 - val_trvae_loss: 1700.5616455078 |███████████---------| 58.0%  - val_loss: 1699.9259033203 - val_trvae_loss: 1699.9259033203 |███████████---------| 59.0%  - val_loss: 1699.1904296875 - val_trvae_loss: 1699.1904296875 |████████████--------| 60.0%  - val_loss: 1699.5566406250 - val_trvae_loss: 1699.5566406250 |████████████--------| 61.0%  - val_loss: 1698.4449462891 - val_trvae_loss: 1698.4449462891 |████████████--------| 62.0%  - val_loss: 1698.1572265625 - val_trvae_loss: 1698.1572265625 |████████████--------| 63.0%  - val_loss: 1697.9549560547 - val_trvae_loss: 1697.9549560547 |████████████--------| 64.0%  - val_loss: 1697.3886718750 - val_trvae_loss: 1697.3886718750 |█████████████-------| 65.0%  - val_loss: 1696.6566162109 - val_trvae_loss: 1696.6566162109 |█████████████-------| 66.0%  - val_loss: 1696.7614746094 - val_trvae_loss: 1696.7614746094 |█████████████-------| 67.0%  - val_loss: 1695.8492431641 - val_trvae_loss: 1695.8492431641 |█████████████-------| 68.0%  - val_loss: 1695.5423583984 - val_trvae_loss: 1695.5423583984 |█████████████-------| 69.0%  - val_loss: 1695.1854248047 - val_trvae_loss: 1695.1854248047 |██████████████------| 70.0%  - val_loss: 1694.5661621094 - val_trvae_loss: 1694.5661621094 |██████████████------| 71.0%  - val_loss: 1694.7319335938 - val_trvae_loss: 1694.7319335938 |██████████████------| 72.0%  - val_loss: 1694.2863769531 - val_trvae_loss: 1694.2863769531 |██████████████------| 73.0%  - val_loss: 1693.5026855469 - val_trvae_loss: 1693.5026855469 |██████████████------| 74.0%  - val_loss: 1693.4355468750 - val_trvae_loss: 1693.4355468750 |███████████████-----| 75.0%  - val_loss: 1693.0610351562 - val_trvae_loss: 1693.0610351562 |███████████████-----| 76.0%  - val_loss: 1692.5216064453 - val_trvae_loss: 1692.5216064453 |███████████████-----| 77.0%  - val_loss: 1692.0773925781 - val_trvae_loss: 1692.0773925781 |███████████████-----| 78.0%  - val_loss: 1691.9362792969 - val_trvae_loss: 1691.9362792969 |███████████████-----| 79.0%  - val_loss: 1691.2049560547 - val_trvae_loss: 1691.2049560547 |████████████████----| 80.0%  - val_loss: 1690.7205810547 - val_trvae_loss: 1690.7205810547
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 12 clusters.
 |████████████████----| 81.0%  - val_loss: 1689.9991455078 - val_trvae_loss: 1689.9985351562 - val_landmark_loss: 0.0005920774 - val_unlabeled_loss: 0.5920773745 |████████████████----| 82.0%  - val_loss: 1689.8492431641 - val_trvae_loss: 1689.8486328125 - val_landmark_loss: 0.0005889013 - val_unlabeled_loss: 0.5889013410 |████████████████----| 83.0%  - val_loss: 1689.8016357422 - val_trvae_loss: 1689.8010253906 - val_landmark_loss: 0.0005929323 - val_unlabeled_loss: 0.5929322243 |████████████████----| 84.0%  - val_loss: 1688.9926757812 - val_trvae_loss: 1688.9920654297 - val_landmark_loss: 0.0005911199 - val_unlabeled_loss: 0.5911198854 |█████████████████---| 85.0%  - val_loss: 1689.1596679688 - val_trvae_loss: 1689.1590576172 - val_landmark_loss: 0.0005975807 - val_unlabeled_loss: 0.5975807309 |█████████████████---| 86.0%  - val_loss: 1688.1511230469 - val_trvae_loss: 1688.1505126953 - val_landmark_loss: 0.0005921749 - val_unlabeled_loss: 0.5921748281 |█████████████████---| 87.0%  - val_loss: 1688.3731689453 - val_trvae_loss: 1688.3725585938 - val_landmark_loss: 0.0005903447 - val_unlabeled_loss: 0.5903446674 |█████████████████---| 88.0%  - val_loss: 1687.8090820312 - val_trvae_loss: 1687.8084716797 - val_landmark_loss: 0.0005881424 - val_unlabeled_loss: 0.5881423950 |█████████████████---| 89.0%  - val_loss: 1687.3275146484 - val_trvae_loss: 1687.3269042969 - val_landmark_loss: 0.0005910039 - val_unlabeled_loss: 0.5910038948 |██████████████████--| 90.0%  - val_loss: 1687.2515869141 - val_trvae_loss: 1687.2509765625 - val_landmark_loss: 0.0005894864 - val_unlabeled_loss: 0.5894863605 |██████████████████--| 91.0%  - val_loss: 1686.7082519531 - val_trvae_loss: 1686.7076416016 - val_landmark_loss: 0.0005906397 - val_unlabeled_loss: 0.5906397104 |██████████████████--| 92.0%  - val_loss: 1685.8946533203 - val_trvae_loss: 1685.8940429688 - val_landmark_loss: 0.0005900072 - val_unlabeled_loss: 0.5900071859 |██████████████████--| 93.0%  - val_loss: 1686.0300292969 - val_trvae_loss: 1686.0294189453 - val_landmark_loss: 0.0005861034 - val_unlabeled_loss: 0.5861033201 |██████████████████--| 94.0%  - val_loss: 1685.4843750000 - val_trvae_loss: 1685.4837646484 - val_landmark_loss: 0.0005892980 - val_unlabeled_loss: 0.5892979503 |███████████████████-| 95.0%  - val_loss: 1685.4073486328 - val_trvae_loss: 1685.4067382812 - val_landmark_loss: 0.0005883196 - val_unlabeled_loss: 0.5883195996 |███████████████████-| 96.0%  - val_loss: 1684.7902832031 - val_trvae_loss: 1684.7896728516 - val_landmark_loss: 0.0005912012 - val_unlabeled_loss: 0.5912011862 |███████████████████-| 97.0%  - val_loss: 1684.3885498047 - val_trvae_loss: 1684.3879394531 - val_landmark_loss: 0.0005909390 - val_unlabeled_loss: 0.5909389257 |███████████████████-| 98.0%  - val_loss: 1683.7878417969 - val_trvae_loss: 1683.7872314453 - val_landmark_loss: 0.0005949692 - val_unlabeled_loss: 0.5949691534 |███████████████████-| 99.0%  - val_loss: 1683.5400390625 - val_trvae_loss: 1683.5394287109 - val_landmark_loss: 0.0005899242 - val_unlabeled_loss: 0.5899241567 |████████████████████| 100.0%  - val_loss: 1683.1314697266 - val_trvae_loss: 1683.1308593750 - val_landmark_loss: 0.0005899725 - val_unlabeled_loss: 0.5899724364
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 10:59:57 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 10:59:57 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
slurmstepd: error: *** JOB 3781271 ON gpusrv11 CANCELLED AT 2021-10-26T11:01:37 ***
