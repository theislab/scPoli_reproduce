Starting job 3783373
SLURM assigned me the node(s): gpusrv16
Experiments are running under the following process IDs:
Experiment ID: 10	Process ID: 42238

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 16:14:44 (INFO): Running command 'run'
2021-10-26 16:14:44 (INFO): Started run with ID "10"
2021-10-26 16:14:44 (INFO): Data loaded succesfully
2021-10-26 16:14:44 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1146.0162784352 - val_trvae_loss: 1146.0162784352 |--------------------| 2.0%  - val_loss: 1112.9468994141 - val_trvae_loss: 1112.9468994141 |--------------------| 3.0%  - val_loss: 1097.0189137178 - val_trvae_loss: 1097.0189137178 |--------------------| 4.0%  - val_loss: 1089.5786420037 - val_trvae_loss: 1089.5786420037 |█-------------------| 5.0%  - val_loss: 1083.1176075655 - val_trvae_loss: 1083.1176075655 |█-------------------| 6.0%  - val_loss: 1079.1110337201 - val_trvae_loss: 1079.1110337201 |█-------------------| 7.0%  - val_loss: 1076.4331413718 - val_trvae_loss: 1076.4331413718 |█-------------------| 8.0%  - val_loss: 1072.0638463637 - val_trvae_loss: 1072.0638463637 |█-------------------| 9.0%  - val_loss: 1069.4735825483 - val_trvae_loss: 1069.4735825483 |██------------------| 10.0%  - val_loss: 1068.1251687443 - val_trvae_loss: 1068.1251687443 |██------------------| 11.0%  - val_loss: 1066.0137867647 - val_trvae_loss: 1066.0137867647 |██------------------| 12.0%  - val_loss: 1064.8924452838 - val_trvae_loss: 1064.8924452838 |██------------------| 13.0%  - val_loss: 1063.1765459846 - val_trvae_loss: 1063.1765459846 |██------------------| 14.0%  - val_loss: 1061.5353752585 - val_trvae_loss: 1061.5353752585 |███-----------------| 15.0%  - val_loss: 1060.9171501608 - val_trvae_loss: 1060.9171501608 |███-----------------| 16.0%  - val_loss: 1059.9122386259 - val_trvae_loss: 1059.9122386259 |███-----------------| 17.0%  - val_loss: 1059.4549704159 - val_trvae_loss: 1059.4549704159 |███-----------------| 18.0%  - val_loss: 1058.9795173196 - val_trvae_loss: 1058.9795173196 |███-----------------| 19.0%  - val_loss: 1058.5903068991 - val_trvae_loss: 1058.5903068991 |████----------------| 20.0%  - val_loss: 1058.5261266372 - val_trvae_loss: 1058.5261266372 |████----------------| 21.0%  - val_loss: 1058.4123930090 - val_trvae_loss: 1058.4123930090 |████----------------| 22.0%  - val_loss: 1057.8995935777 - val_trvae_loss: 1057.8995935777 |████----------------| 23.0%  - val_loss: 1057.8918492934 - val_trvae_loss: 1057.8918492934 |████----------------| 24.0%  - val_loss: 1057.2346981273 - val_trvae_loss: 1057.2346981273 |█████---------------| 25.0%  - val_loss: 1056.8921401080 - val_trvae_loss: 1056.8921401080 |█████---------------| 26.0%  - val_loss: 1056.3533612420 - val_trvae_loss: 1056.3533612420 |█████---------------| 27.0%  - val_loss: 1055.7211231905 - val_trvae_loss: 1055.7211231905 |█████---------------| 28.0%  - val_loss: 1055.1907779469 - val_trvae_loss: 1055.1907779469 |█████---------------| 29.0%  - val_loss: 1055.1869076000 - val_trvae_loss: 1055.1869076000 |██████--------------| 30.0%  - val_loss: 1055.6864013672 - val_trvae_loss: 1055.6864013672 |██████--------------| 31.0%  - val_loss: 1054.7403025908 - val_trvae_loss: 1054.7403025908 |██████--------------| 32.0%  - val_loss: 1056.5582778033 - val_trvae_loss: 1056.5582778033 |██████--------------| 33.0%  - val_loss: 1054.8069709329 - val_trvae_loss: 1054.8069709329 |██████--------------| 34.0%  - val_loss: 1054.2493070715 - val_trvae_loss: 1054.2493070715 |███████-------------| 35.0%  - val_loss: 1054.6380112592 - val_trvae_loss: 1054.6380112592 |███████-------------| 36.0%  - val_loss: 1054.5078053194 - val_trvae_loss: 1054.5078053194 |███████-------------| 37.0%  - val_loss: 1056.5495210535 - val_trvae_loss: 1056.5495210535 |███████-------------| 38.0%  - val_loss: 1059.9145866843 - val_trvae_loss: 1059.9145866843 |███████-------------| 39.0%  - val_loss: 1054.6530366785 - val_trvae_loss: 1054.6530366785 |████████------------| 40.0%  - val_loss: 1053.8932566923 - val_trvae_loss: 1053.8932566923 |████████------------| 41.0%  - val_loss: 1053.4243451287 - val_trvae_loss: 1053.4243451287 |████████------------| 42.0%  - val_loss: 1053.5964283663 - val_trvae_loss: 1053.5964283663 |████████------------| 43.0%  - val_loss: 1053.9450791303 - val_trvae_loss: 1053.9450791303 |████████------------| 44.0%  - val_loss: 1053.9672995175 - val_trvae_loss: 1053.9672995175 |█████████-----------| 45.0%  - val_loss: 1053.4430865119 - val_trvae_loss: 1053.4430865119 |█████████-----------| 46.0%  - val_loss: 1053.7088192210 - val_trvae_loss: 1053.7088192210 |█████████-----------| 47.0%  - val_loss: 1056.5686968635 - val_trvae_loss: 1056.5686968635 |█████████-----------| 48.0%  - val_loss: 1053.9623377183 - val_trvae_loss: 1053.9623377183 |█████████-----------| 49.0%  - val_loss: 1053.4095961627 - val_trvae_loss: 1053.4095961627 |██████████----------| 50.0%  - val_loss: 1055.1551046932 - val_trvae_loss: 1055.1551046932 |██████████----------| 51.0%  - val_loss: 1053.4379918716 - val_trvae_loss: 1053.4379918716 |██████████----------| 52.0%  - val_loss: 1052.9461705825 - val_trvae_loss: 1052.9461705825 |██████████----------| 53.0%  - val_loss: 1054.8288394704 - val_trvae_loss: 1054.8288394704 |██████████----------| 54.0%  - val_loss: 1054.1013470818 - val_trvae_loss: 1054.1013470818 |███████████---------| 55.0%  - val_loss: 1053.6742194681 - val_trvae_loss: 1053.6742194681 |███████████---------| 56.0%  - val_loss: 1052.9284524357 - val_trvae_loss: 1052.9284524357 |███████████---------| 57.0%  - val_loss: 1053.4048605526 - val_trvae_loss: 1053.4048605526 |███████████---------| 58.0%  - val_loss: 1054.1428079044 - val_trvae_loss: 1054.1428079044 |███████████---------| 59.0%  - val_loss: 1053.4210851333 - val_trvae_loss: 1053.4210851333 |████████████--------| 60.0%  - val_loss: 1052.2109015970 - val_trvae_loss: 1052.2109015970 |████████████--------| 61.0%  - val_loss: 1052.7134040384 - val_trvae_loss: 1052.7134040384 |████████████--------| 62.0%  - val_loss: 1054.4461885340 - val_trvae_loss: 1054.4461885340 |████████████--------| 63.0%  - val_loss: 1053.5118192785 - val_trvae_loss: 1053.5118192785 |████████████--------| 64.0%  - val_loss: 1052.7610042796 - val_trvae_loss: 1052.7610042796 |█████████████-------| 65.0%  - val_loss: 1052.9800056009 - val_trvae_loss: 1052.9800056009 |█████████████-------| 66.0%  - val_loss: 1052.5176966050 - val_trvae_loss: 1052.5176966050 |█████████████-------| 67.0%  - val_loss: 1052.6430340935 - val_trvae_loss: 1052.6430340935 |█████████████-------| 68.0%  - val_loss: 1052.1842292337 - val_trvae_loss: 1052.1842292337 |█████████████-------| 69.0%  - val_loss: 1053.0045417337 - val_trvae_loss: 1053.0045417337 |██████████████------| 70.0%  - val_loss: 1052.6916216682 - val_trvae_loss: 1052.6916216682 |██████████████------| 71.0%  - val_loss: 1052.2484310375 - val_trvae_loss: 1052.2484310375 |██████████████------| 72.0%  - val_loss: 1052.8367130055 - val_trvae_loss: 1052.8367130055 |██████████████------| 73.0%  - val_loss: 1052.5873987534 - val_trvae_loss: 1052.5873987534 |██████████████------| 74.0%  - val_loss: 1053.5222562902 - val_trvae_loss: 1053.5222562902 |███████████████-----| 75.0%  - val_loss: 1052.2114975873 - val_trvae_loss: 1052.2114975873 |███████████████-----| 76.0%  - val_loss: 1052.0158116958 - val_trvae_loss: 1052.0158116958 |███████████████-----| 77.0%  - val_loss: 1052.3401094324 - val_trvae_loss: 1052.3401094324 |███████████████-----| 78.0%  - val_loss: 1053.4665922277 - val_trvae_loss: 1053.4665922277 |███████████████-----| 79.0%  - val_loss: 1052.3960284065 - val_trvae_loss: 1052.3960284065 |████████████████----| 80.0%  - val_loss: 1051.8000380572 - val_trvae_loss: 1051.8000380572 |████████████████----| 81.0%  - val_loss: 1074.8820298139 - val_trvae_loss: 1058.7075626149 - val_landmark_loss: 16.1744553061 - val_labeled_loss: 16.1744553061 |████████████████----| 82.0%  - val_loss: 1071.0300400678 - val_trvae_loss: 1058.0333610983 - val_landmark_loss: 12.9966758840 - val_labeled_loss: 12.9966758840 |████████████████----| 83.0%  - val_loss: 1067.0195132985 - val_trvae_loss: 1057.0347972197 - val_landmark_loss: 9.9847124605 - val_labeled_loss: 9.9847124605 |████████████████----| 84.0%  - val_loss: 1066.1511876723 - val_trvae_loss: 1056.2703318876 - val_landmark_loss: 9.8808626287 - val_labeled_loss: 9.8808626287 |█████████████████---| 85.0%  - val_loss: 1064.7247099035 - val_trvae_loss: 1056.0308335248 - val_landmark_loss: 8.6938908521 - val_labeled_loss: 8.6938908521 |█████████████████---| 86.0%  - val_loss: 1063.9304306928 - val_trvae_loss: 1055.8707778033 - val_landmark_loss: 8.0596408283 - val_labeled_loss: 8.0596408283 |█████████████████---| 87.0%  - val_loss: 1063.1838522518 - val_trvae_loss: 1056.7025613224 - val_landmark_loss: 6.4813040986 - val_labeled_loss: 6.4813040986 |█████████████████---| 88.0%  - val_loss: 1062.5740715476 - val_trvae_loss: 1055.5495102826 - val_landmark_loss: 7.0245646729 - val_labeled_loss: 7.0245646729 |█████████████████---| 89.0%  - val_loss: 1062.0853917739 - val_trvae_loss: 1056.0820348403 - val_landmark_loss: 6.0033647032 - val_labeled_loss: 6.0033647032 |██████████████████--| 90.0%  - val_loss: 1061.6190185547 - val_trvae_loss: 1054.7686336742 - val_landmark_loss: 6.8503866196 - val_labeled_loss: 6.8503866196 |██████████████████--| 91.0%  - val_loss: 1061.8815343520 - val_trvae_loss: 1055.8885928883 - val_landmark_loss: 5.9929309873 - val_labeled_loss: 5.9929309873 |██████████████████--| 92.0%  - val_loss: 1059.9415103688 - val_trvae_loss: 1055.0291460823 - val_landmark_loss: 4.9123654155 - val_labeled_loss: 4.9123654155 |██████████████████--| 93.0%  - val_loss: 1060.4221119600 - val_trvae_loss: 1055.4119944853 - val_landmark_loss: 5.0101210650 - val_labeled_loss: 5.0101210650 |██████████████████--| 94.0%  - val_loss: 1059.5412238626 - val_trvae_loss: 1054.6997034409 - val_landmark_loss: 4.8415152045 - val_labeled_loss: 4.8415152045 |███████████████████-| 95.0%  - val_loss: 1058.4029541016 - val_trvae_loss: 1054.0753891889 - val_landmark_loss: 4.3275708381 - val_labeled_loss: 4.3275708381 |███████████████████-| 96.0%  - val_loss: 1058.9505292107 - val_trvae_loss: 1054.4673569623 - val_landmark_loss: 4.4831673959 - val_labeled_loss: 4.4831673959 |███████████████████-| 97.0%  - val_loss: 1058.2564302332 - val_trvae_loss: 1053.6875430836 - val_landmark_loss: 4.5688838608 - val_labeled_loss: 4.5688838608 |███████████████████-| 98.0%  - val_loss: 1059.6749482996 - val_trvae_loss: 1056.0328728171 - val_landmark_loss: 3.6420663455 - val_labeled_loss: 3.6420663455 |███████████████████-| 99.0%  - val_loss: 1065.1252118279 - val_trvae_loss: 1061.1704029756 - val_landmark_loss: 3.9548009143 - val_labeled_loss: 3.9548009143 |████████████████████| 100.0%  - val_loss: 1058.9520730411 - val_trvae_loss: 1054.7979987649 - val_landmark_loss: 4.1540737222 - val_labeled_loss: 4.1540737222
2021-10-26 16:17:43 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 97
AnnData object with n_obs × n_vars = 10727 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1976.9877387153 - val_trvae_loss: 1976.9877387153 |--------------------| 2.0%  - val_loss: 1973.2155626085 - val_trvae_loss: 1973.2155626085 |--------------------| 3.0%  - val_loss: 1971.9074435764 - val_trvae_loss: 1971.9074435764 |--------------------| 4.0%  - val_loss: 1971.8101942274 - val_trvae_loss: 1971.8101942274 |█-------------------| 5.0%  - val_loss: 1963.7240939670 - val_trvae_loss: 1963.7240939670 |█-------------------| 6.0%  - val_loss: 1949.9159206814 - val_trvae_loss: 1949.9159206814 |█-------------------| 7.0%  - val_loss: 1956.9097086589 - val_trvae_loss: 1956.9097086589 |█-------------------| 8.0%  - val_loss: 1939.5575358073 - val_trvae_loss: 1939.5575358073 |█-------------------| 9.0%  - val_loss: 1955.3331434462 - val_trvae_loss: 1955.3331434462 |██------------------| 10.0%  - val_loss: 1939.5022650825 - val_trvae_loss: 1939.5022650825 |██------------------| 11.0%  - val_loss: 1930.5739746094 - val_trvae_loss: 1930.5739746094 |██------------------| 12.0%  - val_loss: 1933.6500515408 - val_trvae_loss: 1933.6500515408 |██------------------| 13.0%  - val_loss: 1941.7247992622 - val_trvae_loss: 1941.7247992622 |██------------------| 14.0%  - val_loss: 1928.8281656901 - val_trvae_loss: 1928.8281656901 |███-----------------| 15.0%  - val_loss: 1942.8152398003 - val_trvae_loss: 1942.8152398003 |███-----------------| 16.0%  - val_loss: 1931.3102620443 - val_trvae_loss: 1931.3102620443 |███-----------------| 17.0%  - val_loss: 1942.2898763021 - val_trvae_loss: 1942.2898763021 |███-----------------| 18.0%  - val_loss: 1927.8100179036 - val_trvae_loss: 1927.8100179036 |███-----------------| 19.0%  - val_loss: 1928.7711859809 - val_trvae_loss: 1928.7711859809 |████----------------| 20.0%  - val_loss: 1924.2088351780 - val_trvae_loss: 1924.2088351780 |████----------------| 21.0%  - val_loss: 1924.8842909071 - val_trvae_loss: 1924.8842909071 |████----------------| 22.0%  - val_loss: 1915.0733506944 - val_trvae_loss: 1915.0733506944 |████----------------| 23.0%  - val_loss: 1925.9446072049 - val_trvae_loss: 1925.9446072049 |████----------------| 24.0%  - val_loss: 1915.5144992405 - val_trvae_loss: 1915.5144992405 |█████---------------| 25.0%  - val_loss: 1915.4073486328 - val_trvae_loss: 1915.4073486328 |█████---------------| 26.0%  - val_loss: 1912.4633246528 - val_trvae_loss: 1912.4633246528 |█████---------------| 27.0%  - val_loss: 1910.7843288845 - val_trvae_loss: 1910.7843288845 |█████---------------| 28.0%  - val_loss: 1910.9922417535 - val_trvae_loss: 1910.9922417535 |█████---------------| 29.0%  - val_loss: 1923.5322401259 - val_trvae_loss: 1923.5322401259 |██████--------------| 30.0%  - val_loss: 1921.8911810981 - val_trvae_loss: 1921.8911810981 |██████--------------| 31.0%  - val_loss: 1926.7280544705 - val_trvae_loss: 1926.7280544705 |██████--------------| 32.0%  - val_loss: 1915.2985432943 - val_trvae_loss: 1915.2985432943 |██████--------------| 33.0%  - val_loss: 1925.3642713759 - val_trvae_loss: 1925.3642713759 |██████--------------| 34.0%  - val_loss: 1925.5027126736 - val_trvae_loss: 1925.5027126736 |███████-------------| 35.0%  - val_loss: 1908.9362792969 - val_trvae_loss: 1908.9362792969 |███████-------------| 36.0%  - val_loss: 1906.4959716797 - val_trvae_loss: 1906.4959716797 |███████-------------| 37.0%  - val_loss: 1925.9194471571 - val_trvae_loss: 1925.9194471571 |███████-------------| 38.0%  - val_loss: 1917.0545111762 - val_trvae_loss: 1917.0545111762 |███████-------------| 39.0%  - val_loss: 1908.4094916450 - val_trvae_loss: 1908.4094916450 |████████------------| 40.0%  - val_loss: 1897.7639567057 - val_trvae_loss: 1897.7639567057 |████████------------| 41.0%  - val_loss: 1908.7277967665 - val_trvae_loss: 1908.7277967665 |████████------------| 42.0%  - val_loss: 1903.6206868490 - val_trvae_loss: 1903.6206868490 |████████------------| 43.0%  - val_loss: 1913.1211344401 - val_trvae_loss: 1913.1211344401 |████████------------| 44.0%  - val_loss: 1911.4590657552 - val_trvae_loss: 1911.4590657552 |█████████-----------| 45.0%  - val_loss: 1916.5008273655 - val_trvae_loss: 1916.5008273655 |█████████-----------| 46.0%  - val_loss: 1905.2434082031 - val_trvae_loss: 1905.2434082031 |█████████-----------| 47.0%  - val_loss: 1907.3570827908 - val_trvae_loss: 1907.3570827908 |█████████-----------| 48.0%  - val_loss: 1905.6233995226 - val_trvae_loss: 1905.6233995226 |█████████-----------| 49.0%  - val_loss: 1900.5465087891 - val_trvae_loss: 1900.5465087891 |██████████----------| 50.0%  - val_loss: 1900.0926649306 - val_trvae_loss: 1900.0926649306 |██████████----------| 51.0%  - val_loss: 1911.2813313802 - val_trvae_loss: 1911.2813313802 |██████████----------| 52.0%  - val_loss: 1900.4555257161 - val_trvae_loss: 1900.4555257161 |██████████----------| 53.0%  - val_loss: 1915.4391140408 - val_trvae_loss: 1915.4391140408 |██████████----------| 54.0%  - val_loss: 1915.9000379774 - val_trvae_loss: 1915.9000379774 |███████████---------| 55.0%  - val_loss: 1908.5772162543 - val_trvae_loss: 1908.5772162543 |███████████---------| 56.0%  - val_loss: 1907.2970106337 - val_trvae_loss: 1907.2970106337 |███████████---------| 57.0%  - val_loss: 1898.3007541233 - val_trvae_loss: 1898.3007541233 |███████████---------| 58.0%  - val_loss: 1912.0484212240 - val_trvae_loss: 1912.0484212240 |███████████---------| 59.0%  - val_loss: 1906.8661159939 - val_trvae_loss: 1906.8661159939 |████████████--------| 60.0%  - val_loss: 1910.4834798177 - val_trvae_loss: 1910.4834798177 |████████████--------| 61.0%  - val_loss: 1906.1182725694 - val_trvae_loss: 1906.1182725694 |████████████--------| 62.0%  - val_loss: 1898.4312879774 - val_trvae_loss: 1898.4312879774 |████████████--------| 63.0%  - val_loss: 1900.5641140408 - val_trvae_loss: 1900.5641140408 |████████████--------| 64.0%  - val_loss: 1897.2744004991 - val_trvae_loss: 1897.2744004991 |█████████████-------| 65.0%  - val_loss: 1902.0883653429 - val_trvae_loss: 1902.0883653429 |█████████████-------| 66.0%  - val_loss: 1902.2255723741 - val_trvae_loss: 1902.2255723741 |█████████████-------| 67.0%  - val_loss: 1912.7098659939 - val_trvae_loss: 1912.7098659939 |█████████████-------| 68.0%  - val_loss: 1890.6424696181 - val_trvae_loss: 1890.6424696181 |█████████████-------| 69.0%  - val_loss: 1906.8934461806 - val_trvae_loss: 1906.8934461806 |██████████████------| 70.0%  - val_loss: 1903.8481852214 - val_trvae_loss: 1903.8481852214 |██████████████------| 71.0%  - val_loss: 1908.9043240017 - val_trvae_loss: 1908.9043240017 |██████████████------| 72.0%  - val_loss: 1922.2229953342 - val_trvae_loss: 1922.2229953342 |██████████████------| 73.0%  - val_loss: 1918.4559054905 - val_trvae_loss: 1918.4559054905 |██████████████------| 74.0%  - val_loss: 1901.8552246094 - val_trvae_loss: 1901.8552246094 |███████████████-----| 75.0%  - val_loss: 1902.0859781901 - val_trvae_loss: 1902.0859781901 |███████████████-----| 76.0%  - val_loss: 1922.6029866536 - val_trvae_loss: 1922.6029866536 |███████████████-----| 77.0%  - val_loss: 1907.9811604818 - val_trvae_loss: 1907.9811604818 |███████████████-----| 78.0%  - val_loss: 1898.0656873915 - val_trvae_loss: 1898.0656873915 |███████████████-----| 79.0%  - val_loss: 1916.8386637370 - val_trvae_loss: 1916.8386637370 |████████████████----| 80.0%  - val_loss: 1907.7410753038 - val_trvae_loss: 1907.7410753038
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 20 clusters.
 |████████████████----| 81.0%  - val_loss: 1916.9718288845 - val_trvae_loss: 1916.9716932509 - val_landmark_loss: 0.0001370150 - val_unlabeled_loss: 0.1370149520 |████████████████----| 82.0%  - val_loss: 1906.4158393012 - val_trvae_loss: 1906.4157036675 - val_landmark_loss: 0.0001309287 - val_unlabeled_loss: 0.1309287254 |████████████████----| 83.0%  - val_loss: 1904.0254448785 - val_trvae_loss: 1904.0252956814 - val_landmark_loss: 0.0001457923 - val_unlabeled_loss: 0.1457922475 |████████████████----| 84.0%  - val_loss: 1900.0372856988 - val_trvae_loss: 1900.0371229384 - val_landmark_loss: 0.0001476904 - val_unlabeled_loss: 0.1476904030 |█████████████████---| 85.0%  - val_loss: 1895.7937961155 - val_trvae_loss: 1895.7936333550 - val_landmark_loss: 0.0001595173 - val_unlabeled_loss: 0.1595172965 |█████████████████---| 86.0%  - val_loss: 1902.3226318359 - val_trvae_loss: 1902.3224690755 - val_landmark_loss: 0.0001419201 - val_unlabeled_loss: 0.1419200848 |█████████████████---| 87.0%  - val_loss: 1913.8782687717 - val_trvae_loss: 1913.8781467014 - val_landmark_loss: 0.0001382781 - val_unlabeled_loss: 0.1382781060 |█████████████████---| 88.0%  - val_loss: 1901.5150960286 - val_trvae_loss: 1901.5149739583 - val_landmark_loss: 0.0001264524 - val_unlabeled_loss: 0.1264523495 |█████████████████---| 89.0%  - val_loss: 1916.0441080729 - val_trvae_loss: 1916.0439588759 - val_landmark_loss: 0.0001435743 - val_unlabeled_loss: 0.1435743148 |██████████████████--| 90.0%  - val_loss: 1916.0709092882 - val_trvae_loss: 1916.0707600911 - val_landmark_loss: 0.0001498546 - val_unlabeled_loss: 0.1498546277 |██████████████████--| 91.0%  - val_loss: 1895.9802788628 - val_trvae_loss: 1895.9801025391 - val_landmark_loss: 0.0001605336 - val_unlabeled_loss: 0.1605336037 |██████████████████--| 92.0%  - val_loss: 1898.4557427300 - val_trvae_loss: 1898.4555935330 - val_landmark_loss: 0.0001513877 - val_unlabeled_loss: 0.1513876576 |██████████████████--| 93.0%  - val_loss: 1894.6789686415 - val_trvae_loss: 1894.6788194444 - val_landmark_loss: 0.0001457216 - val_unlabeled_loss: 0.1457215614 |██████████████████--| 94.0%  - val_loss: 1909.7438557943 - val_trvae_loss: 1909.7436930339 - val_landmark_loss: 0.0001553790 - val_unlabeled_loss: 0.1553789692 |███████████████████-| 95.0%  - val_loss: 1913.9396837023 - val_trvae_loss: 1913.9395345052 - val_landmark_loss: 0.0001656956 - val_unlabeled_loss: 0.1656955688 |███████████████████-| 96.0%  - val_loss: 1921.3992241753 - val_trvae_loss: 1921.3990749783 - val_landmark_loss: 0.0001435477 - val_unlabeled_loss: 0.1435476508 |███████████████████-| 97.0%  - val_loss: 1904.8740234375 - val_trvae_loss: 1904.8738742405 - val_landmark_loss: 0.0001395501 - val_unlabeled_loss: 0.1395500708 |███████████████████-| 98.0%  - val_loss: 1914.1841362847 - val_trvae_loss: 1914.1839870877 - val_landmark_loss: 0.0001440468 - val_unlabeled_loss: 0.1440468149 |███████████████████-| 99.0%  - val_loss: 1907.2752685547 - val_trvae_loss: 1907.2751193576 - val_landmark_loss: 0.0001509582 - val_unlabeled_loss: 0.1509582276 |████████████████████| 100.0%  - val_loss: 1907.5340576172 - val_trvae_loss: 1907.5339219835 - val_landmark_loss: 0.0001496514 - val_unlabeled_loss: 0.1496514264
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 16:19:02 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 16:19:03 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2021-10-26 16:36:18 (INFO): Result: {'distances':   condition  cos_dist  eucl_dist
0    Oetjen  0.838549   0.847540
1       Sun  0.936533   0.705475
2   Freytag  1.177115   0.705475
3       10X  0.838549   2.914424, 'classification_report':                                   precision    recall  f1-score       support
CD10+ B cells                      0.980952  0.995169  0.988010    207.000000
CD14+ Monocytes                    0.988937  0.973178  0.980994   6338.000000
CD16+ Monocytes                    0.962919  0.975758  0.969296    825.000000
CD20+ B cells                      0.996849  0.990950  0.993891   2873.000000
CD4+ T cells                       0.991422  0.587776  0.738012  11011.000000
CD8+ T cells                       0.317200  0.981677  0.479472   2183.000000
Erythrocytes                       0.974882  0.826897  0.894813   1502.000000
Erythroid progenitors              0.542714  0.699784  0.611321    463.000000
HSPCs                              0.958246  0.970402  0.964286    473.000000
Megakaryocyte progenitors          0.652850  0.933333  0.768293    270.000000
Monocyte progenitors               0.749553  0.978972  0.849037    428.000000
Monocyte-derived dendritic cells   0.958621  0.872385  0.913472    478.000000
NK cells                           0.947237  0.829555  0.884499   2294.000000
NKT cells                          0.848805  0.906011  0.876476   2745.000000
Plasma cells                       0.968504  0.953488  0.960938    129.000000
Plasmacytoid dendritic cells       0.988679  0.988679  0.988679    265.000000
accuracy                           0.816679  0.816679  0.816679      0.816679
macro avg                          0.864273  0.904001  0.866343  32484.000000
weighted avg                       0.915905  0.816679  0.836155  32484.000000, 'classification_report_query':                                   precision    recall  f1-score       support
CD14+ Monocytes                    0.983539  0.987603  0.985567   3388.000000
CD16+ Monocytes                    0.920213  0.950549  0.935135    364.000000
CD20+ B cells                      0.996094  0.989651  0.992862   1546.000000
CD4+ T cells                       0.992561  0.636023  0.775265   2937.000000
CD8+ T cells                       0.228311  1.000000  0.371747    350.000000
Erythroid progenitors              0.000000  0.000000  0.000000      0.000000
HSPCs                              0.884615  0.821429  0.851852     28.000000
Megakaryocyte progenitors          0.525000  1.000000  0.688525     21.000000
Monocyte progenitors               0.000000  0.000000  0.000000      0.000000
Monocyte-derived dendritic cells   0.992806  0.758242  0.859813    182.000000
NK cells                           0.964467  0.753968  0.846325    756.000000
NKT cells                          0.817352  0.847538  0.832171   1056.000000
Plasma cells                       1.000000  0.666667  0.800000     18.000000
Plasmacytoid dendritic cells       1.000000  1.000000  1.000000     81.000000
accuracy                           0.855784  0.855784  0.855784      0.855784
macro avg                          0.736068  0.743691  0.709947  10727.000000
weighted avg                       0.942477  0.855784  0.879119  10727.000000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.865744            0.80121  ...                    0.55432    0.991887

[1 rows x 8 columns]}
2021-10-26 16:36:18 (INFO): Completed after 0:21:34
Saving best state of network...
Best State was in Epoch 87
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
