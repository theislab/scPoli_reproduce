Starting job 8135150
SLURM assigned me the node(s): gpusrv18
Experiments are running under the following process IDs:
Experiment ID: 19	Process ID: 27218

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2022-05-19 14:13:38 (INFO): Running command 'run'
2022-05-19 14:13:38 (INFO): Started run with ID "19"
2022-05-19 14:13:39 (INFO): Data loaded succesfully
2022-05-19 14:13:39 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

loaders init
loaders init done
0.9042673110961914
 |--------------------| 1.0%  - val_loss: 1457.6655644956 - val_trvae_loss: 1457.6655644956 |--------------------| 2.0%  - val_loss: 1416.0868397588 - val_trvae_loss: 1416.0868397588 |--------------------| 3.0%  - val_loss: 1396.9376645296 - val_trvae_loss: 1396.9376645296 |--------------------| 4.0%  - val_loss: 1388.8001762058 - val_trvae_loss: 1388.8001762058 |█-------------------| 5.0%  - val_loss: 1380.5735447096 - val_trvae_loss: 1380.5735447096 |█-------------------| 6.0%  - val_loss: 1374.6118535581 - val_trvae_loss: 1374.6118535581 |█-------------------| 7.0%  - val_loss: 1369.8957360309 - val_trvae_loss: 1369.8957360309 |█-------------------| 8.0%  - val_loss: 1364.3018639606 - val_trvae_loss: 1364.3018639606 |█-------------------| 9.0%  - val_loss: 1363.2231922979 - val_trvae_loss: 1363.2231922979 |██------------------| 10.0%  - val_loss: 1362.0776420262 - val_trvae_loss: 1362.0776420262 |██------------------| 11.0%  - val_loss: 1359.5013799253 - val_trvae_loss: 1359.5013799253 |██------------------| 12.0%  - val_loss: 1357.8469185207 - val_trvae_loss: 1357.8469185207 |██------------------| 13.0%  - val_loss: 1356.8340056046 - val_trvae_loss: 1356.8340056046 |██------------------| 14.0%  - val_loss: 1355.3386761209 - val_trvae_loss: 1355.3386761209 |███-----------------| 15.0%  - val_loss: 1354.3918722401 - val_trvae_loss: 1354.3918722401 |███-----------------| 16.0%  - val_loss: 1353.5578029467 - val_trvae_loss: 1353.5578029467 |███-----------------| 17.0%  - val_loss: 1354.2910580842 - val_trvae_loss: 1354.2910580842 |███-----------------| 18.0%  - val_loss: 1352.2218813689 - val_trvae_loss: 1352.2218813689 |███-----------------| 19.0%  - val_loss: 1352.0270836872 - val_trvae_loss: 1352.0270836872 |████----------------| 20.0%  - val_loss: 1352.3219471807 - val_trvae_loss: 1352.3219471807 |████----------------| 21.0%  - val_loss: 1352.2072223166 - val_trvae_loss: 1352.2072223166 |████----------------| 22.0%  - val_loss: 1351.3636686906 - val_trvae_loss: 1351.3636686906 |████----------------| 23.0%  - val_loss: 1350.3597624406 - val_trvae_loss: 1350.3597624406 |████----------------| 24.0%  - val_loss: 1349.7787926715 - val_trvae_loss: 1349.7787926715 |█████---------------| 25.0%  - val_loss: 1349.3892609969 - val_trvae_loss: 1349.3892609969 |█████---------------| 26.0%  - val_loss: 1350.2644520635 - val_trvae_loss: 1350.2644520635 |█████---------------| 27.0%  - val_loss: 1349.1971860139 - val_trvae_loss: 1349.1971860139 |█████---------------| 28.0%  - val_loss: 1350.5566883916 - val_trvae_loss: 1350.5566883916 |█████---------------| 29.0%  - val_loss: 1349.9715416950 - val_trvae_loss: 1349.9715416950 |██████--------------| 30.0%  - val_loss: 1349.4733886719 - val_trvae_loss: 1349.4733886719 |██████--------------| 31.0%  - val_loss: 1349.0178116508 - val_trvae_loss: 1349.0178116508 |██████--------------| 32.0%  - val_loss: 1348.0751157014 - val_trvae_loss: 1348.0751157014 |██████--------------| 33.0%  - val_loss: 1347.8144318954 - val_trvae_loss: 1347.8144318954 |██████--------------| 34.0%  - val_loss: 1348.8176110309 - val_trvae_loss: 1348.8176110309 |███████-------------| 35.0%  - val_loss: 1349.6014457371 - val_trvae_loss: 1349.6014457371 |███████-------------| 36.0%  - val_loss: 1347.7035230554 - val_trvae_loss: 1347.7035230554 |███████-------------| 37.0%  - val_loss: 1348.2139680282 - val_trvae_loss: 1348.2139680282 |███████-------------| 38.0%  - val_loss: 1347.0204494310 - val_trvae_loss: 1347.0204494310 |███████-------------| 39.0%  - val_loss: 1347.4432107677 - val_trvae_loss: 1347.4432107677 |████████------------| 40.0%  - val_loss: 1350.5661780316 - val_trvae_loss: 1350.5661780316 |████████------------| 41.0%  - val_loss: 1348.4290559188 - val_trvae_loss: 1348.4290559188 |████████------------| 42.0%  - val_loss: 1349.0632908033 - val_trvae_loss: 1349.0632908033 |████████------------| 43.0%  - val_loss: 1348.6101339589 - val_trvae_loss: 1348.6101339589 |████████------------| 44.0%  - val_loss: 1347.4959557575 - val_trvae_loss: 1347.4959557575 |█████████-----------| 45.0%  - val_loss: 1345.7827519956 - val_trvae_loss: 1345.7827519956 |█████████-----------| 46.0%  - val_loss: 1346.4093176800 - val_trvae_loss: 1346.4093176800 |█████████-----------| 47.0%  - val_loss: 1347.4566756539 - val_trvae_loss: 1347.4566756539 |█████████-----------| 48.0%  - val_loss: 1346.3155623726 - val_trvae_loss: 1346.3155623726 |█████████-----------| 49.0%  - val_loss: 1347.1154466712 - val_trvae_loss: 1347.1154466712 |██████████----------| 50.0%  - val_loss: 1347.2556948454 - val_trvae_loss: 1347.2556948454 |██████████----------| 51.0%  - val_loss: 1348.5013109290 - val_trvae_loss: 1348.5013109290 |██████████----------| 52.0%  - val_loss: 1348.2431959069 - val_trvae_loss: 1348.2431959069 |██████████----------| 53.0%  - val_loss: 1346.3889797045 - val_trvae_loss: 1346.3889797045 |██████████----------| 54.0%  - val_loss: 1347.1569983441 - val_trvae_loss: 1347.1569983441 |███████████---------| 55.0%  - val_loss: 1346.1567807405 - val_trvae_loss: 1346.1567807405 |███████████---------| 56.0%  - val_loss: 1346.7030772334 - val_trvae_loss: 1346.7030772334 |███████████---------| 57.0%  - val_loss: 1346.2814039147 - val_trvae_loss: 1346.2814039147 |███████████---------| 58.0%  - val_loss: 1345.7653330927 - val_trvae_loss: 1345.7653330927 |███████████---------| 59.0%  - val_loss: 1347.3026123047 - val_trvae_loss: 1347.3026123047 |████████████--------| 60.0%  - val_loss: 1346.4083517323 - val_trvae_loss: 1346.4083517323 |████████████--------| 61.0%  - val_loss: 1347.1474025560 - val_trvae_loss: 1347.1474025560 |████████████--------| 62.0%  - val_loss: 1346.2765423319 - val_trvae_loss: 1346.2765423319 |████████████--------| 63.0%  - val_loss: 1346.5656525985 - val_trvae_loss: 1346.5656525985 |████████████--------| 64.0%  - val_loss: 1347.8301152768 - val_trvae_loss: 1347.8301152768 |█████████████-------| 65.0%  - val_loss: 1345.7067181131 - val_trvae_loss: 1345.7067181131 |█████████████-------| 66.0%  - val_loss: 1345.7277142069 - val_trvae_loss: 1345.7277142069 |█████████████-------| 67.0%  - val_loss: 1345.8533776325 - val_trvae_loss: 1345.8533776325 |█████████████-------| 68.0%  - val_loss: 1345.0691661005 - val_trvae_loss: 1345.0691661005 |█████████████-------| 69.0%  - val_loss: 1347.2015487007 - val_trvae_loss: 1347.2015487007 |██████████████------| 70.0%  - val_loss: 1343.9311311141 - val_trvae_loss: 1343.9311311141 |██████████████------| 71.0%  - val_loss: 1345.5189208984 - val_trvae_loss: 1345.5189208984 |██████████████------| 72.0%  - val_loss: 1345.2199760105 - val_trvae_loss: 1345.2199760105 |██████████████------| 73.0%  - val_loss: 1346.1031228770 - val_trvae_loss: 1346.1031228770 |██████████████------| 74.0%  - val_loss: 1344.8771229620 - val_trvae_loss: 1344.8771229620 |███████████████-----| 75.0%  - val_loss: 1346.0072605299 - val_trvae_loss: 1346.0072605299 |███████████████-----| 76.0%  - val_loss: 1344.4976806641 - val_trvae_loss: 1344.4976806641 |███████████████-----| 77.0%  - val_loss: 1347.2740160071 - val_trvae_loss: 1347.2740160071 |███████████████-----| 78.0%  - val_loss: 1347.2924167799 - val_trvae_loss: 1347.2924167799 |███████████████-----| 79.0%  - val_loss: 1346.3263151749 - val_trvae_loss: 1346.3263151749 |████████████████----| 80.0%  - val_loss: 1344.3165495499 - val_trvae_loss: 1344.3165495499 |████████████████----| 81.0%  - val_loss: 1365.7855171535 - val_trvae_loss: 1353.2151728091 - val_landmark_loss: 12.5703438676 - val_labeled_loss: 12.5703438676 |████████████████----| 82.0%  - val_loss: 1361.0271792204 - val_trvae_loss: 1350.9643713910 - val_landmark_loss: 10.0627961573 - val_labeled_loss: 10.0627961573 |████████████████----| 83.0%  - val_loss: 1358.0177108101 - val_trvae_loss: 1349.4217529297 - val_landmark_loss: 8.5959569268 - val_labeled_loss: 8.5959569268 |████████████████----| 84.0%  - val_loss: 1356.5347369650 - val_trvae_loss: 1349.2530039912 - val_landmark_loss: 7.2817338653 - val_labeled_loss: 7.2817338653 |█████████████████---| 85.0%  - val_loss: 1354.2395284901 - val_trvae_loss: 1347.9200970194 - val_landmark_loss: 6.3194390069 - val_labeled_loss: 6.3194390069 |█████████████████---| 86.0%  - val_loss: 1355.3497420601 - val_trvae_loss: 1349.2264192001 - val_landmark_loss: 6.1233312876 - val_labeled_loss: 6.1233312876 |█████████████████---| 87.0%  - val_loss: 1353.3265752378 - val_trvae_loss: 1347.7629606827 - val_landmark_loss: 5.5636214484 - val_labeled_loss: 5.5636214484 |█████████████████---| 88.0%  - val_loss: 1353.5390147334 - val_trvae_loss: 1348.2863344939 - val_landmark_loss: 5.2526838157 - val_labeled_loss: 5.2526838157 |█████████████████---| 89.0%  - val_loss: 1353.9306481403 - val_trvae_loss: 1348.4395751953 - val_landmark_loss: 5.4910542550 - val_labeled_loss: 5.4910542550 |██████████████████--| 90.0%  - val_loss: 1354.6746136209 - val_trvae_loss: 1349.8994087551 - val_landmark_loss: 4.7752066695 - val_labeled_loss: 4.7752066695 |██████████████████--| 91.0%  - val_loss: 1349.7537470279 - val_trvae_loss: 1345.7008534307 - val_landmark_loss: 4.0528971164 - val_labeled_loss: 4.0528971164 |██████████████████--| 92.0%  - val_loss: 1351.6387461787 - val_trvae_loss: 1347.5622664742 - val_landmark_loss: 4.0764701366 - val_labeled_loss: 4.0764701366 |██████████████████--| 93.0%  - val_loss: 1350.8739544412 - val_trvae_loss: 1346.8047034222 - val_landmark_loss: 4.0692451570 - val_labeled_loss: 4.0692451570 |██████████████████--| 94.0%  - val_loss: 1351.9017387058 - val_trvae_loss: 1347.8223770805 - val_landmark_loss: 4.0793717737 - val_labeled_loss: 4.0793717737 |███████████████████-| 95.0%  - val_loss: 1350.2520061990 - val_trvae_loss: 1346.7858462126 - val_landmark_loss: 3.4661558867 - val_labeled_loss: 3.4661558867 |███████████████████-| 96.0%  - val_loss: 1350.1963952106 - val_trvae_loss: 1347.0426025391 - val_landmark_loss: 3.1537925990 - val_labeled_loss: 3.1537925990 |███████████████████-| 97.0%  - val_loss: 1349.6025337551 - val_trvae_loss: 1346.6421110734 - val_landmark_loss: 2.9604192661 - val_labeled_loss: 2.9604192661 |███████████████████-| 98.0%  - val_loss: 1349.7874172045 - val_trvae_loss: 1346.7646378227 - val_landmark_loss: 3.0227782467 - val_labeled_loss: 3.0227782467 |███████████████████-| 99.0%  - val_loss: 1349.0895836872 - val_trvae_loss: 1346.5081362517 - val_landmark_loss: 2.5814522038 - val_labeled_loss: 2.5814522038 |████████████████████| 100.0%  - val_loss: 1349.9662661345 - val_trvae_loss: 1347.2515285326 - val_landmark_loss: 2.7147379543 - val_labeled_loss: 2.7147379543
2022-05-19 14:17:32 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 3347 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

3
loaders init
loaders init done
0.02614116668701172
 |--------------------| 1.0%  - val_loss: 915.9695027669 - val_trvae_loss: 915.9695027669 |--------------------| 2.0%  - val_loss: 913.2258707682 - val_trvae_loss: 913.2258707682 |--------------------| 3.0%  - val_loss: 912.8594767253 - val_trvae_loss: 912.8594767253 |--------------------| 4.0%  - val_loss: 914.5413411458 - val_trvae_loss: 914.5413411458 |█-------------------| 5.0%  - val_loss: 911.0910441081 - val_trvae_loss: 911.0910441081 |█-------------------| 6.0%  - val_loss: 912.5811971029 - val_trvae_loss: 912.5811971029 |█-------------------| 7.0%  - val_loss: 904.9430541992 - val_trvae_loss: 904.9430541992 |█-------------------| 8.0%  - val_loss: 909.0822753906 - val_trvae_loss: 909.0822753906 |█-------------------| 9.0%  - val_loss: 906.9461059570 - val_trvae_loss: 906.9461059570 |██------------------| 10.0%  - val_loss: 912.8500366211 - val_trvae_loss: 912.8500366211 |██------------------| 11.0%  - val_loss: 905.1641642253 - val_trvae_loss: 905.1641642253 |██------------------| 12.0%  - val_loss: 907.5760091146 - val_trvae_loss: 907.5760091146 |██------------------| 13.0%  - val_loss: 906.7149861654 - val_trvae_loss: 906.7149861654 |██------------------| 14.0%  - val_loss: 912.2603963216 - val_trvae_loss: 912.2603963216 |███-----------------| 15.0%  - val_loss: 904.0080973307 - val_trvae_loss: 904.0080973307 |███-----------------| 16.0%  - val_loss: 902.8442586263 - val_trvae_loss: 902.8442586263 |███-----------------| 17.0%  - val_loss: 904.9868164062 - val_trvae_loss: 904.9868164062 |███-----------------| 18.0%  - val_loss: 909.4668579102 - val_trvae_loss: 909.4668579102 |███-----------------| 19.0%  - val_loss: 901.9559733073 - val_trvae_loss: 901.9559733073 |████----------------| 20.0%  - val_loss: 898.6789550781 - val_trvae_loss: 898.6789550781 |████----------------| 21.0%  - val_loss: 900.8411254883 - val_trvae_loss: 900.8411254883 |████----------------| 22.0%  - val_loss: 900.5218709310 - val_trvae_loss: 900.5218709310 |████----------------| 23.0%  - val_loss: 900.4381917318 - val_trvae_loss: 900.4381917318 |████----------------| 24.0%  - val_loss: 897.0709431966 - val_trvae_loss: 897.0709431966 |█████---------------| 25.0%  - val_loss: 904.2518310547 - val_trvae_loss: 904.2518310547 |█████---------------| 26.0%  - val_loss: 904.8479614258 - val_trvae_loss: 904.8479614258 |█████---------------| 27.0%  - val_loss: 893.8547770182 - val_trvae_loss: 893.8547770182 |█████---------------| 28.0%  - val_loss: 901.9525349935 - val_trvae_loss: 901.9525349935 |█████---------------| 29.0%  - val_loss: 892.6554158529 - val_trvae_loss: 892.6554158529 |██████--------------| 30.0%  - val_loss: 900.6231892904 - val_trvae_loss: 900.6231892904 |██████--------------| 31.0%  - val_loss: 905.5139160156 - val_trvae_loss: 905.5139160156 |██████--------------| 32.0%  - val_loss: 901.0324910482 - val_trvae_loss: 901.0324910482 |██████--------------| 33.0%  - val_loss: 897.9054565430 - val_trvae_loss: 897.9054565430 |██████--------------| 34.0%  - val_loss: 898.1830851237 - val_trvae_loss: 898.1830851237 |███████-------------| 35.0%  - val_loss: 894.6829223633 - val_trvae_loss: 894.6829223633 |███████-------------| 36.0%  - val_loss: 897.2298583984 - val_trvae_loss: 897.2298583984 |███████-------------| 37.0%  - val_loss: 894.3847859701 - val_trvae_loss: 894.3847859701 |███████-------------| 38.0%  - val_loss: 889.2855021159 - val_trvae_loss: 889.2855021159 |███████-------------| 39.0%  - val_loss: 894.7410685221 - val_trvae_loss: 894.7410685221 |████████------------| 40.0%  - val_loss: 898.7430826823 - val_trvae_loss: 898.7430826823 |████████------------| 41.0%  - val_loss: 891.8511962891 - val_trvae_loss: 891.8511962891 |████████------------| 42.0%  - val_loss: 894.5764567057 - val_trvae_loss: 894.5764567057 |████████------------| 43.0%  - val_loss: 902.7931111654 - val_trvae_loss: 902.7931111654 |████████------------| 44.0%  - val_loss: 897.8115641276 - val_trvae_loss: 897.8115641276 |█████████-----------| 45.0%  - val_loss: 892.0674845378 - val_trvae_loss: 892.0674845378 |█████████-----------| 46.0%  - val_loss: 901.1710815430 - val_trvae_loss: 901.1710815430 |█████████-----------| 47.0%  - val_loss: 900.4171142578 - val_trvae_loss: 900.4171142578 |█████████-----------| 48.0%  - val_loss: 896.2705078125 - val_trvae_loss: 896.2705078125 |█████████-----------| 49.0%  - val_loss: 893.0157063802 - val_trvae_loss: 893.0157063802 |██████████----------| 50.0%  - val_loss: 888.0932413737 - val_trvae_loss: 888.0932413737 |██████████----------| 51.0%  - val_loss: 894.0873819987 - val_trvae_loss: 894.0873819987 |██████████----------| 52.0%  - val_loss: 895.5491943359 - val_trvae_loss: 895.5491943359 |██████████----------| 53.0%  - val_loss: 891.0747273763 - val_trvae_loss: 891.0747273763 |██████████----------| 54.0%  - val_loss: 899.2394816081 - val_trvae_loss: 899.2394816081 |███████████---------| 55.0%  - val_loss: 891.6346842448 - val_trvae_loss: 891.6346842448 |███████████---------| 56.0%  - val_loss: 895.2056274414 - val_trvae_loss: 895.2056274414 |███████████---------| 57.0%  - val_loss: 901.2790120443 - val_trvae_loss: 901.2790120443 |███████████---------| 58.0%  - val_loss: 890.7705485026 - val_trvae_loss: 890.7705485026 |███████████---------| 59.0%  - val_loss: 893.4284464518 - val_trvae_loss: 893.4284464518 |████████████--------| 60.0%  - val_loss: 899.4512329102 - val_trvae_loss: 899.4512329102 |████████████--------| 61.0%  - val_loss: 896.2225545247 - val_trvae_loss: 896.2225545247 |████████████--------| 62.0%  - val_loss: 893.1541544596 - val_trvae_loss: 893.1541544596 |████████████--------| 63.0%  - val_loss: 893.3281860352 - val_trvae_loss: 893.3281860352 |████████████--------| 64.0%  - val_loss: 896.7890421549 - val_trvae_loss: 896.7890421549 |█████████████-------| 65.0%  - val_loss: 901.5886027018 - val_trvae_loss: 901.5886027018 |█████████████-------| 66.0%  - val_loss: 895.4386189779 - val_trvae_loss: 895.4386189779 |█████████████-------| 67.0%  - val_loss: 893.9764811198 - val_trvae_loss: 893.9764811198 |█████████████-------| 68.0%  - val_loss: 893.0097859701 - val_trvae_loss: 893.0097859701 |█████████████-------| 69.0%  - val_loss: 894.9137776693 - val_trvae_loss: 894.9137776693 |██████████████------| 70.0%  - val_loss: 896.1163330078 - val_trvae_loss: 896.1163330078 |██████████████------| 71.0%  - val_loss: 898.0032958984 - val_trvae_loss: 898.0032958984 |██████████████------| 72.0%  - val_loss: 889.9517618815 - val_trvae_loss: 889.9517618815 |██████████████------| 73.0%  - val_loss: 892.0070597331 - val_trvae_loss: 892.0070597331 |██████████████------| 74.0%  - val_loss: 900.5861816406 - val_trvae_loss: 900.5861816406 |███████████████-----| 75.0%  - val_loss: 890.1093139648 - val_trvae_loss: 890.1093139648 |███████████████-----| 76.0%  - val_loss: 904.0386555990 - val_trvae_loss: 904.0386555990 |███████████████-----| 77.0%  - val_loss: 890.7980957031 - val_trvae_loss: 890.7980957031 |███████████████-----| 78.0%  - val_loss: 897.0019734701 - val_trvae_loss: 897.0019734701 |███████████████-----| 79.0%  - val_loss: 892.2408447266 - val_trvae_loss: 892.2408447266 |████████████████----| 80.0%  - val_loss: 892.0865071615 - val_trvae_loss: 892.0865071615
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 18 clusters.
 |████████████████----| 81.0%  - val_loss: 891.5935262044 - val_trvae_loss: 891.5934041341 - val_landmark_loss: 0.0001493352 - val_unlabeled_loss: 0.1493351956 |████████████████----| 82.0%  - val_loss: 893.1776123047 - val_trvae_loss: 893.1774902344 - val_landmark_loss: 0.0001356226 - val_unlabeled_loss: 0.1356225610 |████████████████----| 83.0%  - val_loss: 883.7049763997 - val_trvae_loss: 883.7048339844 - val_landmark_loss: 0.0001387310 - val_unlabeled_loss: 0.1387310053 |████████████████----| 84.0%  - val_loss: 893.9089355469 - val_trvae_loss: 893.9087931315 - val_landmark_loss: 0.0001328687 - val_unlabeled_loss: 0.1328687221 |█████████████████---| 85.0%  - val_loss: 893.3378295898 - val_trvae_loss: 893.3376871745 - val_landmark_loss: 0.0001402267 - val_unlabeled_loss: 0.1402266547 |█████████████████---| 86.0%  - val_loss: 884.2353515625 - val_trvae_loss: 884.2352091471 - val_landmark_loss: 0.0001393487 - val_unlabeled_loss: 0.1393486410 |█████████████████---| 87.0%  - val_loss: 894.5398966471 - val_trvae_loss: 894.5396931966 - val_landmark_loss: 0.0001950239 - val_unlabeled_loss: 0.1950239191 |█████████████████---| 88.0%  - val_loss: 896.6705932617 - val_trvae_loss: 896.6704508464 - val_landmark_loss: 0.0001655595 - val_unlabeled_loss: 0.1655594458 |█████████████████---| 89.0%  - val_loss: 892.7844034831 - val_trvae_loss: 892.7842407227 - val_landmark_loss: 0.0001414893 - val_unlabeled_loss: 0.1414893071 |██████████████████--| 90.0%  - val_loss: 895.1952921549 - val_trvae_loss: 895.1951700846 - val_landmark_loss: 0.0001293545 - val_unlabeled_loss: 0.1293544794 |██████████████████--| 91.0%  - val_loss: 891.4940185547 - val_trvae_loss: 891.4938761393 - val_landmark_loss: 0.0001373992 - val_unlabeled_loss: 0.1373991643 |██████████████████--| 92.0%  - val_loss: 892.0700683594 - val_trvae_loss: 892.0699462891 - val_landmark_loss: 0.0001369857 - val_unlabeled_loss: 0.1369856844 |██████████████████--| 93.0%  - val_loss: 893.5690104167 - val_trvae_loss: 893.5688680013 - val_landmark_loss: 0.0001435738 - val_unlabeled_loss: 0.1435738256 |██████████████████--| 94.0%  - val_loss: 887.7534586589 - val_trvae_loss: 887.7533162435 - val_landmark_loss: 0.0001323314 - val_unlabeled_loss: 0.1323314086 |███████████████████-| 95.0%  - val_loss: 896.3984375000 - val_trvae_loss: 896.3983154297 - val_landmark_loss: 0.0001363777 - val_unlabeled_loss: 0.1363777195 |███████████████████-| 96.0%  - val_loss: 893.1554361979 - val_trvae_loss: 893.1552937826 - val_landmark_loss: 0.0001421186 - val_unlabeled_loss: 0.1421186229 |███████████████████-| 97.0%  - val_loss: 889.4617716471 - val_trvae_loss: 889.4616292318 - val_landmark_loss: 0.0001443524 - val_unlabeled_loss: 0.1443523566 |███████████████████-| 98.0%  - val_loss: 887.5349527995 - val_trvae_loss: 887.5348103841 - val_landmark_loss: 0.0001387902 - val_unlabeled_loss: 0.1387901704 |███████████████████-| 99.0%  - val_loss: 886.8693644206 - val_trvae_loss: 886.8692220052 - val_landmark_loss: 0.0001398804 - val_unlabeled_loss: 0.1398803915 |████████████████████| 100.0%  - val_loss: 892.1684570312 - val_trvae_loss: 892.1683146159 - val_landmark_loss: 0.0001464445 - val_unlabeled_loss: 0.1464444846
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2022-05-19 14:18:04 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2022-05-19 14:18:05 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
Saving best state of network...
Best State was in Epoch 89
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
2022-05-19 14:30:24 (ERROR): Failed after 0:16:46!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/tmp/8996/uncertainty/uncertainty_seml.py", line 252, in run
    rmtree(REF_PATH)
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 699, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/shutil.py", line 697, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/storage/groups/ml01/workspace/carlo.dedonno/lataq_reproduce/tmp/ref_model_embedcvae_19'

