Starting job 3781267
SLURM assigned me the node(s): gpusrv09
Experiments are running under the following process IDs:
Experiment ID: 4	Process ID: 46454

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 10:57:03 (INFO): Running command 'run'
2021-10-26 10:57:03 (INFO): Started run with ID "4"
2021-10-26 10:57:16 (INFO): Data loaded succesfully
2021-10-26 10:57:16 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 8
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1255.3501993815 - val_trvae_loss: 1255.3501993815 |--------------------| 2.0%  - val_loss: 1197.9940490723 - val_trvae_loss: 1197.9940490723 |--------------------| 3.0%  - val_loss: 1167.9662272135 - val_trvae_loss: 1167.9662272135 |--------------------| 4.0%  - val_loss: 1152.3849589030 - val_trvae_loss: 1152.3849589030 |█-------------------| 5.0%  - val_loss: 1142.7538757324 - val_trvae_loss: 1142.7538757324 |█-------------------| 6.0%  - val_loss: 1134.4655049642 - val_trvae_loss: 1134.4655049642 |█-------------------| 7.0%  - val_loss: 1127.4627278646 - val_trvae_loss: 1127.4627278646 |█-------------------| 8.0%  - val_loss: 1121.9855041504 - val_trvae_loss: 1121.9855041504 |█-------------------| 9.0%  - val_loss: 1119.5067647298 - val_trvae_loss: 1119.5067647298 |██------------------| 10.0%  - val_loss: 1115.3556620280 - val_trvae_loss: 1115.3556620280 |██------------------| 11.0%  - val_loss: 1111.8386637370 - val_trvae_loss: 1111.8386637370 |██------------------| 12.0%  - val_loss: 1108.6951090495 - val_trvae_loss: 1108.6951090495 |██------------------| 13.0%  - val_loss: 1104.7990926107 - val_trvae_loss: 1104.7990926107 |██------------------| 14.0%  - val_loss: 1103.3453979492 - val_trvae_loss: 1103.3453979492 |███-----------------| 15.0%  - val_loss: 1101.4480794271 - val_trvae_loss: 1101.4480794271 |███-----------------| 16.0%  - val_loss: 1099.4798380534 - val_trvae_loss: 1099.4798380534 |███-----------------| 17.0%  - val_loss: 1099.2626342773 - val_trvae_loss: 1099.2626342773 |███-----------------| 18.0%  - val_loss: 1097.7845153809 - val_trvae_loss: 1097.7845153809 |███-----------------| 19.0%  - val_loss: 1095.9022318522 - val_trvae_loss: 1095.9022318522 |████----------------| 20.0%  - val_loss: 1094.5076497396 - val_trvae_loss: 1094.5076497396 |████----------------| 21.0%  - val_loss: 1092.6680196126 - val_trvae_loss: 1092.6680196126 |████----------------| 22.0%  - val_loss: 1092.9070027669 - val_trvae_loss: 1092.9070027669 |████----------------| 23.0%  - val_loss: 1090.6306050618 - val_trvae_loss: 1090.6306050618 |████----------------| 24.0%  - val_loss: 1090.0922749837 - val_trvae_loss: 1090.0922749837 |█████---------------| 25.0%  - val_loss: 1089.6783803304 - val_trvae_loss: 1089.6783803304 |█████---------------| 26.0%  - val_loss: 1090.5760701497 - val_trvae_loss: 1090.5760701497 |█████---------------| 27.0%  - val_loss: 1090.3730875651 - val_trvae_loss: 1090.3730875651 |█████---------------| 28.0%  - val_loss: 1088.1325378418 - val_trvae_loss: 1088.1325378418 |█████---------------| 29.0%  - val_loss: 1086.9422302246 - val_trvae_loss: 1086.9422302246 |██████--------------| 30.0%  - val_loss: 1086.6836954753 - val_trvae_loss: 1086.6836954753 |██████--------------| 31.0%  - val_loss: 1087.0649210612 - val_trvae_loss: 1087.0649210612 |██████--------------| 32.0%  - val_loss: 1085.7828165690 - val_trvae_loss: 1085.7828165690 |██████--------------| 33.0%  - val_loss: 1085.7678426107 - val_trvae_loss: 1085.7678426107 |██████--------------| 34.0%  - val_loss: 1086.0108540853 - val_trvae_loss: 1086.0108540853 |███████-------------| 35.0%  - val_loss: 1085.4814961751 - val_trvae_loss: 1085.4814961751 |███████-------------| 36.0%  - val_loss: 1086.0063578288 - val_trvae_loss: 1086.0063578288 |███████-------------| 37.0%  - val_loss: 1086.8587137858 - val_trvae_loss: 1086.8587137858 |███████-------------| 38.0%  - val_loss: 1084.9760487874 - val_trvae_loss: 1084.9760487874 |███████-------------| 39.0%  - val_loss: 1084.1503804525 - val_trvae_loss: 1084.1503804525 |████████------------| 40.0%  - val_loss: 1084.5049133301 - val_trvae_loss: 1084.5049133301 |████████------------| 41.0%  - val_loss: 1084.6546630859 - val_trvae_loss: 1084.6546630859 |████████------------| 42.0%  - val_loss: 1084.0473429362 - val_trvae_loss: 1084.0473429362 |████████------------| 43.0%  - val_loss: 1083.6797281901 - val_trvae_loss: 1083.6797281901 |████████------------| 44.0%  - val_loss: 1086.1082560221 - val_trvae_loss: 1086.1082560221 |█████████-----------| 45.0%  - val_loss: 1084.9054870605 - val_trvae_loss: 1084.9054870605 |█████████-----------| 46.0%  - val_loss: 1084.2372843424 - val_trvae_loss: 1084.2372843424 |█████████-----------| 47.0%  - val_loss: 1081.7143147786 - val_trvae_loss: 1081.7143147786 |█████████-----------| 48.0%  - val_loss: 1082.5033671061 - val_trvae_loss: 1082.5033671061 |█████████-----------| 49.0%  - val_loss: 1083.0503641764 - val_trvae_loss: 1083.0503641764 |██████████----------| 50.0%  - val_loss: 1083.5051676432 - val_trvae_loss: 1083.5051676432 |██████████----------| 51.0%  - val_loss: 1083.2665100098 - val_trvae_loss: 1083.2665100098 |██████████----------| 52.0%  - val_loss: 1082.0117390951 - val_trvae_loss: 1082.0117390951 |██████████----------| 53.0%  - val_loss: 1083.3977661133 - val_trvae_loss: 1083.3977661133 |██████████----------| 54.0%  - val_loss: 1082.5893351237 - val_trvae_loss: 1082.5893351237 |███████████---------| 55.0%  - val_loss: 1082.9150695801 - val_trvae_loss: 1082.9150695801 |███████████---------| 56.0%  - val_loss: 1082.0041605632 - val_trvae_loss: 1082.0041605632 |███████████---------| 57.0%  - val_loss: 1082.5345458984 - val_trvae_loss: 1082.5345458984 |███████████---------| 58.0%  - val_loss: 1082.6923217773 - val_trvae_loss: 1082.6923217773 |███████████---------| 59.0%  - val_loss: 1082.5685221354 - val_trvae_loss: 1082.5685221354 |████████████--------| 60.0%  - val_loss: 1081.9916178385 - val_trvae_loss: 1081.9916178385 |████████████--------| 61.0%  - val_loss: 1082.5703735352 - val_trvae_loss: 1082.5703735352 |████████████--------| 62.0%  - val_loss: 1082.8640747070 - val_trvae_loss: 1082.8640747070 |████████████--------| 63.0%  - val_loss: 1082.3084920247 - val_trvae_loss: 1082.3084920247 |████████████--------| 64.0%  - val_loss: 1082.9302469889 - val_trvae_loss: 1082.9302469889 |█████████████-------| 65.0%  - val_loss: 1080.9128011068 - val_trvae_loss: 1080.9128011068 |█████████████-------| 66.0%  - val_loss: 1082.2062072754 - val_trvae_loss: 1082.2062072754 |█████████████-------| 67.0%  - val_loss: 1082.5173543294 - val_trvae_loss: 1082.5173543294 |█████████████-------| 68.0%  - val_loss: 1081.2084147135 - val_trvae_loss: 1081.2084147135 |█████████████-------| 69.0%  - val_loss: 1080.1966247559 - val_trvae_loss: 1080.1966247559 |██████████████------| 70.0%  - val_loss: 1082.2192281087 - val_trvae_loss: 1082.2192281087 |██████████████------| 71.0%  - val_loss: 1082.3600667318 - val_trvae_loss: 1082.3600667318 |██████████████------| 72.0%  - val_loss: 1081.1917114258 - val_trvae_loss: 1081.1917114258 |██████████████------| 73.0%  - val_loss: 1081.0606740316 - val_trvae_loss: 1081.0606740316 |██████████████------| 74.0%  - val_loss: 1082.3240966797 - val_trvae_loss: 1082.3240966797 |███████████████-----| 75.0%  - val_loss: 1080.6583251953 - val_trvae_loss: 1080.6583251953 |███████████████-----| 76.0%  - val_loss: 1081.2842458089 - val_trvae_loss: 1081.2842458089 |███████████████-----| 77.0%  - val_loss: 1081.2358601888 - val_trvae_loss: 1081.2358601888 |███████████████-----| 78.0%  - val_loss: 1081.3031921387 - val_trvae_loss: 1081.3031921387 |███████████████-----| 79.0%  - val_loss: 1080.6229960124 - val_trvae_loss: 1080.6229960124 |████████████████----| 80.0%  - val_loss: 1081.4914347331 - val_trvae_loss: 1081.4914347331 |████████████████----| 81.0%  - val_loss: 1086.1054077148 - val_trvae_loss: 1082.9755147298 - val_landmark_loss: 3.1298828423 - val_labeled_loss: 3.1298828423 |████████████████----| 82.0%  - val_loss: 1085.6169128418 - val_trvae_loss: 1082.4863789876 - val_landmark_loss: 3.1305263937 - val_labeled_loss: 3.1305263937 |████████████████----| 83.0%  - val_loss: 1085.0819803874 - val_trvae_loss: 1082.3760782878 - val_landmark_loss: 2.7058937947 - val_labeled_loss: 2.7058937947 |████████████████----| 84.0%  - val_loss: 1085.3488464355 - val_trvae_loss: 1083.0675150553 - val_landmark_loss: 2.2813381851 - val_labeled_loss: 2.2813381851 |█████████████████---| 85.0%  - val_loss: 1084.9366658529 - val_trvae_loss: 1082.4811706543 - val_landmark_loss: 2.4554919799 - val_labeled_loss: 2.4554919799 |█████████████████---| 86.0%  - val_loss: 1085.6362711589 - val_trvae_loss: 1083.5765991211 - val_landmark_loss: 2.0596650938 - val_labeled_loss: 2.0596650938 |█████████████████---| 87.0%  - val_loss: 1085.0103963216 - val_trvae_loss: 1083.0980733236 - val_landmark_loss: 1.9123311838 - val_labeled_loss: 1.9123311838 |█████████████████---| 88.0%  - val_loss: 1084.7957255046 - val_trvae_loss: 1082.9579366048 - val_landmark_loss: 1.8377984613 - val_labeled_loss: 1.8377984613 |█████████████████---| 89.0%  - val_loss: 1083.4414265951 - val_trvae_loss: 1081.6722005208 - val_landmark_loss: 1.7692277630 - val_labeled_loss: 1.7692277630 |██████████████████--| 90.0%  - val_loss: 1084.1243693034 - val_trvae_loss: 1082.0653889974 - val_landmark_loss: 2.0590006659 - val_labeled_loss: 2.0590006659 |██████████████████--| 91.0%  - val_loss: 1083.9855753581 - val_trvae_loss: 1081.9126586914 - val_landmark_loss: 2.0729062657 - val_labeled_loss: 2.0729062657 |██████████████████--| 92.0%  - val_loss: 1082.9146525065 - val_trvae_loss: 1081.4346516927 - val_landmark_loss: 1.4800066898 - val_labeled_loss: 1.4800066898 |██████████████████--| 93.0%  - val_loss: 1084.5439758301 - val_trvae_loss: 1083.1336568197 - val_landmark_loss: 1.4103112221 - val_labeled_loss: 1.4103112221 |██████████████████--| 94.0%  - val_loss: 1083.4674987793 - val_trvae_loss: 1081.7119649251 - val_landmark_loss: 1.7555203040 - val_labeled_loss: 1.7555203040 |███████████████████-| 95.0%  - val_loss: 1083.5332234701 - val_trvae_loss: 1081.8369140625 - val_landmark_loss: 1.6963188052 - val_labeled_loss: 1.6963188052 |███████████████████-| 96.0%  - val_loss: 1084.0181070964 - val_trvae_loss: 1082.3315124512 - val_landmark_loss: 1.6865848452 - val_labeled_loss: 1.6865848452 |███████████████████-| 97.0%  - val_loss: 1084.7027486165 - val_trvae_loss: 1082.7147623698 - val_landmark_loss: 1.9879916012 - val_labeled_loss: 1.9879916012 |███████████████████-| 98.0%  - val_loss: 1084.5161844889 - val_trvae_loss: 1083.0166320801 - val_landmark_loss: 1.4995571822 - val_labeled_loss: 1.4995571822 |███████████████████-| 99.0%  - val_loss: 1083.7084248861 - val_trvae_loss: 1082.5104777018 - val_landmark_loss: 1.1979441047 - val_labeled_loss: 1.1979441047 |████████████████████| 100.0%  - val_loss: 1083.1858520508 - val_trvae_loss: 1081.8687235514 - val_landmark_loss: 1.3171351502 - val_labeled_loss: 1.3171351502
2021-10-26 10:59:35 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 98
AnnData object with n_obs × n_vars = 1303 × 4000
    obs: 'study', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 9
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1043.6783447266 - val_trvae_loss: 1043.6783447266 |--------------------| 2.0%  - val_loss: 1051.8738403320 - val_trvae_loss: 1051.8738403320 |--------------------| 3.0%  - val_loss: 1090.3985595703 - val_trvae_loss: 1090.3985595703 |--------------------| 4.0%  - val_loss: 1051.9841308594 - val_trvae_loss: 1051.9841308594 |█-------------------| 5.0%  - val_loss: 1144.4121093750 - val_trvae_loss: 1144.4121093750 |█-------------------| 6.0%  - val_loss: 1139.1567993164 - val_trvae_loss: 1139.1567993164 |█-------------------| 7.0%  - val_loss: 1049.5203247070 - val_trvae_loss: 1049.5203247070 |█-------------------| 8.0%  - val_loss: 1105.2258911133 - val_trvae_loss: 1105.2258911133 |█-------------------| 9.0%  - val_loss: 1009.7217407227 - val_trvae_loss: 1009.7217407227 |██------------------| 10.0%  - val_loss: 1194.5401000977 - val_trvae_loss: 1194.5401000977 |██------------------| 11.0%  - val_loss: 1029.0670471191 - val_trvae_loss: 1029.0670471191 |██------------------| 12.0%  - val_loss: 1047.8853149414 - val_trvae_loss: 1047.8853149414 |██------------------| 13.0%  - val_loss: 1022.3567199707 - val_trvae_loss: 1022.3567199707 |██------------------| 14.0%  - val_loss: 1014.1694946289 - val_trvae_loss: 1014.1694946289 |███-----------------| 15.0%  - val_loss: 1222.6821899414 - val_trvae_loss: 1222.6821899414 |███-----------------| 16.0%  - val_loss: 1029.2813720703 - val_trvae_loss: 1029.2813720703 |███-----------------| 17.0%  - val_loss: 988.5095214844 - val_trvae_loss: 988.5095214844 |███-----------------| 18.0%  - val_loss: 970.3952941895 - val_trvae_loss: 970.3952941895 |███-----------------| 19.0%  - val_loss: 1239.5593261719 - val_trvae_loss: 1239.5593261719 |████----------------| 20.0%  - val_loss: 1083.5839233398 - val_trvae_loss: 1083.5839233398 |████----------------| 21.0%  - val_loss: 1033.4136352539 - val_trvae_loss: 1033.4136352539 |████----------------| 22.0%  - val_loss: 974.4572753906 - val_trvae_loss: 974.4572753906 |████----------------| 23.0%  - val_loss: 998.4961853027 - val_trvae_loss: 998.4961853027 |████----------------| 24.0%  - val_loss: 1034.7753295898 - val_trvae_loss: 1034.7753295898 |█████---------------| 25.0%  - val_loss: 1180.9146728516 - val_trvae_loss: 1180.9146728516 |█████---------------| 26.0%  - val_loss: 924.9189453125 - val_trvae_loss: 924.9189453125 |█████---------------| 27.0%  - val_loss: 1094.9523925781 - val_trvae_loss: 1094.9523925781 |█████---------------| 28.0%  - val_loss: 1014.8046569824 - val_trvae_loss: 1014.8046569824 |█████---------------| 29.0%  - val_loss: 1059.4864501953 - val_trvae_loss: 1059.4864501953 |██████--------------| 30.0%  - val_loss: 951.2231750488 - val_trvae_loss: 951.2231750488 |██████--------------| 31.0%  - val_loss: 1066.3414916992 - val_trvae_loss: 1066.3414916992 |██████--------------| 32.0%  - val_loss: 1019.7165222168 - val_trvae_loss: 1019.7165222168 |██████--------------| 33.0%  - val_loss: 993.2306518555 - val_trvae_loss: 993.2306518555 |██████--------------| 34.0%  - val_loss: 1000.2860107422 - val_trvae_loss: 1000.2860107422 |███████-------------| 35.0%  - val_loss: 1049.0714721680 - val_trvae_loss: 1049.0714721680 |███████-------------| 36.0%  - val_loss: 1116.2420654297 - val_trvae_loss: 1116.2420654297 |███████-------------| 37.0%  - val_loss: 973.4621276855 - val_trvae_loss: 973.4621276855 |███████-------------| 38.0%  - val_loss: 985.5651855469 - val_trvae_loss: 985.5651855469 |███████-------------| 39.0%  - val_loss: 1185.9500732422 - val_trvae_loss: 1185.9500732422 |████████------------| 40.0%  - val_loss: 1026.0798339844 - val_trvae_loss: 1026.0798339844 |████████------------| 41.0%  - val_loss: 932.3389282227 - val_trvae_loss: 932.3389282227 |████████------------| 42.0%  - val_loss: 986.9810791016 - val_trvae_loss: 986.9810791016 |████████------------| 43.0%  - val_loss: 1165.1887817383 - val_trvae_loss: 1165.1887817383 |████████------------| 44.0%  - val_loss: 1097.8918457031 - val_trvae_loss: 1097.8918457031 |█████████-----------| 45.0%  - val_loss: 1082.6834716797 - val_trvae_loss: 1082.6834716797 |█████████-----------| 46.0%  - val_loss: 1003.0281372070 - val_trvae_loss: 1003.0281372070 |█████████-----------| 47.0%  - val_loss: 1105.8180541992 - val_trvae_loss: 1105.8180541992 |█████████-----------| 48.0%  - val_loss: 951.2077026367 - val_trvae_loss: 951.2077026367 |█████████-----------| 49.0%  - val_loss: 1018.4273376465 - val_trvae_loss: 1018.4273376465 |██████████----------| 50.0%  - val_loss: 1015.7404785156 - val_trvae_loss: 1015.7404785156 |██████████----------| 51.0%  - val_loss: 1017.1002502441 - val_trvae_loss: 1017.1002502441 |██████████----------| 52.0%  - val_loss: 1089.8338623047 - val_trvae_loss: 1089.8338623047 |██████████----------| 53.0%  - val_loss: 1060.7880859375 - val_trvae_loss: 1060.7880859375 |██████████----------| 54.0%  - val_loss: 1008.4438171387 - val_trvae_loss: 1008.4438171387 |███████████---------| 55.0%  - val_loss: 1015.8808898926 - val_trvae_loss: 1015.8808898926 |███████████---------| 56.0%  - val_loss: 991.9354858398 - val_trvae_loss: 991.9354858398 |███████████---------| 57.0%  - val_loss: 1002.4626464844 - val_trvae_loss: 1002.4626464844 |███████████---------| 58.0%  - val_loss: 1048.6932373047 - val_trvae_loss: 1048.6932373047 |███████████---------| 59.0%  - val_loss: 1130.2471313477 - val_trvae_loss: 1130.2471313477 |████████████--------| 60.0%  - val_loss: 977.2519836426 - val_trvae_loss: 977.2519836426 |████████████--------| 61.0%  - val_loss: 1011.3158874512 - val_trvae_loss: 1011.3158874512 |████████████--------| 62.0%  - val_loss: 1167.8249511719 - val_trvae_loss: 1167.8249511719 |████████████--------| 63.0%  - val_loss: 953.9384155273 - val_trvae_loss: 953.9384155273 |████████████--------| 64.0%  - val_loss: 1022.7095031738 - val_trvae_loss: 1022.7095031738 |█████████████-------| 65.0%  - val_loss: 1078.4207763672 - val_trvae_loss: 1078.4207763672 |█████████████-------| 66.0%  - val_loss: 1108.5717773438 - val_trvae_loss: 1108.5717773438 |█████████████-------| 67.0%  - val_loss: 956.5386352539 - val_trvae_loss: 956.5386352539 |█████████████-------| 68.0%  - val_loss: 1036.4887084961 - val_trvae_loss: 1036.4887084961 |█████████████-------| 69.0%  - val_loss: 1028.9521179199 - val_trvae_loss: 1028.9521179199 |██████████████------| 70.0%  - val_loss: 1047.5784912109 - val_trvae_loss: 1047.5784912109 |██████████████------| 71.0%  - val_loss: 1016.4146423340 - val_trvae_loss: 1016.4146423340 |██████████████------| 72.0%  - val_loss: 1079.9986572266 - val_trvae_loss: 1079.9986572266 |██████████████------| 73.0%  - val_loss: 1049.8572998047 - val_trvae_loss: 1049.8572998047 |██████████████------| 74.0%  - val_loss: 1112.9603881836 - val_trvae_loss: 1112.9603881836 |███████████████-----| 75.0%  - val_loss: 1011.4417724609 - val_trvae_loss: 1011.4417724609 |███████████████-----| 76.0%  - val_loss: 950.5543823242 - val_trvae_loss: 950.5543823242 |███████████████-----| 77.0%  - val_loss: 1051.1467895508 - val_trvae_loss: 1051.1467895508 |███████████████-----| 78.0%  - val_loss: 946.5117187500 - val_trvae_loss: 946.5117187500 |███████████████-----| 79.0%  - val_loss: 1002.3135986328 - val_trvae_loss: 1002.3135986328 |████████████████----| 80.0%  - val_loss: 950.5056762695 - val_trvae_loss: 950.5056762695
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 12 clusters.
 |████████████████----| 81.0%  - val_loss: 989.4212341309 - val_trvae_loss: 989.4211425781 - val_landmark_loss: 0.0000733208 - val_unlabeled_loss: 0.0733207650 |████████████████----| 82.0%  - val_loss: 1013.3561706543 - val_trvae_loss: 1013.3560180664 - val_landmark_loss: 0.0001438321 - val_unlabeled_loss: 0.1438321136 |████████████████----| 83.0%  - val_loss: 1031.4337768555 - val_trvae_loss: 1031.4336547852 - val_landmark_loss: 0.0000813871 - val_unlabeled_loss: 0.0813871063 |████████████████----| 84.0%  - val_loss: 994.6430664062 - val_trvae_loss: 994.6429748535 - val_landmark_loss: 0.0000817056 - val_unlabeled_loss: 0.0817055628 |█████████████████---| 85.0%  - val_loss: 930.2666625977 - val_trvae_loss: 930.2665710449 - val_landmark_loss: 0.0000880687 - val_unlabeled_loss: 0.0880687311 |█████████████████---| 86.0%  - val_loss: 1083.7327880859 - val_trvae_loss: 1083.7324218750 - val_landmark_loss: 0.0003165860 - val_unlabeled_loss: 0.3165859580 |█████████████████---| 87.0%  - val_loss: 1102.7310791016 - val_trvae_loss: 1102.7309570312 - val_landmark_loss: 0.0000821517 - val_unlabeled_loss: 0.0821516812 |█████████████████---| 88.0%  - val_loss: 1117.9515991211 - val_trvae_loss: 1117.9514770508 - val_landmark_loss: 0.0000821792 - val_unlabeled_loss: 0.0821791999 |█████████████████---| 89.0%  - val_loss: 979.8844909668 - val_trvae_loss: 979.8843688965 - val_landmark_loss: 0.0000921066 - val_unlabeled_loss: 0.0921066143 |██████████████████--| 90.0%  - val_loss: 1002.8738403320 - val_trvae_loss: 1002.8737487793 - val_landmark_loss: 0.0000845707 - val_unlabeled_loss: 0.0845706910 |██████████████████--| 91.0%  - val_loss: 1039.6818847656 - val_trvae_loss: 1039.6818237305 - val_landmark_loss: 0.0000698759 - val_unlabeled_loss: 0.0698758662 |██████████████████--| 92.0%  - val_loss: 1007.5132751465 - val_trvae_loss: 1007.5131835938 - val_landmark_loss: 0.0000898781 - val_unlabeled_loss: 0.0898781195 |██████████████████--| 93.0%  - val_loss: 975.6040954590 - val_trvae_loss: 975.6040039062 - val_landmark_loss: 0.0000723629 - val_unlabeled_loss: 0.0723629147 |██████████████████--| 94.0%  - val_loss: 1113.8676147461 - val_trvae_loss: 1113.8674926758 - val_landmark_loss: 0.0001021712 - val_unlabeled_loss: 0.1021711975 |███████████████████-| 95.0%  - val_loss: 942.5837707520 - val_trvae_loss: 942.5836791992 - val_landmark_loss: 0.0000806014 - val_unlabeled_loss: 0.0806014128 |███████████████████-| 96.0%  - val_loss: 1091.4598388672 - val_trvae_loss: 1091.4597167969 - val_landmark_loss: 0.0001150073 - val_unlabeled_loss: 0.1150072515 |███████████████████-| 97.0%  - val_loss: 1114.4915771484 - val_trvae_loss: 1114.4914550781 - val_landmark_loss: 0.0000997170 - val_unlabeled_loss: 0.0997170284 |███████████████████-| 98.0%  - val_loss: 964.9224853516 - val_trvae_loss: 964.9223937988 - val_landmark_loss: 0.0000781038 - val_unlabeled_loss: 0.0781038180 |███████████████████-| 99.0%  - val_loss: 983.0233154297 - val_trvae_loss: 983.0232238770 - val_landmark_loss: 0.0000806851 - val_unlabeled_loss: 0.0806851089 |████████████████████| 100.0%  - val_loss: 1011.4270629883 - val_trvae_loss: 1011.4269409180 - val_landmark_loss: 0.0000977633 - val_unlabeled_loss: 0.0977633148
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 10:59:55 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 10:59:55 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
slurmstepd: error: *** JOB 3781267 ON gpusrv09 CANCELLED AT 2021-10-26T11:01:37 ***
