Starting job 3782799
SLURM assigned me the node(s): gpusrv16
Experiments are running under the following process IDs:
Experiment ID: 6	Process ID: 15681

During startup - Warning messages:
1: package ‘methods’ was built under R version 3.6.3 
2: package ‘datasets’ was built under R version 3.6.3 
3: package ‘utils’ was built under R version 3.6.3 
4: package ‘grDevices’ was built under R version 3.6.3 
5: package ‘graphics’ was built under R version 3.6.3 
6: package ‘stats’ was built under R version 3.6.3 
2021-10-26 15:16:06 (INFO): Running command 'run'
2021-10-26 15:16:06 (INFO): Started run with ID "6"
2021-10-26 15:16:09 (INFO): Data loaded succesfully
2021-10-26 15:16:09 (INFO): Model instantiated
Embedding dictionary:
 	Num conditions: 3
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 1151.8019086052 - val_trvae_loss: 1151.8019086052 |--------------------| 2.0%  - val_loss: 1114.3826976103 - val_trvae_loss: 1114.3826976103 |--------------------| 3.0%  - val_loss: 1100.0183464499 - val_trvae_loss: 1100.0183464499 |--------------------| 4.0%  - val_loss: 1092.7154433307 - val_trvae_loss: 1092.7154433307 |█-------------------| 5.0%  - val_loss: 1085.9452335133 - val_trvae_loss: 1085.9452335133 |█-------------------| 6.0%  - val_loss: 1080.7069594439 - val_trvae_loss: 1080.7069594439 |█-------------------| 7.0%  - val_loss: 1077.7470379998 - val_trvae_loss: 1077.7470379998 |█-------------------| 8.0%  - val_loss: 1073.6355913948 - val_trvae_loss: 1073.6355913948 |█-------------------| 9.0%  - val_loss: 1071.5296559053 - val_trvae_loss: 1071.5296559053 |██------------------| 10.0%  - val_loss: 1069.1483692842 - val_trvae_loss: 1069.1483692842 |██------------------| 11.0%  - val_loss: 1067.9244277057 - val_trvae_loss: 1067.9244277057 |██------------------| 12.0%  - val_loss: 1067.6706291648 - val_trvae_loss: 1067.6706291648 |██------------------| 13.0%  - val_loss: 1066.6769157858 - val_trvae_loss: 1066.6769157858 |██------------------| 14.0%  - val_loss: 1064.6879057043 - val_trvae_loss: 1064.6879057043 |███-----------------| 15.0%  - val_loss: 1064.4941513959 - val_trvae_loss: 1064.4941513959 |███-----------------| 16.0%  - val_loss: 1063.3507223690 - val_trvae_loss: 1063.3507223690 |███-----------------| 17.0%  - val_loss: 1062.5061035156 - val_trvae_loss: 1062.5061035156 |███-----------------| 18.0%  - val_loss: 1061.9703369141 - val_trvae_loss: 1061.9703369141 |███-----------------| 19.0%  - val_loss: 1061.4960470761 - val_trvae_loss: 1061.4960470761 |████----------------| 20.0%  - val_loss: 1062.4203993853 - val_trvae_loss: 1062.4203993853 |████----------------| 21.0%  - val_loss: 1061.4015215705 - val_trvae_loss: 1061.4015215705 |████----------------| 22.0%  - val_loss: 1060.4669656193 - val_trvae_loss: 1060.4669656193 |████----------------| 23.0%  - val_loss: 1060.2433723001 - val_trvae_loss: 1060.2433723001 |████----------------| 24.0%  - val_loss: 1059.4739200368 - val_trvae_loss: 1059.4739200368 |█████---------------| 25.0%  - val_loss: 1060.2590583352 - val_trvae_loss: 1060.2590583352 |█████---------------| 26.0%  - val_loss: 1059.1272367590 - val_trvae_loss: 1059.1272367590 |█████---------------| 27.0%  - val_loss: 1058.7886173024 - val_trvae_loss: 1058.7886173024 |█████---------------| 28.0%  - val_loss: 1058.1210398955 - val_trvae_loss: 1058.1210398955 |█████---------------| 29.0%  - val_loss: 1058.1894387638 - val_trvae_loss: 1058.1894387638 |██████--------------| 30.0%  - val_loss: 1062.0438088810 - val_trvae_loss: 1062.0438088810 |██████--------------| 31.0%  - val_loss: 1059.6655345244 - val_trvae_loss: 1059.6655345244 |██████--------------| 32.0%  - val_loss: 1058.9413488051 - val_trvae_loss: 1058.9413488051 |██████--------------| 33.0%  - val_loss: 1058.3220430262 - val_trvae_loss: 1058.3220430262 |██████--------------| 34.0%  - val_loss: 1058.1689273610 - val_trvae_loss: 1058.1689273610 |███████-------------| 35.0%  - val_loss: 1057.8507762236 - val_trvae_loss: 1057.8507762236 |███████-------------| 36.0%  - val_loss: 1057.7129049862 - val_trvae_loss: 1057.7129049862 |███████-------------| 37.0%  - val_loss: 1057.6955063764 - val_trvae_loss: 1057.6955063764 |███████-------------| 38.0%  - val_loss: 1057.7913997875 - val_trvae_loss: 1057.7913997875 |███████-------------| 39.0%  - val_loss: 1056.8274607939 - val_trvae_loss: 1056.8274607939 |████████------------| 40.0%  - val_loss: 1057.4203527114 - val_trvae_loss: 1057.4203527114 |████████------------| 41.0%  - val_loss: 1057.2299984203 - val_trvae_loss: 1057.2299984203 |████████------------| 42.0%  - val_loss: 1057.5964750402 - val_trvae_loss: 1057.5964750402 |████████------------| 43.0%  - val_loss: 1057.6305577895 - val_trvae_loss: 1057.6305577895 |████████------------| 44.0%  - val_loss: 1056.9361859490 - val_trvae_loss: 1056.9361859490 |█████████-----------| 45.0%  - val_loss: 1057.0970351275 - val_trvae_loss: 1057.0970351275 |█████████-----------| 46.0%  - val_loss: 1057.8487764246 - val_trvae_loss: 1057.8487764246 |█████████-----------| 47.0%  - val_loss: 1057.4791834214 - val_trvae_loss: 1057.4791834214 |█████████-----------| 48.0%  - val_loss: 1057.1387436811 - val_trvae_loss: 1057.1387436811 |█████████-----------| 49.0%  - val_loss: 1056.3336648380 - val_trvae_loss: 1056.3336648380 |██████████----------| 50.0%  - val_loss: 1056.6512487075 - val_trvae_loss: 1056.6512487075 |██████████----------| 51.0%  - val_loss: 1056.3981825885 - val_trvae_loss: 1056.3981825885 |██████████----------| 52.0%  - val_loss: 1062.4145005170 - val_trvae_loss: 1062.4145005170 |██████████----------| 53.0%  - val_loss: 1056.7249109605 - val_trvae_loss: 1056.7249109605 |██████████----------| 54.0%  - val_loss: 1056.0441894531 - val_trvae_loss: 1056.0441894531 |███████████---------| 55.0%  - val_loss: 1056.1924294864 - val_trvae_loss: 1056.1924294864 |███████████---------| 56.0%  - val_loss: 1056.1206090591 - val_trvae_loss: 1056.1206090591 |███████████---------| 57.0%  - val_loss: 1057.6501500747 - val_trvae_loss: 1057.6501500747 |███████████---------| 58.0%  - val_loss: 1056.5723912856 - val_trvae_loss: 1056.5723912856 |███████████---------| 59.0%  - val_loss: 1056.0308263442 - val_trvae_loss: 1056.0308263442 |████████████--------| 60.0%  - val_loss: 1055.9795388614 - val_trvae_loss: 1055.9795388614 |████████████--------| 61.0%  - val_loss: 1055.9517714557 - val_trvae_loss: 1055.9517714557 |████████████--------| 62.0%  - val_loss: 1056.3096421186 - val_trvae_loss: 1056.3096421186 |████████████--------| 63.0%  - val_loss: 1056.2975392061 - val_trvae_loss: 1056.2975392061 |████████████--------| 64.0%  - val_loss: 1055.5491584329 - val_trvae_loss: 1055.5491584329 |█████████████-------| 65.0%  - val_loss: 1055.6047147863 - val_trvae_loss: 1055.6047147863 |█████████████-------| 66.0%  - val_loss: 1055.4877175724 - val_trvae_loss: 1055.4877175724 |█████████████-------| 67.0%  - val_loss: 1056.9767815085 - val_trvae_loss: 1056.9767815085 |█████████████-------| 68.0%  - val_loss: 1055.2130557790 - val_trvae_loss: 1055.2130557790 |█████████████-------| 69.0%  - val_loss: 1056.7088299920 - val_trvae_loss: 1056.7088299920 |██████████████------| 70.0%  - val_loss: 1055.9502060834 - val_trvae_loss: 1055.9502060834 |██████████████------| 71.0%  - val_loss: 1055.1123729033 - val_trvae_loss: 1055.1123729033 |██████████████------| 72.0%  - val_loss: 1055.2567318187 - val_trvae_loss: 1055.2567318187 |██████████████------| 73.0%  - val_loss: 1054.9227151310 - val_trvae_loss: 1054.9227151310 |██████████████------| 74.0%  - val_loss: 1055.2974314970 - val_trvae_loss: 1055.2974314970 |███████████████-----| 75.0%  - val_loss: 1055.4765337776 - val_trvae_loss: 1055.4765337776 |███████████████-----| 76.0%  - val_loss: 1056.2707268210 - val_trvae_loss: 1056.2707268210 |███████████████-----| 77.0%  - val_loss: 1054.8828412224 - val_trvae_loss: 1054.8828412224 |███████████████-----| 78.0%  - val_loss: 1054.7257726333 - val_trvae_loss: 1054.7257726333 |███████████████-----| 79.0%  - val_loss: 1056.5498262293 - val_trvae_loss: 1056.5498262293 |████████████████----| 80.0%  - val_loss: 1054.7184196921 - val_trvae_loss: 1054.7184196921 |████████████████----| 81.0%  - val_loss: 1077.0000897576 - val_trvae_loss: 1062.0579762178 - val_landmark_loss: 14.9421121373 - val_labeled_loss: 14.9421121373 |████████████████----| 82.0%  - val_loss: 1071.2901324104 - val_trvae_loss: 1060.4900907629 - val_landmark_loss: 10.8000362060 - val_labeled_loss: 10.8000362060 |████████████████----| 83.0%  - val_loss: 1068.9523064108 - val_trvae_loss: 1059.6758315142 - val_landmark_loss: 9.2764837041 - val_labeled_loss: 9.2764837041 |████████████████----| 84.0%  - val_loss: 1067.3323902803 - val_trvae_loss: 1058.7184986788 - val_landmark_loss: 8.6139001145 - val_labeled_loss: 8.6139001145 |█████████████████---| 85.0%  - val_loss: 1066.0575058881 - val_trvae_loss: 1059.0276166131 - val_landmark_loss: 7.0298838475 - val_labeled_loss: 7.0298838475 |█████████████████---| 86.0%  - val_loss: 1068.8691226735 - val_trvae_loss: 1060.4231280159 - val_landmark_loss: 8.4459818812 - val_labeled_loss: 8.4459818812 |█████████████████---| 87.0%  - val_loss: 1067.0840669520 - val_trvae_loss: 1059.2207103056 - val_landmark_loss: 7.8633624245 - val_labeled_loss: 7.8633624245 |█████████████████---| 88.0%  - val_loss: 1064.6693905101 - val_trvae_loss: 1058.1813605813 - val_landmark_loss: 6.4880284422 - val_labeled_loss: 6.4880284422 |█████████████████---| 89.0%  - val_loss: 1064.5843075023 - val_trvae_loss: 1058.5661764706 - val_landmark_loss: 6.0181234023 - val_labeled_loss: 6.0181234023 |██████████████████--| 90.0%  - val_loss: 1063.5569709329 - val_trvae_loss: 1057.9188519646 - val_landmark_loss: 5.6381013674 - val_labeled_loss: 5.6381013674 |██████████████████--| 91.0%  - val_loss: 1063.6002448587 - val_trvae_loss: 1058.3471284754 - val_landmark_loss: 5.2531214812 - val_labeled_loss: 5.2531214812 |██████████████████--| 92.0%  - val_loss: 1063.2999123966 - val_trvae_loss: 1058.2702600816 - val_landmark_loss: 5.0296573358 - val_labeled_loss: 5.0296573358 |██████████████████--| 93.0%  - val_loss: 1062.6095329733 - val_trvae_loss: 1057.8038653205 - val_landmark_loss: 4.8056622463 - val_labeled_loss: 4.8056622463 |██████████████████--| 94.0%  - val_loss: 1062.4813232422 - val_trvae_loss: 1057.6704532399 - val_landmark_loss: 4.8108651498 - val_labeled_loss: 4.8108651498 |███████████████████-| 95.0%  - val_loss: 1062.2590475643 - val_trvae_loss: 1057.7176226448 - val_landmark_loss: 4.5414154459 - val_labeled_loss: 4.5414154459 |███████████████████-| 96.0%  - val_loss: 1062.0572437960 - val_trvae_loss: 1057.7796020508 - val_landmark_loss: 4.2776305605 - val_labeled_loss: 4.2776305605 |███████████████████-| 97.0%  - val_loss: 1062.4834846048 - val_trvae_loss: 1058.7015632181 - val_landmark_loss: 3.7819337985 - val_labeled_loss: 3.7819337985 |███████████████████-| 98.0%  - val_loss: 1073.6867137236 - val_trvae_loss: 1069.4256986730 - val_landmark_loss: 4.2610097633 - val_labeled_loss: 4.2610097633 |███████████████████-| 99.0%  - val_loss: 1060.6633228975 - val_trvae_loss: 1057.1304034065 - val_landmark_loss: 3.5329102558 - val_labeled_loss: 3.5329102558 |████████████████████| 100.0%  - val_loss: 1064.5922025793 - val_trvae_loss: 1061.0652358111 - val_landmark_loss: 3.5269784226 - val_labeled_loss: 3.5269784226
2021-10-26 15:19:04 (INFO): Model trained and saved, initiate surgery
Saving best state of network...
Best State was in Epoch 99
AnnData object with n_obs × n_vars = 10727 × 4000
    obs: 'study', 'condition', 'cell_type', 'pred_label', 'pred_score'
    obsm: 'X_seurat', 'X_symphony'
Embedding dictionary:
 	Num conditions: 4
 	Embedding dim: 10
Encoder Architecture:
	Input Layer in, out and cond: 4000 128 0
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Mean/Var Layer in/out: 128 25
Decoder Architecture:
	First Layer in, out and cond:  25 128 10
	Hidden Layer 1 in/out: 128 128
	Hidden Layer 2 in/out: 128 128
	Output Layer in/out:  128 4000 

 |--------------------| 1.0%  - val_loss: 2057.3769531250 - val_trvae_loss: 2057.3769531250 |--------------------| 2.0%  - val_loss: 2050.6068929036 - val_trvae_loss: 2050.6068929036 |--------------------| 3.0%  - val_loss: 2048.5466172960 - val_trvae_loss: 2048.5466172960 |--------------------| 4.0%  - val_loss: 2048.9117838542 - val_trvae_loss: 2048.9117838542 |█-------------------| 5.0%  - val_loss: 2040.2877468533 - val_trvae_loss: 2040.2877468533 |█-------------------| 6.0%  - val_loss: 2025.6353488498 - val_trvae_loss: 2025.6353488498 |█-------------------| 7.0%  - val_loss: 2031.3702392578 - val_trvae_loss: 2031.3702392578 |█-------------------| 8.0%  - val_loss: 2013.7406141493 - val_trvae_loss: 2013.7406141493 |█-------------------| 9.0%  - val_loss: 2028.5876736111 - val_trvae_loss: 2028.5876736111 |██------------------| 10.0%  - val_loss: 2012.5309651693 - val_trvae_loss: 2012.5309651693 |██------------------| 11.0%  - val_loss: 2001.1595594618 - val_trvae_loss: 2001.1595594618 |██------------------| 12.0%  - val_loss: 2004.9045003255 - val_trvae_loss: 2004.9045003255 |██------------------| 13.0%  - val_loss: 2012.3943006727 - val_trvae_loss: 2012.3943006727 |██------------------| 14.0%  - val_loss: 1998.7759467231 - val_trvae_loss: 1998.7759467231 |███-----------------| 15.0%  - val_loss: 2012.2010633681 - val_trvae_loss: 2012.2010633681 |███-----------------| 16.0%  - val_loss: 1999.7635904948 - val_trvae_loss: 1999.7635904948 |███-----------------| 17.0%  - val_loss: 2009.8257649740 - val_trvae_loss: 2009.8257649740 |███-----------------| 18.0%  - val_loss: 1994.6147867839 - val_trvae_loss: 1994.6147867839 |███-----------------| 19.0%  - val_loss: 1996.0126139323 - val_trvae_loss: 1996.0126139323 |████----------------| 20.0%  - val_loss: 1990.5362955729 - val_trvae_loss: 1990.5362955729 |████----------------| 21.0%  - val_loss: 1989.9773898655 - val_trvae_loss: 1989.9773898655 |████----------------| 22.0%  - val_loss: 1978.7573377821 - val_trvae_loss: 1978.7573377821 |████----------------| 23.0%  - val_loss: 1989.8249511719 - val_trvae_loss: 1989.8249511719 |████----------------| 24.0%  - val_loss: 1978.5917426215 - val_trvae_loss: 1978.5917426215 |█████---------------| 25.0%  - val_loss: 1978.6143934462 - val_trvae_loss: 1978.6143934462 |█████---------------| 26.0%  - val_loss: 1974.0244683160 - val_trvae_loss: 1974.0244683160 |█████---------------| 27.0%  - val_loss: 1971.5647786458 - val_trvae_loss: 1971.5647786458 |█████---------------| 28.0%  - val_loss: 1971.9555257161 - val_trvae_loss: 1971.9555257161 |█████---------------| 29.0%  - val_loss: 1984.3761528863 - val_trvae_loss: 1984.3761528863 |██████--------------| 30.0%  - val_loss: 1982.0420464410 - val_trvae_loss: 1982.0420464410 |██████--------------| 31.0%  - val_loss: 1986.3765869141 - val_trvae_loss: 1986.3765869141 |██████--------------| 32.0%  - val_loss: 1974.9904513889 - val_trvae_loss: 1974.9904513889 |██████--------------| 33.0%  - val_loss: 1982.5279134115 - val_trvae_loss: 1982.5279134115 |██████--------------| 34.0%  - val_loss: 1982.3592800564 - val_trvae_loss: 1982.3592800564 |███████-------------| 35.0%  - val_loss: 1965.6353081597 - val_trvae_loss: 1965.6353081597 |███████-------------| 36.0%  - val_loss: 1963.5494520399 - val_trvae_loss: 1963.5494520399 |███████-------------| 37.0%  - val_loss: 1982.9222683377 - val_trvae_loss: 1982.9222683377 |███████-------------| 38.0%  - val_loss: 1973.2101372613 - val_trvae_loss: 1973.2101372613 |███████-------------| 39.0%  - val_loss: 1964.5291476780 - val_trvae_loss: 1964.5291476780 |████████------------| 40.0%  - val_loss: 1953.3246392144 - val_trvae_loss: 1953.3246392144 |████████------------| 41.0%  - val_loss: 1964.8468424479 - val_trvae_loss: 1964.8468424479 |████████------------| 42.0%  - val_loss: 1958.9804009332 - val_trvae_loss: 1958.9804009332 |████████------------| 43.0%  - val_loss: 1967.8758951823 - val_trvae_loss: 1967.8758951823 |████████------------| 44.0%  - val_loss: 1965.7685682509 - val_trvae_loss: 1965.7685682509 |█████████-----------| 45.0%  - val_loss: 1970.9318576389 - val_trvae_loss: 1970.9318576389 |█████████-----------| 46.0%  - val_loss: 1959.4503038194 - val_trvae_loss: 1959.4503038194 |█████████-----------| 47.0%  - val_loss: 1961.3274332682 - val_trvae_loss: 1961.3274332682 |█████████-----------| 48.0%  - val_loss: 1959.7876519097 - val_trvae_loss: 1959.7876519097 |█████████-----------| 49.0%  - val_loss: 1953.9494222005 - val_trvae_loss: 1953.9494222005 |██████████----------| 50.0%  - val_loss: 1952.7208794488 - val_trvae_loss: 1952.7208794488 |██████████----------| 51.0%  - val_loss: 1964.2646484375 - val_trvae_loss: 1964.2646484375 |██████████----------| 52.0%  - val_loss: 1952.7001274957 - val_trvae_loss: 1952.7001274957 |██████████----------| 53.0%  - val_loss: 1967.8123372396 - val_trvae_loss: 1967.8123372396 |██████████----------| 54.0%  - val_loss: 1968.8481852214 - val_trvae_loss: 1968.8481852214 |███████████---------| 55.0%  - val_loss: 1960.5722520616 - val_trvae_loss: 1960.5722520616 |███████████---------| 56.0%  - val_loss: 1960.0983751085 - val_trvae_loss: 1960.0983751085 |███████████---------| 57.0%  - val_loss: 1950.3173421224 - val_trvae_loss: 1950.3173421224 |███████████---------| 58.0%  - val_loss: 1964.1152479384 - val_trvae_loss: 1964.1152479384 |███████████---------| 59.0%  - val_loss: 1958.2890218099 - val_trvae_loss: 1958.2890218099 |████████████--------| 60.0%  - val_loss: 1962.4552951389 - val_trvae_loss: 1962.4552951389 |████████████--------| 61.0%  - val_loss: 1956.2023111979 - val_trvae_loss: 1956.2023111979 |████████████--------| 62.0%  - val_loss: 1949.0607096354 - val_trvae_loss: 1949.0607096354 |████████████--------| 63.0%  - val_loss: 1951.4938964844 - val_trvae_loss: 1951.4938964844 |████████████--------| 64.0%  - val_loss: 1948.0678168403 - val_trvae_loss: 1948.0678168403 |█████████████-------| 65.0%  - val_loss: 1954.4396701389 - val_trvae_loss: 1954.4396701389 |█████████████-------| 66.0%  - val_loss: 1952.4474555122 - val_trvae_loss: 1952.4474555122 |█████████████-------| 67.0%  - val_loss: 1963.8731418186 - val_trvae_loss: 1963.8731418186 |█████████████-------| 68.0%  - val_loss: 1941.4108886719 - val_trvae_loss: 1941.4108886719 |█████████████-------| 69.0%  - val_loss: 1957.9604763455 - val_trvae_loss: 1957.9604763455 |██████████████------| 70.0%  - val_loss: 1955.1061333550 - val_trvae_loss: 1955.1061333550 |██████████████------| 71.0%  - val_loss: 1959.9238281250 - val_trvae_loss: 1959.9238281250 |██████████████------| 72.0%  - val_loss: 1971.9384358724 - val_trvae_loss: 1971.9384358724 |██████████████------| 73.0%  - val_loss: 1969.7977837457 - val_trvae_loss: 1969.7977837457 |██████████████------| 74.0%  - val_loss: 1952.2864040799 - val_trvae_loss: 1952.2864040799 |███████████████-----| 75.0%  - val_loss: 1952.5960015191 - val_trvae_loss: 1952.5960015191 |███████████████-----| 76.0%  - val_loss: 1972.8635525174 - val_trvae_loss: 1972.8635525174 |███████████████-----| 77.0%  - val_loss: 1957.7478976780 - val_trvae_loss: 1957.7478976780 |███████████████-----| 78.0%  - val_loss: 1948.3282877604 - val_trvae_loss: 1948.3282877604 |███████████████-----| 79.0%  - val_loss: 1967.3924831814 - val_trvae_loss: 1967.3924831814 |████████████████----| 80.0%  - val_loss: 1958.5455864800 - val_trvae_loss: 1958.5455864800
Initializing unlabeled landmarks with Leiden-Clustering with an unknown number of clusters.
Leiden Clustering succesful. Found 23 clusters.
 |████████████████----| 81.0%  - val_loss: 1966.8262939453 - val_trvae_loss: 1966.8261854384 - val_landmark_loss: 0.0001258016 - val_unlabeled_loss: 0.1258015964 |████████████████----| 82.0%  - val_loss: 1957.0173339844 - val_trvae_loss: 1957.0172119141 - val_landmark_loss: 0.0001181661 - val_unlabeled_loss: 0.1181660601 |████████████████----| 83.0%  - val_loss: 1954.6076795790 - val_trvae_loss: 1954.6075303819 - val_landmark_loss: 0.0001250543 - val_unlabeled_loss: 0.1250542949 |████████████████----| 84.0%  - val_loss: 1950.7991129557 - val_trvae_loss: 1950.7989773220 - val_landmark_loss: 0.0001218623 - val_unlabeled_loss: 0.1218622468 |█████████████████---| 85.0%  - val_loss: 1945.6010606554 - val_trvae_loss: 1945.6009250217 - val_landmark_loss: 0.0001203840 - val_unlabeled_loss: 0.1203840300 |█████████████████---| 86.0%  - val_loss: 1951.9430474175 - val_trvae_loss: 1951.9429253472 - val_landmark_loss: 0.0001194609 - val_unlabeled_loss: 0.1194608994 |█████████████████---| 87.0%  - val_loss: 1963.8244222005 - val_trvae_loss: 1963.8242865668 - val_landmark_loss: 0.0001157844 - val_unlabeled_loss: 0.1157843942 |█████████████████---| 88.0%  - val_loss: 1951.4834255642 - val_trvae_loss: 1951.4833170573 - val_landmark_loss: 0.0001228104 - val_unlabeled_loss: 0.1228104105 |█████████████████---| 89.0%  - val_loss: 1964.9165988498 - val_trvae_loss: 1964.9164767795 - val_landmark_loss: 0.0001177865 - val_unlabeled_loss: 0.1177864745 |██████████████████--| 90.0%  - val_loss: 1965.0389133030 - val_trvae_loss: 1965.0387912326 - val_landmark_loss: 0.0001380668 - val_unlabeled_loss: 0.1380668092 |██████████████████--| 91.0%  - val_loss: 1946.0012885200 - val_trvae_loss: 1946.0011257595 - val_landmark_loss: 0.0001318222 - val_unlabeled_loss: 0.1318221655 |██████████████████--| 92.0%  - val_loss: 1948.7077229818 - val_trvae_loss: 1948.7075737847 - val_landmark_loss: 0.0001273444 - val_unlabeled_loss: 0.1273443749 |██████████████████--| 93.0%  - val_loss: 1944.2545708550 - val_trvae_loss: 1944.2544487847 - val_landmark_loss: 0.0001181959 - val_unlabeled_loss: 0.1181958599 |██████████████████--| 94.0%  - val_loss: 1960.3785264757 - val_trvae_loss: 1960.3783908420 - val_landmark_loss: 0.0001252079 - val_unlabeled_loss: 0.1252078497 |███████████████████-| 95.0%  - val_loss: 1964.6112874349 - val_trvae_loss: 1964.6111382378 - val_landmark_loss: 0.0001313853 - val_unlabeled_loss: 0.1313853198 |███████████████████-| 96.0%  - val_loss: 1972.1727294922 - val_trvae_loss: 1972.1726345486 - val_landmark_loss: 0.0001246331 - val_unlabeled_loss: 0.1246331392 |███████████████████-| 97.0%  - val_loss: 1955.1930745443 - val_trvae_loss: 1955.1929253472 - val_landmark_loss: 0.0001140054 - val_unlabeled_loss: 0.1140054026 |███████████████████-| 98.0%  - val_loss: 1964.6142171224 - val_trvae_loss: 1964.6140814887 - val_landmark_loss: 0.0001249176 - val_unlabeled_loss: 0.1249176015 |███████████████████-| 99.0%  - val_loss: 1956.4802110460 - val_trvae_loss: 1956.4800754123 - val_landmark_loss: 0.0001225308 - val_unlabeled_loss: 0.1225308412 |████████████████████| 100.0%  - val_loss: 1957.4296061198 - val_trvae_loss: 1957.4294840495 - val_landmark_loss: 0.0001288633 - val_unlabeled_loss: 0.1288633347
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y, hue. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
2021-10-26 15:20:23 (INFO): Computing metrics
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/icb/carlo.dedonno/anaconda3/envs/lataq_cuda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-10-26 15:20:25 (INFO): Compute integration metrics
... storing 'study' as categorical
... storing 'cell_type' as categorical
2021-10-26 15:34:46 (INFO): Result: {'distances':   condition      dist
0    Oetjen  1.175874
1       Sun  1.139458
2   Freytag  0.399234
3       10X  0.399234, 'classification_report':                                   precision    recall  f1-score      support
CD10+ B cells                      0.985714  1.000000  0.992806    207.00000
CD14+ Monocytes                    0.985732  0.981067  0.983394   6338.00000
CD16+ Monocytes                    0.971951  0.966061  0.968997    825.00000
CD20+ B cells                      0.995477  0.995823  0.995650   2873.00000
CD4+ T cells                       0.945161  0.925075  0.935010  11011.00000
CD8+ T cells                       0.704683  0.744388  0.723992   2183.00000
Erythrocytes                       0.982003  0.835553  0.902878   1502.00000
Erythroid progenitors              0.610698  0.887689  0.723592    463.00000
HSPCs                              0.940574  0.970402  0.955255    473.00000
Megakaryocyte progenitors          0.757764  0.903704  0.824324    270.00000
Monocyte progenitors               0.770713  0.934579  0.844773    428.00000
Monocyte-derived dendritic cells   0.953086  0.807531  0.874292    478.00000
NK cells                           0.963656  0.785963  0.865786   2294.00000
NKT cells                          0.795805  0.939891  0.861867   2745.00000
Plasma cells                       0.984252  0.968992  0.976562    129.00000
Plasmacytoid dendritic cells       0.992424  0.988679  0.990548    265.00000
accuracy                           0.917960  0.917960  0.917960      0.91796
macro avg                          0.896231  0.914712  0.901233  32484.00000
weighted avg                       0.924661  0.917960  0.919206  32484.00000, 'classification_report_query':                                   precision    recall  f1-score       support
CD14+ Monocytes                    0.984178  0.991440  0.987796   3388.000000
CD16+ Monocytes                    0.936639  0.934066  0.935351    364.000000
CD20+ B cells                      0.997408  0.995472  0.996439   1546.000000
CD4+ T cells                       0.985381  0.963909  0.974527   2937.000000
CD8+ T cells                       0.774942  0.954286  0.855314    350.000000
HSPCs                              0.657143  0.821429  0.730159     28.000000
Megakaryocyte progenitors          0.437500  1.000000  0.608696     21.000000
Monocyte progenitors               0.000000  0.000000  0.000000      0.000000
Monocyte-derived dendritic cells   0.991803  0.664835  0.796053    182.000000
NK cells                           1.000000  0.743386  0.852807    756.000000
NKT cells                          0.804758  0.928977  0.862418   1056.000000
Plasma cells                       1.000000  0.777778  0.875000     18.000000
Plasmacytoid dendritic cells       1.000000  0.987654  0.993789     81.000000
accuracy                           0.951338  0.951338  0.951338      0.951338
macro avg                          0.813058  0.827941  0.805257  10727.000000
weighted avg                       0.959778  0.951338  0.952638  10727.000000, 'integration_scores':    NMI_cluster/label  ARI_cluster/label  ...  isolated_label_silhouette  graph_conn
0           0.864193           0.857778  ...                   0.592919    0.993437

[1 rows x 8 columns]}
2021-10-26 15:34:46 (INFO): Completed after 0:18:40
Saving best state of network...
Best State was in Epoch 96
NMI...
ARI...
Silhouette score...
PC regression...
Isolated labels F1...
Isolated labels ASW...
Graph connectivity...
