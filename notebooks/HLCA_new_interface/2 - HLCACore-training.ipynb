{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79e232e-722d-40d2-b67b-c26c30617bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319d7f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "INFO:lightning_fabric.utilities.seed:[rank: 0] Global seed set to 0\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
      "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scarches.dataset.trvae.data_handling import remove_sparsity\n",
    "from scarches.models.scpoli import scPoli\n",
    "\n",
    "sc.settings.set_figure_params(dpi=200, frameon=False)\n",
    "sc.set_figure_params(dpi=500)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb191609",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_key = 'sample'\n",
    "cell_type_key = ['ann_finest_level']\n",
    "\n",
    "Path(os.path.expanduser(\"~/io/scpoli_repr/scpoli_models/\")).mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_format = os.path.expanduser(\"~/io/scpoli_repr/scpoli_models/hlca_core_sample_{replicate}{ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4afba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'EPOCHS': 50,                                      #TOTAL TRAINING EPOCHS\n",
    "    'N_PRE_EPOCHS': 40,                                #EPOCHS OF PRETRAINING WITHOUT LANDMARK LOSS\n",
    "    #'DATA_DIR': '../../lataq_reproduce/data',          #DIRECTORY WHERE THE DATA IS STORED\n",
    "    #'DATA': 'pancreas',                                #DATA USED FOR THE EXPERIMENT\n",
    "    'EARLY_STOPPING_KWARGS': {                         #KWARGS FOR EARLY STOPPING\n",
    "        \"early_stopping_metric\": \"val_prototype_loss\",  ####value used for early stopping\n",
    "        \"mode\": \"min\",                                 ####choose if look for min or max\n",
    "        \"threshold\": 0,\n",
    "        \"patience\": 20,\n",
    "        \"reduce_lr\": True,\n",
    "        \"lr_patience\": 13,\n",
    "        \"lr_factor\": 0.1,\n",
    "    },\n",
    "    'LABELED_LOSS_METRIC': 'dist',           \n",
    "    'UNLABELED_LOSS_METRIC': 'dist',\n",
    "    'LATENT_DIM': 50,\n",
    "    'ALPHA_EPOCH_ANNEAL': 1e3,\n",
    "    'CLUSTERING_RES': 2,\n",
    "    'HIDDEN_LAYERS': 4,\n",
    "    'ETA': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6c58bb-3cc5-45fe-ade4-1dcfd730699b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 584884 × 1897\n",
       "    obs: 'is_primary_data', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'ethnicity_ontology_term_id', 'tissue_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', 'sample', 'study', 'subject_ID', 'smoking_status', 'BMI', 'condition', 'subject_type', 'sample_type', \"3'_or_5'\", 'sequencing_platform', 'cell_ranger_version', 'fresh_or_frozen', 'dataset', 'anatomical_region_level_2', 'anatomical_region_level_3', 'anatomical_region_highest_res', 'age', 'ann_highest_res', 'n_genes', 'size_factors', 'log10_total_counts', 'mito_frac', 'ribo_frac', 'original_ann_level_1', 'original_ann_level_2', 'original_ann_level_3', 'original_ann_level_4', 'original_ann_level_5', 'original_ann_nonharmonized', 'scanvi_label', 'leiden_1', 'leiden_2', 'leiden_3', 'anatomical_region_ccf_score', 'entropy_study_leiden_3', 'entropy_dataset_leiden_3', 'entropy_subject_ID_leiden_3', 'entropy_original_ann_level_1_leiden_3', 'entropy_original_ann_level_2_clean_leiden_3', 'entropy_original_ann_level_3_clean_leiden_3', 'entropy_original_ann_level_4_clean_leiden_3', 'entropy_original_ann_level_5_clean_leiden_3', 'leiden_4', 'reannotation_type', 'leiden_5', 'ann_finest_level', 'ann_level_1', 'ann_level_2', 'ann_level_3', 'ann_level_4', 'ann_level_5', 'ann_coarse_for_GWAS_and_modeling', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'ethnicity', 'development_stage'\n",
       "    var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'feature_biotype', 'feature_is_filtered', 'feature_reference'\n",
       "    uns: 'X_normalization', 'batch_condition', 'contributors', 'default_embedding', 'schema_version', 'title'\n",
       "    obsm: 'X_scanvi_emb', 'X_umap'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read(os.path.expanduser('~/io/scpoli_repr/hlca_counts_commonvars.h5ad'))\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8249600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study\n",
       "Banovich_Kropski_2020     121881\n",
       "Barbry_Leroy_2020          74486\n",
       "Jain_Misharin_2021         45557\n",
       "Krasnow_2020               60977\n",
       "Lafyatis_Rojas_2019        24180\n",
       "Meyer_2019                 35522\n",
       "Misharin_2021              64842\n",
       "Misharin_Budinger_2018     41216\n",
       "Nawijn_2021                70401\n",
       "Seibold_2020               33593\n",
       "Teichmann_Meyer_2019       12229\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.groupby('study').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10cd7f62-d0de-4d60-a4ad-f4ff745abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d425b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate  0\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |████████████████████| 100.0%  - val_loss: 608.3992461824 - val_cvae_loss: 598.7960665847 - val_prototype_loss: 9.6031794496 - val_labeled_loss: 9.60317944965\n",
      "Replicate  1\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |████████████████████| 100.0%  - val_loss: 607.1993153111 - val_cvae_loss: 597.1445000646 - val_prototype_loss: 10.0548166801 - val_labeled_loss: 10.0548166801\n",
      "Replicate  2\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |████████████████████| 100.0%  - val_loss: 609.0290640866 - val_cvae_loss: 599.8964471128 - val_prototype_loss: 9.1326172232 - val_labeled_loss: 9.13261722327\n",
      "Replicate  3\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |████████████████████| 100.0%  - val_loss: 606.0518882968 - val_cvae_loss: 597.3475833951 - val_prototype_loss: 8.7043036762 - val_labeled_loss: 8.70430367628\n",
      "Replicate  4\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |████████████████████| 100.0%  - val_loss: 606.7396762439 - val_cvae_loss: 598.5667000735 - val_prototype_loss: 8.1729758151 - val_labeled_loss: 8.17297581516\n",
      "Replicate  5\n",
      "Embedding dictionary:\n",
      " \tNum conditions: 166\n",
      " \tEmbedding dim: 20\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1897 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tMean/Var Layer in/out: 128 50\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  50 128 20\n",
      "\tHidden Layer 1 in/out: 128 128\n",
      "\tHidden Layer 2 in/out: 128 128\n",
      "\tOutput Layer in/out:  128 1897 \n",
      "\n",
      "Initializing dataloaders\n",
      "Starting training\n",
      " |█-------------------| 8.0%  - val_loss: 591.3551220383 - val_cvae_loss: 591.3551220383"
     ]
    }
   ],
   "source": [
    "seeds = [random.randint(0, 2**32) for _ in range(10)]\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(\"Replicate \", i)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    model_output_path = OUTPUT_format.format(replicate=i, ext=\"\")\n",
    "    latent_output_path = OUTPUT_format.format(replicate=i, ext=\".latent.h5ad\")\n",
    "    if os.path.exists(model_output_path) and os.path.exists(latent_output_path):\n",
    "        print(f\"{latent_outout_path} exists. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    scpoli_model = scPoli(\n",
    "        adata=adata,\n",
    "        condition_key=condition_key,\n",
    "        cell_type_keys=cell_type_key,\n",
    "        hidden_layer_sizes=[128]*3,\n",
    "        latent_dim=50,\n",
    "        embedding_dim=20,\n",
    "        inject_condition=['encoder', 'decoder']\n",
    "    )\n",
    "    \n",
    "    scpoli_model.train(\n",
    "        n_epochs=50,\n",
    "        pretraining_epochs=45,\n",
    "        early_stopping_kwargs=PARAMS['EARLY_STOPPING_KWARGS'],\n",
    "        alpha_epoch_anneal=PARAMS['ALPHA_EPOCH_ANNEAL'],\n",
    "        eta=PARAMS['ETA'],\n",
    "        clustering_res=PARAMS['CLUSTERING_RES'],\n",
    "        labeled_loss_metric=PARAMS['LABELED_LOSS_METRIC'],\n",
    "        unlabeled_loss_metric=PARAMS['UNLABELED_LOSS_METRIC'],\n",
    "        use_stratified_sampling=False,\n",
    "        best_reload=False\n",
    "    )\n",
    "    scpoli_model.save(model_output_path, overwrite=True)\n",
    "    \n",
    "    data_latent = scpoli_model.get_latent(\n",
    "        adata.X.A.astype('float32'), \n",
    "        adata.obs[condition_key].values,\n",
    "        mean=True,\n",
    "    )\n",
    "    adata_latent = sc.AnnData(data_latent)\n",
    "    adata_latent.obs = adata.obs.copy()\n",
    "    adata_latent.write(latent_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445150f-4540-46b8-ad14-b830d7bad836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lataq",
   "language": "python",
   "name": "lataq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
